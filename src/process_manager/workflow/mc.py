from pathlib import Path
from typing import Dict, Any, List
import numpy as np
import pandas as pd
from dataclasses import dataclass
import asyncio
import subprocess
from concurrent.futures import ThreadPoolExecutor

from process_manager.workflow.core import Workflow, WorkflowNode
from process_manager.workflow.process import BaseProcess, ProcessConfig, ProcessType
from process_manager.workflow.id_generator import ProcessIdGenerator
from data_handling.file_handler import FileHandler
from data_handling.data_validator import DataValidator, ValidationRule

@dataclass
class SimulationParams:
    """Parameters for a single Monte Carlo simulation"""
    temperature: float  # Kelvin
    pressure: float    # Pascal
    flow_rate: float   # m3/s
    sim_time: float    # seconds

class InputGenerator(BaseProcess):
    """Generates input files for the MID solver"""
    
    def __init__(self, output_dir: Path, num_simulations: int):
        super().__init__(ProcessConfig(
            process_type=ProcessType.THREAD,
            process_id="input_generator"
        ))
        self.output_dir = output_dir
        self.num_simulations = num_simulations
        self.file_handler = FileHandler(output_dir)
        
    def _generate_random_params(self) -> SimulationParams:
        """Generate random simulation parameters"""
        return SimulationParams(
            temperature=np.random.uniform(273, 373),  # 0-100Â°C
            pressure=np.random.uniform(1e5, 5e5),     # 1-5 bar
            flow_rate=np.random.uniform(0.1, 1.0),    # 0.1-1.0 m3/s
            sim_time=np.random.uniform(10, 100)       # 10-100 seconds
        )
    
    def _create_mid_input_file(self, params: SimulationParams, case_id: str) -> Path:
        """Create input file for MID solver"""
        input_content = f"""
        # MID Solver Input File
        CASE_ID: {case_id}
        TEMPERATURE: {params.temperature}
        PRESSURE: {params.pressure}
        FLOW_RATE: {params.flow_rate}
        SIM_TIME: {params.sim_time}
        """
        
        filepath = self.output_dir / f"case_{case_id}.mid"
        self.file_handler.write_text(filepath, input_content)
        return filepath

    def _sync_execute(self, input_data: Any) -> Dict[str, Path]:
        """Generate all input files for Monte Carlo simulation"""
        case_files = {}
        id_gen = ProcessIdGenerator(prefix="case")
        
        for _ in range(self.num_simulations):
            case_id = id_gen.next_id()
            params = self._generate_random_params()
            filepath = self._create_mid_input_file(params, case_id)
            case_files[case_id] = filepath
            
        return case_files

class MIDSolver(BaseProcess):
    """Runs the MID solver on input files"""
    
    def __init__(self, mid_executable: Path):
        super().__init__(ProcessConfig(
            process_type=ProcessType.PROCESS,  # Use process pool for parallel execution
            process_id="mid_solver"
        ))
        self.mid_executable = mid_executable
    
    def _run_mid_solver(self, input_file: Path) -> Path:
        """Run MID solver on a single input file"""
        output_file = input_file.parent / f"{input_file.stem}_results.out"
        
        # Simulate running commercial solver
        cmd = [
            str(self.mid_executable),
            "-input", str(input_file),
            "-output", str(output_file)
        ]
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=True
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"MID solver failed: {result.stderr}")
            
        return output_file
    
    def _sync_execute(self, input_data: Dict[str, Path]) -> Dict[str, Path]:
        """Run solver on all input files"""
        results = {}
        
        # Process each case
        for case_id, input_file in input_data.items():
            output_file = self._run_mid_solver(input_file)
            results[case_id] = output_file
            
        return results

class ResultsAnalyzer(BaseProcess):
    """Analyzes results from all Monte Carlo simulations"""
    
    def __init__(self, output_dir: Path):
        super().__init__(ProcessConfig(
            process_type=ProcessType.THREAD,
            process_id="results_analyzer"
        ))
        self.output_dir = output_dir
        self.file_handler = FileHandler(output_dir)
    
    def _parse_results_file(self, results_file: Path) -> Dict[str, float]:
        """Parse a single results file"""
        # Simulate parsing results from MID solver output
        # In reality, you'd parse the actual output format
        return {
            "max_temperature": np.random.uniform(300, 400),
            "max_pressure": np.random.uniform(1e5, 6e5),
            "total_flow": np.random.uniform(10, 100)
        }
    
    def _sync_execute(self, input_data: Dict[str, Path]) -> pd.DataFrame:
        """Analyze all results and create summary"""
        results_data = []
        
        for case_id, results_file in input_data.items():
            results = self._parse_results_file(results_file)
            results["case_id"] = case_id
            results_data.append(results)
            
        # Create summary DataFrame
        df = pd.DataFrame(results_data)
        
        # Save summary to CSV
        summary_file = self.output_dir / "monte_carlo_summary.csv"
        df.to_csv(summary_file, index=False)
        
        return df

async def run_monte_carlo_study(
    output_dir: Path,
    mid_executable: Path,
    num_simulations: int
) -> pd.DataFrame:
    """
    Run complete Monte Carlo study workflow
    
    Args:
        output_dir: Directory for all output files
        mid_executable: Path to MID solver executable
        num_simulations: Number of Monte Carlo simulations to run
    
    Returns:
        DataFrame with analysis results
    """
    # Create output directory
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Create processes
    input_gen = InputGenerator(output_dir, num_simulations)
    solver = MIDSolver(mid_executable)
    analyzer = ResultsAnalyzer(output_dir)
    
    # Create workflow nodes
    input_node = WorkflowNode(
        process=input_gen,
        dependencies=[]  # No dependencies
    )
    
    solver_node = WorkflowNode(
        process=solver,
        dependencies=[input_gen.config.process_id]
    )
    
    analyzer_node = WorkflowNode(
        process=analyzer,
        dependencies=[solver.config.process_id]
    )
    
    # Create and run workflow
    async with Workflow(
        max_processes=4,  # Adjust based on your system
        max_threads=2
    ) as workflow:
        # Add nodes
        workflow.add_node(input_node)
        workflow.add_node(solver_node)
        workflow.add_node(analyzer_node)
        
        # Execute workflow
        results = await workflow.execute()
        
        # Return analysis results
        return results[analyzer.config.process_id].data

# Example usage
if __name__ == "__main__":
    import asyncio
    
    async def main():
        results = await run_monte_carlo_study(
            output_dir=Path("monte_carlo_results"),
            mid_executable=Path("/opt/mid/bin/solver"),  # Update with actual path
            num_simulations=100
        )
        
        print("Monte Carlo Analysis Summary:")
        print(results.describe())
        
    asyncio.run(main())