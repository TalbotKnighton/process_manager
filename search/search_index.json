{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Process Manager Documentation","text":"<p>Welcome to the Process Manager documentation. This documentation covers the design principles, implementation details, and API reference for the process management system.</p>"},{"location":"#quickstart-guides","title":"Quickstart Guides","text":"<ul> <li>Data Handling: Handle inputs, outputs, and other data resources across multiple processes.</li> </ul> <p>Todo</p> <p>Add more getting started guides and tutorials.</p>"},{"location":"#core-components","title":"Core Components","text":"<ul> <li>Named Values: Type-safe value containers with validation</li> <li>Random Variables: Statistical distribution implementations</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>Data Handlers</li> </ul>"},{"location":"#design-principles","title":"Design Principles","text":"<p>The process manager is designed to be a flexible, extensible system that can handle various types of data processing tasks. It follows the following principles:</p> <ul> <li>Modularity: The system should be modular, allowing for easy addition or removal of components.</li> <li>Flexibility: The system should be flexible enough to accommodate different types of data and processing requirements.</li> <li>Extensibility: The system should be extensible, allowing for customization and integration with other systems.</li> </ul>"},{"location":"design/named_values/","title":"NamedValue Design","text":"<p>The <code>NamedValue</code> class implements a type-safe container for named values with built-in validation and serialization support. It follows several key design principles to ensure robust and flexible value handling.</p>"},{"location":"design/named_values/#core-design-principles","title":"Core Design Principles","text":""},{"location":"design/named_values/#1-type-safety","title":"1. Type Safety","text":"<p>The <code>NamedValue</code> class uses Python's generic typing system to enforce type safety at both runtime and static analysis time:</p> <pre><code># Type-safe value container\narray_value = NamedValue[np.ndarray](\"my_array\", value=np.array([1, 2, 3]))\nint_value = NamedValue[int](\"my_int\", value=42)\n</code></pre> <p>Type safety is enforced through: - Generic type parameters (<code>NamedValue[T]</code>) - Runtime type validation - Automatic type conversion when possible - Clear error messages when types don't match</p>"},{"location":"design/named_values/#2-value-immutability","title":"2. Value Immutability","text":"<p>Values are immutable by default after initial setting to prevent accidental modifications:</p> <pre><code>value = NamedValue[int](\"counter\", 1)\nvalue.value = 2  # Raises ValueError - value is frozen\nvalue.force_set_value(2)  # Explicit override when needed\n</code></pre>"},{"location":"design/named_values/#3-flexible-type-conversion","title":"3. Flexible Type Conversion","text":"<p>The system attempts to convert values to the correct type when possible:</p> <pre><code># String to int conversion\nint_value = NamedValue[int](\"count\", \"123\")  # Automatically converts to int(123)\n\n# Float to int conversion\nint_value = NamedValue[int](\"count\", 123.0)  # Automatically converts to int(123)\n</code></pre>"},{"location":"design/named_values/#4-inheritance-support","title":"4. Inheritance Support","text":"<p>Two different patterns are supported for extending <code>NamedValue</code>:</p> <ol> <li> <p>Direct generic usage: <pre><code>value = NamedValue[int](\"my_int\", 42)\n</code></pre></p> </li> <li> <p>Subclass with custom behavior: <pre><code>class IntegerValue(NamedValue[int]):\n    def __init__(self, name: str, value: int = None):\n        super().__init__(name, value)\n</code></pre></p> </li> </ol>"},{"location":"design/named_values/#error-handling-design","title":"Error Handling Design","text":"<p>The class implements a sophisticated error handling system that distinguishes between different usage patterns:</p> <ol> <li> <p>Direct Usage Errors (TypeError): <pre><code># Raises TypeError with detailed type information\nvalue = NamedValue[int](\"test\", \"not an integer\")\n</code></pre></p> </li> <li> <p>Subclass Usage Errors (ValueError): <pre><code># Raises ValueError with user-friendly message\nclass IntegerValue(NamedValue[int]):\n    pass\nvalue = IntegerValue(\"test\", \"not an integer\")\n</code></pre></p> </li> </ol>"},{"location":"design/named_values/#testing-strategy","title":"Testing Strategy","text":"<p>The design principles are verified through comprehensive testing:</p>"},{"location":"design/named_values/#1-type-safety-tests","title":"1. Type Safety Tests","text":"<pre><code>def test_type_checking(self):\n    # Test with explicit type parameter\n    class IntValue(NamedValue[int]):\n        pass\n\n    # Valid integer assignment\n    int_value = IntValue(\"test\", 42)\n    assert int_value.value == 42\n\n    # Valid string that can be cast to int\n    str_int_value = IntValue(\"test2\", \"123\")\n    assert str_int_value.value == 123\n\n    # Invalid type that can't be cast\n    with pytest.raises(TypeError):\n        IntValue(\"test3\", \"not an integer\")\n</code></pre>"},{"location":"design/named_values/#2-inheritance-tests","title":"2. Inheritance Tests","text":"<pre><code>def test_type_casting_inheritance(self):\n    class IntegerValue(NamedValue[int]):\n        def __init__(self, name: str, value: int = None):\n            super().__init__(name, value)\n\n    # Test valid assignment\n    int_value = IntegerValue(\"test\", 42)\n    assert isinstance(int_value.value, int)\n\n    # Test type hints are preserved\n    with pytest.raises(ValueError):\n        IntegerValue(\"test\", \"not an integer\")\n</code></pre>"},{"location":"design/named_values/#3-value-immutability-tests","title":"3. Value Immutability Tests","text":"<pre><code>def test_value_immutability(self):\n    value = NamedValue[int](\"test\", 42)\n\n    # Cannot change value after setting\n    with pytest.raises(ValueError):\n        value.value = 43\n\n    # Can force change value when needed\n    value.force_set_value(43)\n    assert value.value == 43\n</code></pre>"},{"location":"design/named_values/#serialization-support","title":"Serialization Support","text":"<p>The class implements JSON serialization support through pydantic:</p> <pre><code>value = NamedValue[int](\"counter\", 42)\nserialized = value.model_dump_json()\ndeserialized = NamedValue.model_validate_json(serialized)\n</code></pre>"},{"location":"design/named_values/#usage-guidelines","title":"Usage Guidelines","text":"<ol> <li> <p>Use direct generic syntax for simple value containers: <pre><code>value = NamedValue[int](\"simple_counter\", 0)\n</code></pre></p> </li> <li> <p>Create subclasses for custom validation or behavior: <pre><code>class PositiveInteger(NamedValue[int]):\n    def _validate_type(self, value: Any) -&gt; int:\n        value = super()._validate_type(value)\n        if value &lt;= 0:\n            raise ValueError(\"Value must be positive\")\n        return value\n</code></pre></p> </li> <li> <p>Use <code>force_set_value()</code> only when value mutability is explicitly needed: <pre><code>value.force_set_value(new_value)  # Use with caution\n</code></pre></p> </li> </ol>"},{"location":"design/named_values/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always specify the type parameter for clarity: <pre><code># Good\nvalue = NamedValue[int](\"count\", 42)\n\n# Avoid\nvalue = NamedValue(\"count\", 42)  # Type defaults to Any\n</code></pre></p> </li> <li> <p>Use meaningful names that describe the value's purpose: <pre><code># Good\ncount = NamedValue[int](\"iteration_count\", 0)\n\n# Avoid\nx = NamedValue[int](\"x\", 0)  # Name is not descriptive\n</code></pre></p> </li> <li> <p>Handle type conversion errors appropriately: <pre><code>try:\n    value = NamedValue[int](\"count\", user_input)\nexcept (TypeError, ValueError) as e:\n    # Handle invalid input\n    pass\n</code></pre></p> </li> </ol> <p>By following these design principles and usage patterns, <code>NamedValue</code> provides a robust and type-safe way to manage named values in your application.</p>"},{"location":"design/random_variables/","title":"Random Variable Design","text":"<p>The random variable system provides a flexible and type-safe way to define, sample, and manage random variables in simulations. It implements a hierarchical design pattern where specific distributions inherit from a base random variable class.</p>"},{"location":"design/random_variables/#core-design-principles","title":"Core Design Principles","text":""},{"location":"design/random_variables/#1-type-safety-and-validation","title":"1. Type Safety and Validation","text":"<p>The system uses Python's type hints and runtime validation to ensure distributions are configured correctly:</p> <pre><code># Type-safe parameter definitions\nclass NormalRandomVariable(RandomVariable[float]):\n    mean: float\n    std_dev: float = Field(gt=0)  # Validation that std_dev must be positive\n</code></pre>"},{"location":"design/random_variables/#2-inheritance-hierarchy","title":"2. Inheritance Hierarchy","text":"<p>A clear inheritance structure ensures consistent behavior across different distributions:</p> <pre><code>RandomVariable[T]  # Base class with generic type T\n    \u21b3 ContinuousRandomVariable  # For continuous distributions\n        \u21b3 NormalRandomVariable  # Specific normal distribution\n        \u21b3 UniformRandomVariable # Specific uniform distribution\n    \u21b3 DiscreteRandomVariable   # For discrete distributions\n        \u21b3 PoissonRandomVariable # Specific Poisson distribution\n</code></pre>"},{"location":"design/random_variables/#3-sampling-interface","title":"3. Sampling Interface","text":"<p>All random variables implement a consistent sampling interface:</p> <pre><code>class RandomVariable(Generic[T]):\n    def sample(self, size: Optional[int] = None) -&gt; T | NDArray:\n        \"\"\"Sample from the distribution.\"\"\"\n        raise NotImplementedError\n\n    def sample_to_list(self, size: int) -&gt; list[T]:\n        \"\"\"Sample multiple values into a list.\"\"\"\n        return list(self.sample(size))\n</code></pre>"},{"location":"design/random_variables/#4-parameter-validation","title":"4. Parameter Validation","text":"<p>Parameters are validated both at instantiation and runtime:</p> <pre><code>class UniformRandomVariable(ContinuousRandomVariable):\n    low: float\n    high: float\n\n    @field_validator(\"high\")\n    def validate_bounds(cls, high: float, info: ValidationInfo) -&gt; float:\n        low = info.data.get(\"low\", 0.0)\n        if high &lt;= low:\n            raise ValueError(\"high must be greater than low\")\n        return high\n</code></pre>"},{"location":"design/random_variables/#implementation-details","title":"Implementation Details","text":""},{"location":"design/random_variables/#1-normal-distribution","title":"1. Normal Distribution","text":"<pre><code>class NormalRandomVariable(ContinuousRandomVariable):\n    \"\"\"\n    Generates normally distributed random values.\n    \"\"\"\n    mean: float = 0.0\n    std_dev: float = Field(gt=0, default=1.0)\n\n    def sample(self, size: Optional[int] = None) -&gt; float | NDArray:\n        return np.random.normal(self.mean, self.std_dev, size)\n</code></pre>"},{"location":"design/random_variables/#2-uniform-distribution","title":"2. Uniform Distribution","text":"<pre><code>class UniformRandomVariable(ContinuousRandomVariable):\n    \"\"\"\n    Generates uniformly distributed random values.\n    \"\"\"\n    low: float = 0.0\n    high: float = 1.0\n\n    def sample(self, size: Optional[int] = None) -&gt; float | NDArray:\n        return np.random.uniform(self.low, self.high, size)\n</code></pre>"},{"location":"design/random_variables/#testing-strategy","title":"Testing Strategy","text":"<p>The testing approach verifies both the statistical properties and error handling of the distributions.</p>"},{"location":"design/random_variables/#1-statistical-property-tests","title":"1. Statistical Property Tests","text":"<pre><code>def test_normal_distribution_properties():\n    # Create normal distribution\n    normal = NormalRandomVariable(mean=10, std_dev=2)\n\n    # Sample large number of values\n    samples = normal.sample(10000)\n\n    # Check statistical properties\n    assert 9.8 &lt; np.mean(samples) &lt; 10.2  # Mean within range\n    assert 1.9 &lt; np.std(samples) &lt; 2.1    # Std dev within range\n</code></pre>"},{"location":"design/random_variables/#2-parameter-validation-tests","title":"2. Parameter Validation Tests","text":"<pre><code>def test_invalid_parameters():\n    # Test invalid standard deviation\n    with pytest.raises(ValidationError):\n        NormalRandomVariable(mean=0, std_dev=-1)\n\n    # Test invalid uniform bounds\n    with pytest.raises(ValidationError):\n        UniformRandomVariable(low=10, high=5)\n</code></pre>"},{"location":"design/random_variables/#3-sampling-interface-tests","title":"3. Sampling Interface Tests","text":"<pre><code>def test_sampling_interface():\n    normal = NormalRandomVariable(mean=0, std_dev=1)\n\n    # Test single sample\n    assert isinstance(normal.sample(), float)\n\n    # Test multiple samples\n    samples = normal.sample(10)\n    assert len(samples) == 10\n\n    # Test list conversion\n    sample_list = normal.sample_to_list(5)\n    assert isinstance(sample_list, list)\n    assert len(sample_list) == 5\n</code></pre>"},{"location":"design/random_variables/#usage-examples","title":"Usage Examples","text":""},{"location":"design/random_variables/#1-basic-usage","title":"1. Basic Usage","text":"<pre><code># Create a normal distribution\nnormal = NormalRandomVariable(mean=10, std_dev=2)\n\n# Single sample\nvalue = normal.sample()\n\n# Multiple samples\nvalues = normal.sample(100)\n</code></pre>"},{"location":"design/random_variables/#2-using-in-simulations","title":"2. Using in Simulations","text":"<pre><code># Define process variation\nprocess_var = NormalRandomVariable(mean=100, std_dev=5)\n\n# Simulate process\nmeasurements = process_var.sample_to_list(1000)\n</code></pre>"},{"location":"design/random_variables/#3-combining-distributions","title":"3. Combining Distributions","text":"<pre><code># Process with random failures\nbase_process = NormalRandomVariable(mean=100, std_dev=2)\nfailure_rate = PoissonRandomVariable(lambda_=0.1)\n\ndef simulate_process(n_steps: int) -&gt; list[float]:\n    measurements = base_process.sample_to_list(n_steps)\n    failures = failure_rate.sample_to_list(n_steps)\n    return [m if f == 0 else 0.0 for m, f in zip(measurements, failures)]\n</code></pre>"},{"location":"design/random_variables/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always validate distribution parameters: <pre><code># Good\nnormal = NormalRandomVariable(mean=0, std_dev=1.0)\n\n# Avoid\nnormal = NormalRandomVariable(mean=0, std_dev=-1.0)  # Will raise error\n</code></pre></p> </li> <li> <p>Use appropriate distribution types: <pre><code># Good - continuous values\nprocess_temp = NormalRandomVariable(mean=350, std_dev=5)\n\n# Good - discrete counts\ndefects = PoissonRandomVariable(lambda_=2.5)\n</code></pre></p> </li> <li> <p>Handle sampling errors appropriately: <pre><code>try:\n    samples = distribution.sample(1000)\nexcept ValueError as e:\n    # Handle sampling error\n    logger.error(f\"Sampling failed: {e}\")\n</code></pre></p> </li> <li> <p>Use type hints for clarity: <pre><code>def simulate_process(\n    distribution: RandomVariable[float],\n    n_samples: int\n) -&gt; NDArray:\n    return distribution.sample(n_samples)\n</code></pre></p> </li> </ol>"},{"location":"design/random_variables/#extended-features","title":"Extended Features","text":""},{"location":"design/random_variables/#1-distribution-composition","title":"1. Distribution Composition","text":"<p>The system supports combining distributions:</p> <pre><code>class CompositeRandomVariable(RandomVariable[float]):\n    distributions: list[RandomVariable[float]]\n    weights: list[float]\n\n    def sample(self, size: Optional[int] = None) -&gt; float | NDArray:\n        samples = [d.sample(size) for d in self.distributions]\n        return np.average(samples, weights=self.weights, axis=0)\n</code></pre>"},{"location":"design/random_variables/#2-serialization-support","title":"2. Serialization Support","text":"<p>Random variables can be serialized for storage or transmission:</p> <pre><code># Save distribution parameters\nnormal = NormalRandomVariable(mean=10, std_dev=2)\njson_data = normal.model_dump_json()\n\n# Recreate distribution\nloaded = NormalRandomVariable.model_validate_json(json_data)\n</code></pre> <p>This design provides a robust foundation for handling random variables in simulation and statistical applications while maintaining type safety and proper validation.</p>"},{"location":"design/workflow/nodes/","title":"Nodes","text":"<p>This implementation provides:</p> <ol> <li>A flexible workflow engine with support for serial and parallel execution</li> <li>Process state tracking via ProcessState enum</li> <li>Robust error handling and retry mechanisms</li> <li>Pydantic models for data validation and serialization</li> <li>Support for different types of processes (CLI, data transformation, API calls)</li> <li>Configurable retry strategies with exponential backoff</li> <li>Process validation rules</li> <li>Workflow state serialization to JSON</li> <li>Support for optional (non-critical) processes</li> <li>Clean, type-hinted API that will work well with IDE autocompletion</li> </ol> <p>Users can easily extend this framework by:</p> <ol> <li>Creating new process implementations by subclassing BaseProcess</li> <li>Adding custom validation rules</li> <li>Configuring retry strategies</li> <li>Building complex workflows with multiple parallel and serial branches</li> <li>Implementing custom error handling strategies</li> </ol> <p>The framework is also easily extensible for additional features like:</p> <ol> <li>Workflow persistence</li> <li>Process monitoring and logging</li> <li>Workflow visualization</li> <li>Distributed execution</li> <li>Process checkpointing and resumption</li> </ol> <p>Users can create arbitrarily complex workflows while maintaining type safety and data validation through Pydantic models. The async implementation allows for efficient parallel execution where possible, while the dependency system ensures proper ordering of operations.</p>"},{"location":"for_reference/named_values_extensions/","title":"Named values extensions","text":"<p>Here's a comprehensive example showing both practical usage and potential extensions:</p> <p>First, basic usage: test_named_values.py</p> <pre><code>from process_manager.data_handlers import (\n    NamedValue,\n    NamedValueState,\n    NamedValueList,\n    NamedValueHash\n)\n\ndef test_basic_usage():\n    print(\"\\n=== Basic Usage ===\")\n\n    # Create a value and check its state\n    value = NamedValue(name=\"temperature\")\n    print(f\"Initial state: {value._state}\")\n\n    # Set the value and verify state change\n    value.value = 72.5\n    print(f\"After setting: {value._state}\")\n    print(f\"Value: {value.value}\")\n\n    # Try to modify (should fail)\n    try:\n        value.value = 73.0\n        print(\"Warning: Value was modified!\")\n    except ValueError as e:\n        print(f\"Protected: {e}\")\n\n    # Force set and verify state\n    value.force_set_value(73.0)\n    print(f\"After force set: {value._state}\")\n    print(f\"New value: {value.value}\")\n\ndef test_serialization():\n    print(\"\\n=== Serialization ===\")\n\n    # Create values in different states\n    unset = NamedValue(name=\"unset\")\n    set_value = NamedValue(name=\"set\", value=42)\n\n    # Serialize both\n    print(\"\\nUnset value serialized:\")\n    print(unset.model_dump_json(indent=2))\n\n    print(\"\\nSet value serialized:\")\n    print(set_value.model_dump_json(indent=2))\n\n    # Deserialize and verify states\n    json_str = set_value.model_dump_json()\n    restored = NamedValue.model_validate_json(json_str)\n    print(f\"\\nRestored value state: {restored._state}\")\n    print(f\"Restored value: {restored.value}\")\n\ndef test_collections():\n    print(\"\\n=== Collections Usage ===\")\n\n    # Create a list with mixed states\n    value_list = NamedValueList()\n    value_list.append(NamedValue(name=\"unset\"))\n    value_list.append(NamedValue(name=\"set\", value=\"hello\"))\n\n    # Create a hash with mixed states\n    value_hash = NamedValueHash()\n    value_hash.register_value(NamedValue(name=\"temp\", value=98.6))\n    value_hash.register_value(NamedValue(name=\"pressure\"))\n\n    # Serialize both\n    print(\"\\nList serialized:\")\n    print(value_list.model_dump_json(indent=2))\n\n    print(\"\\nHash serialized:\")\n    print(value_hash.model_dump_json(indent=2))\n\nif __name__ == \"__main__\":\n    test_basic_usage()\n    test_serialization()\n    test_collections()\n</code></pre> <p>Extended version with more complex state management:</p> <p><pre><code>from enum import Enum\nfrom typing import Any, Optional\nfrom datetime import datetime\n\nclass NamedValueState(str, Enum):\n    \"\"\"Extended state enum for NamedValue objects.\"\"\"\n    UNSET = \"unset\"\n    SET = \"set\"\n    PENDING = \"pending\"  # For async operations\n    INVALID = \"invalid\"  # For validation failures\n    EXPIRED = \"expired\"  # For time-sensitive values\n\nclass NamedValueMetadata:\n    \"\"\"Metadata for tracking value state changes.\"\"\"\n    def __init__(self):\n        self.created_at: datetime = datetime.now()\n        self.last_modified: Optional[datetime] = None\n        self.set_count: int = 0\n        self.previous_value: Any = None\n        self.validation_error: Optional[str] = None\n\nclass NamedValue(NamedObject, Generic[T]):\n    \"\"\"Enhanced NamedValue with extended state management.\"\"\"\n\n    _registry_category: ClassVar[str] = \"values\"\n\n    name: str = Field(..., description=\"Name of the value\")\n    _stored_value: T | UNSET = PrivateAttr(default=UNSET.token)\n    _state: NamedValueState = PrivateAttr(default=NamedValueState.UNSET)\n    _type: type = PrivateAttr()\n    _metadata: NamedValueMetadata = PrivateAttr()\n    _expiry: Optional[datetime] = PrivateAttr(default=None)\n\n    def __init__(self, name: str, value: T | None = None, expires_in: Optional[float] = None, **data):\n        super().__init__(name=name, **data)\n        self._type = self._extract_value_type()\n        self._metadata = NamedValueMetadata()\n\n        if expires_in is not None:\n            self._expiry = datetime.now().timestamp() + expires_in\n\n        if value is not None:\n            self.value = value\n\n    @property\n    def value(self) -&gt; T:\n        \"\"\"Get the stored value with additional state checks.\"\"\"\n        if self._state == NamedValueState.UNSET:\n            raise ValueError(f\"Value '{self.name}' has not been set yet.\")\n\n        if self._state == NamedValueState.INVALID:\n            raise ValueError(f\"Value '{self.name}' is invalid: {self._metadata.validation_error}\")\n\n        if self._state == NamedValueState.PENDING:\n            raise ValueError(f\"Value '{self.name}' is pending.\")\n\n        if self._state == NamedValueState.EXPIRED:\n            raise ValueError(f\"Value '{self.name}' has expired.\")\n\n        return self._stored_value\n\n    @value.setter\n    def value(self, new_value: T):\n        \"\"\"Set value with metadata tracking.\"\"\"\n        if self._state == NamedValueState.SET:\n            raise ValueError(\n                f\"Value '{self.name}' has already been set and is frozen. \"\n                \"Use force_set_value() if you need to override it.\"\n            )\n\n        try:\n            validated_value = self._validate_type(new_value)\n\n            # Update metadata\n            self._metadata.last_modified = datetime.now()\n            self._metadata.set_count += 1\n            self._metadata.previous_value = self._stored_value\n\n            # Set the new value\n            object.__setattr__(self, '_stored_value', validated_value)\n            object.__setattr__(self, '_state', NamedValueState.SET)\n\n        except Exception as e:\n            # Handle validation failure\n            self._metadata.validation_error = str(e)\n            object.__setattr__(self, '_state', NamedValueState.INVALID)\n            raise\n\n    def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Enhanced serialization with metadata.\"\"\"\n        data = super().model_dump(**kwargs)\n        data['state'] = self._state\n\n        if self._state == NamedValueState.SET:\n            data['stored_value'] = self._stored_value\n\n        # Include metadata\n        data['metadata'] = {\n            'created_at': self._metadata.created_at.isoformat(),\n            'last_modified': self._metadata.last_modified.isoformat() if self._metadata.last_modified else None,\n            'set_count': self._metadata.set_count,\n        }\n\n        if self._expiry:\n            data['expires_at'] = datetime.fromtimestamp(self._expiry).isoformat()\n\n        return data\n\n    def check_expiry(self) -&gt; bool:\n        \"\"\"Check if the value has expired.\"\"\"\n        if self._expiry and datetime.now().timestamp() &gt; self._expiry:\n            object.__setattr__(self, '_state', NamedValueState.EXPIRED)\n            return True\n        return False\n\n    def mark_pending(self) -&gt; None:\n        \"\"\"Mark value as pending (for async operations).\"\"\"\n        object.__setattr__(self, '_state', NamedValueState.PENDING)\n\n    @property\n    def state(self) -&gt; NamedValueState:\n        \"\"\"Get current state.\"\"\"\n        return self._state\n\n    @property\n    def metadata(self) -&gt; dict:\n        \"\"\"Get value metadata.\"\"\"\n        return {\n            'created_at': self._metadata.created_at,\n            'last_modified': self._metadata.last_modified,\n            'set_count': self._metadata.set_count,\n            'has_previous_value': self._metadata.previous_value is not None\n        }\n</code></pre> Example usage of the extended version: test_extended_values.py</p> <p><pre><code>from process_manager.data_handlers import NamedValue, NamedValueState\nfrom time import sleep\n\ndef test_extended_features():\n    print(\"\\n=== Testing Extended Features ===\")\n\n    # Test expiring value\n    print(\"\\nTesting expiring value:\")\n    temp = NamedValue(name=\"temperature\", value=98.6, expires_in=2)\n    print(f\"Initial value: {temp.value}\")\n    print(f\"Initial state: {temp.state}\")\n\n    print(\"Waiting for expiration...\")\n    sleep(2.1)\n    temp.check_expiry()\n    print(f\"State after expiry: {temp.state}\")\n\n    try:\n        print(f\"Value after expiry: {temp.value}\")\n    except ValueError as e:\n        print(f\"Expected error: {e}\")\n\n    # Test pending state\n    print(\"\\nTesting pending state:\")\n    async_value = NamedValue(name=\"async_data\")\n    async_value.mark_pending()\n    print(f\"State: {async_value.state}\")\n\n    try:\n        print(f\"Value: {async_value.value}\")\n    except ValueError as e:\n        print(f\"Expected error: {e}\")\n\n    # Test metadata\n    print(\"\\nTesting metadata:\")\n    value = NamedValue(name=\"tracked\", value=42)\n    print(\"Initial metadata:\", value.metadata)\n\n    value.force_set_value(43)\n    print(\"Metadata after update:\", value.metadata)\n\n    # Test serialization with metadata\n    print(\"\\nTesting enhanced serialization:\")\n    print(value.model_dump_json(indent=2))\n\nif __name__ == \"__main__\":\n    test_extended_features()\n</code></pre> This extended version shows:</p> <p>Additional states for more complex scenarios Metadata tracking for value changes Expiring values Pending state for async operations Enhanced error handling Rich serialization format</p>"},{"location":"for_reference/python_metaclasses/","title":"Python Metaclasses Guide","text":""},{"location":"for_reference/python_metaclasses/#core-concepts","title":"Core Concepts","text":"<ol> <li>A metaclass is a class for a class - it allows you to customize class creation</li> <li>Metaclasses are called when a class is defined, not when it's instantiated</li> <li>The metaclass can modify the class definition before it's created</li> </ol>"},{"location":"for_reference/python_metaclasses/#key-rules","title":"Key Rules","text":""},{"location":"for_reference/python_metaclasses/#1-inheritance-rules","title":"1. Inheritance Rules","text":"<ul> <li>Metaclasses are inherited by subclasses</li> <li>If a class has a metaclass, all its subclasses must be compatible with that metaclass</li> <li>When there are multiple metaclasses in the inheritance hierarchy, they must be compatible</li> </ul>"},{"location":"for_reference/python_metaclasses/#2-creation-order","title":"2. Creation Order","text":"<pre><code>class MyMetaclass(type):\n    def __new__(mcs, name, bases, namespace, **kwargs):\n        # 1. __new__ is called first\n        return super().__new__(mcs, name, bases, namespace)\n\n    def __init__(cls, name, bases, namespace, **kwargs):\n        # 2. __init__ is called after __new__\n        super().__init__(name, bases, namespace)\n\n    def __call__(cls, *args, **kwargs):\n        # 3. __call__ is called when creating instances\n        return super().__call__(*args, **kwargs)\n</code></pre>"},{"location":"for_reference/python_metaclasses/#3-declaration-methods","title":"3. Declaration Methods","text":"<pre><code># Method 1: metaclass keyword\nclass MyClass(metaclass=MyMetaclass):\n    pass\n\n# Method 2: inheritance from a class with metaclass\nclass MyMetaclassBase(metaclass=MyMetaclass):\n    pass\nclass MyClass(MyMetaclassBase):\n    pass\n</code></pre>"},{"location":"for_reference/python_metaclasses/#4-common-use-cases","title":"4. Common Use Cases","text":"<pre><code>class RegisterMeta(type):\n    registry = {}\n\n    def __new__(mcs, name, bases, namespace):\n        # Register all classes using this metaclass\n        cls = super().__new__(mcs, name, bases, namespace)\n        mcs.registry[name] = cls\n        return cls\n\nclass ValidatorMeta(type):\n    def __new__(mcs, name, bases, namespace):\n        # Add validation to all methods\n        for key, value in namespace.items():\n            if callable(value):\n                namespace[key] = validate(value)\n        return super().__new__(mcs, name, bases, namespace)\n</code></pre>"},{"location":"for_reference/python_metaclasses/#5-working-with-other-metaclasses","title":"5. Working with Other Metaclasses","text":"<pre><code># Combining metaclasses\nclass CombinedMeta(MetaclassA, MetaclassB):\n    def __new__(mcs, name, bases, namespace):\n        # Call both metaclass's __new__\n        namespace = MetaclassA.__new__(mcs, name, bases, namespace)\n        return MetaclassB.__new__(mcs, name, bases, namespace)\n</code></pre>"},{"location":"for_reference/python_metaclasses/#recommended-references","title":"Recommended References","text":""},{"location":"for_reference/python_metaclasses/#1-official-python-documentation","title":"1. Official Python Documentation","text":"<ul> <li>Python Data Model</li> <li>Custom Metaclasses</li> </ul>"},{"location":"for_reference/python_metaclasses/#2-books","title":"2. Books","text":"<ul> <li>\"Python in a Nutshell\" by Alex Martelli (O'Reilly)</li> <li>\"Fluent Python\" by Luciano Ramalho (O'Reilly)</li> </ul>"},{"location":"for_reference/python_metaclasses/#3-real-world-example","title":"3. Real-world Example","text":"<pre><code>class RandomVariableMeta(type(BaseModel)):\n    def __new__(mcs, name, bases, namespace, **kwargs):\n        # Automatically apply squeezable decorator\n        for method in ['sample', 'pdf', 'cdf']:\n            if method in namespace and callable(namespace[method]):\n                namespace[method] = squeezable(namespace[method])\n        return super().__new__(mcs, name, bases, namespace, **kwargs)\n</code></pre>"},{"location":"for_reference/python_metaclasses/#common-gotchas","title":"Common Gotchas","text":"<ol> <li>Multiple Inheritance: Be careful when combining classes with different metaclasses</li> <li>Order of Operations: Remember metaclass code runs during class definition</li> <li>Performance: Metaclasses can impact class creation performance</li> <li>Complexity: They can make code harder to understand if overused</li> </ol>"},{"location":"for_reference/python_metaclasses/#best-practices","title":"Best Practices","text":"<ol> <li>Use metaclasses sparingly - only when class decorators or inheritance won't suffice</li> <li>Document metaclass behavior clearly</li> <li>Keep metaclass logic simple and focused</li> <li>Consider alternatives like class decorators or descriptors first</li> </ol>"},{"location":"guides/data_handling/","title":"Data Handling Quickstart Guide","text":"<p>This guide demonstrates how to use the <code>data_handlers</code> package for handling random variables and named values.</p>"},{"location":"guides/data_handling/#basic-usage-of-named-values","title":"Basic Usage of Named Values","text":"<pre><code>from process_manager import data_handlers as dh\n\n# Create named values with automatic state management\nname = dh.NamedValue(name=\"name\", value=\"John Doe\")  # Value is set immediately\nage = dh.NamedValue(name=\"age\")  # Value is initially unset\n\n# Check and set values\nprint(name.value)  # Output: \"John Doe\"\ntry:\n    print(age.value)  # Raises ValueError: Value 'age' has not been set yet\nexcept ValueError as e:\n    print(e)\n\n# Set the value for age\nage.value = 25  # Sets and freezes the value\ntry:\n    age.value = 26  # Raises ValueError - value is frozen\nexcept ValueError as e:\n    print(e)  # Output: Value 'age' has already been set and is frozen...\n\n# Use force_set_value to change a frozen value\nage.force_set_value(26)  # Successfully changes the value\nprint(age.value)  # Output: 26\n</code></pre>"},{"location":"guides/data_handling/#managing-named-value-collections","title":"Managing Named Value Collections","text":"<pre><code># Create a hash to store named values\nnv_hash = dh.NamedValueHash()\n\n# Register named values\nnv_hash.register_value(name)\nnv_hash.register_value(age)\n\n# Access values through the hash\nprint(nv_hash.get_raw_value(\"name\"))  # Output: \"John Doe\"\nprint(nv_hash.get_raw_value(\"age\"))   # Output: 26\n\n# Create ordered lists of named values\nnv_list = dh.NamedValueList()\nnv_list.append(name)\nnv_list.append(age)\n\n# Access values by index or name\nprint(nv_list[0].value)  # Output: \"John Doe\"\nprint(nv_list.get_value(\"age\").value)  # Output: 26\n</code></pre>"},{"location":"guides/data_handling/#working-with-random-variables","title":"Working with Random Variables","text":"<pre><code>import numpy as np\n\n# Create random variable distributions\nnormal_dist = dh.NormalDistribution(name=\"height\", mu=170, sigma=10)\nuniform_dist = dh.UniformDistribution(name=\"weight\", low=60, high=90)\ncategories = np.array([\"A\", \"B\", \"C\"])\ncat_dist = dh.CategoricalDistribution(\n    name=\"blood_type\",\n    categories=categories,\n    probabilities=np.array([0.4, 0.1, 0.5])\n)\n\n# Create a hash to store random variables\nrv_hash = dh.RandomVariableHash()\n\n# Register variables and get samples\nheight = normal_dist.register_to_hash(rv_hash, size=5)\nweight = uniform_dist.register_to_hash(rv_hash, size=5)\nblood_type = cat_dist.register_to_hash(rv_hash, size=5)\n\n# View the samples\nprint(f\"Heights: {height.value}\")      # e.g., [168.3, 175.2, 162.1, 171.8, 169.5]\nprint(f\"Weights: {weight.value}\")      # e.g., [75.3, 82.1, 68.4, 71.2, 88.9]\nprint(f\"Blood Types: {blood_type.value}\")  # e.g., ['A', 'C', 'A', 'C', 'C']\n</code></pre>"},{"location":"guides/data_handling/#serialization-and-deserialization","title":"Serialization and Deserialization","text":"<pre><code># Serialize named values hash\nnv_json = nv_hash.model_dump_json(indent=2)\nprint(nv_json)\n</code></pre> <p>Example output: <pre><code>{\n  \"objects\": {\n    \"name\": {\n      \"name\": \"name\",\n      \"type\": \"NamedValue\",\n      \"state\": \"set\",\n      \"stored_value\": \"John Doe\"\n    },\n    \"age\": {\n      \"name\": \"age\",\n      \"type\": \"NamedValue\",\n      \"state\": \"set\",\n      \"stored_value\": 26\n    }\n  }\n}\n</code></pre></p> <pre><code># Serialize random variables hash\nrv_json = rv_hash.model_dump_json(indent=2)\nprint(rv_json)\n</code></pre> <p>Example output: <pre><code>{\n  \"objects\": {\n    \"height\": {\n      \"name\": \"height\",\n      \"type\": \"NormalDistribution\",\n      \"mu\": 170,\n      \"sigma\": 10,\n      \"seed\": null\n    },\n    \"weight\": {\n      \"name\": \"weight\",\n      \"type\": \"UniformDistribution\",\n      \"low\": 60,\n      \"high\": 90,\n      \"seed\": null\n    },\n    \"blood_type\": {\n      \"name\": \"blood_type\",\n      \"type\": \"CategoricalDistribution\",\n      \"categories\": [\"A\", \"B\", \"C\"],\n      \"probabilities\": [0.4, 0.1, 0.5],\n      \"seed\": null\n    }\n  }\n}\n</code></pre></p> <pre><code># Load from serialized data\nnew_nv_hash = dh.NamedValueHash.model_validate_json(nv_json)\nnew_rv_hash = dh.RandomVariableHash.model_validate_json(rv_json)\n\n# Save to and load from files\nwith open(\"nv_hash.json\", \"w\") as f:\n    f.write(nv_hash.model_dump_json(indent=2))\n\nwith open(\"nv_hash.json\", \"r\") as f:\n    loaded_nv_hash = dh.NamedValueHash.model_validate_json(f.read())\n</code></pre>"},{"location":"guides/data_handling/#advanced-named-value-features","title":"Advanced Named Value Features","text":"<pre><code>from process_manager import data_handlers as dh\n\n# Type-safe value handling\ninteger_value = dh.NamedValue[int](name=\"count\")  # Explicitly typed as int\ntry:\n    integer_value.value = \"not an integer\"  # Raises TypeError\nexcept TypeError as e:\n    print(e)\ninteger_value.value = 42\n\n# Working with collections\nvalues_list = dh.NamedValueList()\ninteger_value.append_to_value_list(values_list)  # Method chaining\nvalues_list.append(dh.NamedValue(\"price\", 10.99))\n\n# Iterate over values\nfor value in values_list.get_values():\n    print(f\"{value.name}: {value.value}\")\n\n# Filter values by type\nnumber_values = values_list.get_value_by_type(int)\n</code></pre>"},{"location":"guides/data_handling/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always use type hints with NamedValue for better type safety: <pre><code>temperature = dh.NamedValue[float](name=\"temp\")\nname = dh.NamedValue[str](name=\"user_name\")\n</code></pre></p> </li> <li> <p>Handle unset values appropriately: <pre><code>value = dh.NamedValue(name=\"example\")\nif value._state == dh.NamedValueState.UNSET:\n    # Handle unset value case\n    value.value = default_value\n</code></pre></p> </li> <li> <p>Use force_set_value() sparingly and only when you need to override frozen values: <pre><code># Prefer setting values once\nconfig = dh.NamedValue(name=\"config\", value=initial_config)\n\n# Only use force_set_value when absolutely necessary\nif needs_update:\n    config.force_set_value(new_config)\n</code></pre></p> </li> <li> <p>Leverage the built-in serialization for persistence: <pre><code># Save state\nsaved_state = value.model_dump_json()\n\n# Restore state\nrestored_value = dh.NamedValue.model_validate_json(saved_state)\n</code></pre></p> </li> </ol>"},{"location":"guides/results_manager/","title":"ResultsManager: Pydantic-Validated Data Storage for Parallel Processing","text":"<p>ResultsManager is a flexible storage system for Pydantic models, designed for keeping track of results from parallel processing tasks. It provides a simple yet powerful interface to store, retrieve, and manage structured data with built-in validation.</p>"},{"location":"guides/results_manager/#key-features","title":"Key Features","text":"<ul> <li>Pydantic Integration: First-class support for storing and retrieving Pydantic models with automatic validation</li> <li>Hierarchical Organization: Store data using intuitive path-like IDs (e.g., \"projects/project1/results/analysis\")</li> <li>Multiple Storage Backends: Seamlessly switch between file-based, SQLite, or custom backends</li> <li>Namespace Management: Organize models by namespace to prevent naming conflicts</li> <li>Concurrency Support: Thread and process safe with proper locking mechanisms</li> <li>Async Support: Full async API for use with asyncio-based applications</li> <li>Type Safety: Comprehensive type hints and runtime type validation</li> </ul>"},{"location":"guides/results_manager/#when-to-use-resultsmanager","title":"When to Use ResultsManager","text":"<p>ResultsManager is ideal for:</p> <ul> <li>Data Processing Pipelines: Store intermediate and final results from data transformations</li> <li>Machine Learning Workflows: Save model artifacts, parameters, and evaluation metrics</li> <li>Parallel Task Processing: Manage results from distributed or concurrent processing</li> <li>API Result Caching: Store validated results from API calls for reuse</li> <li>ETL Processes: Capture extraction, transformation, and loading outputs</li> </ul>"},{"location":"guides/results_manager/#getting-started","title":"Getting Started","text":""},{"location":"guides/results_manager/#installation","title":"Installation","text":"<pre><code>pip install results-manager\n</code></pre>"},{"location":"guides/results_manager/#basic-usage","title":"Basic Usage","text":"<pre><code>from pydantic import BaseModel\nfrom typing import List, Optional\nfrom results_manager import ResultsManager, register_model\n\n# Define your data models\n@register_model\nclass Person(BaseModel):\n    name: str\n    age: int\n    email: Optional[str] = None\n\n@register_model\nclass Team(BaseModel):\n    name: str\n    members: List[Person]\n\n# Create a manager\nresults = ResultsManager(\"./data\")\n\n# Store some data\nperson = Person(name=\"John Doe\", age=30, email=\"john@example.com\")\nresults.set(\"people/john\", person)\n\nteam = Team(\n    name=\"Engineering\",\n    members=[\n        Person(name=\"John Doe\", age=30),\n        Person(name=\"Jane Smith\", age=28)\n    ]\n)\nresults.set(\"teams/engineering\", team)\n\n# Retrieve data later\njohn = results.get(\"people/john\")\nprint(f\"Retrieved: {john.name}, {john.age}\")\n\n# List available results\nall_ids = results.list_ids()\nprint(f\"Available results: {all_ids}\")\n\n# Find results with a prefix\nteam_ids = results.list_ids(\"teams\")\nprint(f\"Teams: {team_ids}\")\n\n# Check if data exists\nif results.exists(\"people/jane\"):\n    print(\"Jane's data exists\")\nelse:\n    print(\"Jane's data not found\")\n\n# Delete data when no longer needed\nresults.delete(\"people/john\")\n</code></pre>"},{"location":"guides/results_manager/#storage-backends","title":"Storage Backends","text":"<p>ResultsManager offers multiple backends for different use cases:</p>"},{"location":"guides/results_manager/#file-backend-default","title":"File Backend (Default)","text":"<p>The FileBackend stores each result as a separate JSON file in a directory structure that mirrors your ID hierarchy:</p> <pre><code>from results_manager import ResultsManager, FileBackend\n\n# Default uses FileBackend\nresults = ResultsManager(\"./data\")\n\n# Or explicitly specify it\nfile_backend = FileBackend(\"./data\")\nresults = ResultsManager(backend=file_backend)\n</code></pre> <p>Best for:</p> <ul> <li>Development and testing</li> <li>Simple applications</li> <li>Small to medium datasets</li> <li>Local processing</li> </ul>"},{"location":"guides/results_manager/#sqlite-backend","title":"SQLite Backend","text":"<p>The SQLiteBackend stores results in a SQLite database for better query performance and atomicity:</p> <pre><code>from results_manager import ResultsManager\nfrom results_manager.backends.sqlite_backend import SqliteBackend\n\nsqlite_backend = SqliteBackend(\"./results.db\")\nresults = ResultsManager(backend=sqlite_backend)\n</code></pre> <p>Best for:</p> <ul> <li>Larger datasets</li> <li>More frequent updates</li> <li>Applications needing transactional consistency</li> <li>Situations where you need to query across many results</li> </ul>"},{"location":"guides/results_manager/#custom-backends","title":"Custom Backends","text":"<p>You can implement custom backends by inheriting from ResultsBackend:</p> <pre><code>from results_manager import ResultsManager, ResultsBackend\n\nclass MyCustomBackend(ResultsBackend):\n    # Implement required methods\n    # ...\n\nresults = ResultsManager(backend=MyCustomBackend())\n</code></pre>"},{"location":"guides/results_manager/#switching-backends","title":"Switching Backends","text":"<p>One of ResultsManager's most powerful features is the ability to switch backends without changing your application code:</p> <pre><code># Start with file storage during development\nresults = ResultsManager(\"./dev_data\")\n\n# Later switch to SQLite for production\nsqlite_backend = SqliteBackend(\"./prod.db\")\nresults.backend = sqlite_backend\n\n# Your application code remains unchanged\nresults.set(\"key\", data)\nretrieved = results.get(\"key\")\n</code></pre> <p>This makes it easy to scale up as your needs grow.</p>"},{"location":"guides/results_manager/#async-support","title":"Async Support","text":"<p>For asyncio-based applications, ResultsManager provides a full async API:</p> <pre><code>import asyncio\nfrom results_manager import AsyncResultsManager\n\nasync def process_data():\n    results = AsyncResultsManager(\"./data\")\n\n    # All operations are async\n    await results.set(\"key\", data)\n    retrieved = await results.get(\"key\")\n\n    # Run operations concurrently\n    tasks = [\n        results.set(f\"item/{i}\", data) \n        for i in range(10)\n    ]\n    await asyncio.gather(*tasks)\n\nasyncio.run(process_data())\n</code></pre>"},{"location":"guides/results_manager/#namespace-management","title":"Namespace Management","text":"<p>ResultsManager uses a model registry with namespace support to avoid naming conflicts:</p> <pre><code>from results_manager import register_model, get_model_class\n\n# Register in default namespace\n@register_model\nclass User(BaseModel):\n    name: str\n\n# Register in custom namespace\n@register_model(namespace=\"analytics\")\nclass User(BaseModel):  # Same name, different model\n    user_id: str\n    visit_count: int\n\n# Get the right model by namespace\nuser_model = get_model_class(\"User\")  # Default namespace\nanalytics_user = get_model_class(\"User\", namespace=\"analytics\")\n</code></pre>"},{"location":"guides/results_manager/#scaling-your-workflows","title":"Scaling Your Workflows","text":"<p>ResultsManager is designed to grow with your application needs:</p>"},{"location":"guides/results_manager/#from-single-process-to-distributed-execution","title":"From Single Process to Distributed Execution","text":"<pre><code>import concurrent.futures\nfrom results_manager import ResultsManager, SetBehavior\n\ndef process_item(item_id):\n    # Each process creates its own manager instance\n    results = ResultsManager(\"./results\")\n\n    # Process the item\n    output = compute_result(item_id)\n\n    # Store with SKIP_IF_EXISTS to handle cases where another process\n    # already completed this item\n    results.set(f\"items/{item_id}\", output, behavior=SetBehavior.SKIP_IF_EXISTS)\n    return item_id\n\n# Process items in parallel\nwith concurrent.futures.ProcessPoolExecutor() as executor:\n    futures = [executor.submit(process_item, i) for i in range(100)]\n    for future in concurrent.futures.as_completed(futures):\n        print(f\"Completed item {future.result()}\")\n</code></pre>"},{"location":"guides/results_manager/#from-small-to-large-datasets","title":"From Small to Large Datasets","text":"<p>As your data grows, you can easily switch to a more scalable backend:</p> <pre><code># During development with small data\nresults = ResultsManager(\"./dev_data\")\n\n# For production with larger data\nfrom results_manager.backends.sqlite_backend import SqliteBackend\nresults = ResultsManager(backend=SqliteBackend(\"./prod.db\"))\n\n# Future expansion to other backends\n# from results_manager.backends.postgres_backend import PostgresBackend\n# results.backend = PostgresBackend(connection_string)\n</code></pre>"},{"location":"guides/results_manager/#why-resultsmanager","title":"Why ResultsManager?","text":""},{"location":"guides/results_manager/#compared-to-simple-file-storage","title":"Compared to Simple File Storage","text":"<ul> <li>Type Safety: Automatic validation of data structures</li> <li>Organization: Hierarchical IDs vs. flat files</li> <li>Concurrency: Built-in locking for safe concurrent access</li> <li>Flexibility: Multiple backend options</li> </ul>"},{"location":"guides/results_manager/#compared-to-databases","title":"Compared to Databases","text":"<ul> <li>Simplified Interface: No SQL or ORM knowledge required</li> <li>Schema Flexibility: Models can evolve without migrations</li> <li>Type Validation: Automatic through Pydantic</li> <li>Python-Native: Works directly with Python objects</li> </ul>"},{"location":"guides/results_manager/#compared-to-key-value-stores","title":"Compared to Key-Value Stores","text":"<ul> <li>Rich Data Models: Full Pydantic model support vs. simple values</li> <li>Hierarchical Structure: Natural organization vs. flat namespaces</li> <li>Type Safety: Strongly typed vs. schema-less</li> </ul>"},{"location":"guides/results_manager/#real-world-use-cases","title":"Real-World Use Cases","text":""},{"location":"guides/results_manager/#machine-learning-experiment-tracking","title":"Machine Learning Experiment Tracking","text":"<pre><code>from results_manager import ResultsManager, register_model\n\n@register_model\nclass ModelMetrics(BaseModel):\n    model_name: str\n    accuracy: float\n    precision: float\n    recall: float\n    training_time: float\n    parameters: Dict[str, Any]\n\nresults = ResultsManager(\"./experiments\")\n\n# Track experiment results\nmetrics = ModelMetrics(\n    model_name=\"RandomForest\",\n    accuracy=0.92,\n    precision=0.89,\n    recall=0.94,\n    training_time=45.2,\n    parameters={\"n_estimators\": 100, \"max_depth\": 10}\n)\nresults.set(\"models/random_forest/run_1\", metrics)\n\n# Later, analyze all experiments\nfor result_id in results.list_ids(\"models/random_forest\"):\n    metrics = results.get(result_id, ModelMetrics)\n    print(f\"{result_id}: Accuracy={metrics.accuracy}, Time={metrics.training_time}s\")\n</code></pre>"},{"location":"guides/results_manager/#data-processing-pipeline","title":"Data Processing Pipeline","text":"<pre><code>from results_manager import ResultsManager, register_model\n\n@register_model\nclass RawData(BaseModel):\n    # Raw data schema\n    ...\n\n@register_model\nclass ProcessedData(BaseModel):\n    # Processed data schema\n    ...\n\n@register_model\nclass AnalysisResult(BaseModel):\n    # Analysis results schema\n    ...\n\nresults = ResultsManager(\"./pipeline_data\")\n\n# Stage 1: Extract data\nraw_data = extract_data()\nresults.set(\"pipeline/extraction\", raw_data)\n\n# Stage 2: Process data\nraw = results.get(\"pipeline/extraction\", RawData)\nprocessed = process_data(raw)\nresults.set(\"pipeline/processing\", processed)\n\n# Stage 3: Analyze data\nprocessed = results.get(\"pipeline/processing\", ProcessedData)\nanalysis = analyze_data(processed)\nresults.set(\"pipeline/analysis\", analysis)\n\n# Get final results any time later\nfinal_results = results.get(\"pipeline/analysis\", AnalysisResult)\n</code></pre>"},{"location":"guides/results_manager/#conclusion","title":"Conclusion","text":"<p>ResultsManager provides a robust solution for managing structured data in Python applications. Its combination of type safety, flexible storage options, and intuitive interface makes it an ideal choice for data processing, machine learning workflows, and parallel task management.</p> <p>Whether you're working on a small personal project or a large-scale data processing pipeline, ResultsManager adapts to your needs and grows with your application.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>data_handlers<ul> <li>base</li> <li>custom_serde_definitions<ul> <li>pandantic</li> </ul> </li> <li>mixins</li> <li>random_variables</li> <li>values</li> <li>values_save</li> </ul> </li> <li>flow<ul> <li>core<ul> <li>context</li> <li>errors</li> <li>f1</li> <li>f2</li> <li>f3</li> <li>f4</li> <li>f5</li> <li>flow</li> <li>logging</li> <li>results</li> <li>types</li> </ul> </li> <li>examples<ul> <li>data_processing</li> </ul> </li> <li>execution<ul> <li>pool</li> </ul> </li> <li>monitoring<ul> <li>metrics</li> <li>service</li> <li>types</li> </ul> </li> <li>storage</li> <li>visualization<ul> <li>graph</li> </ul> </li> </ul> </li> <li>process_manager<ul> <li>data_handling<ul> <li>data_validator</li> <li>file_handler</li> </ul> </li> <li>examples<ul> <li>monte_carlo<ul> <li>caching</li> <li>monte_carlo_workflow</li> <li>progress</li> <li>simulation_parameters</li> <li>simulation_types</li> <li>validation</li> </ul> </li> <li>simple<ul> <li>v2</li> <li>v3</li> <li>v4</li> <li>v5</li> <li>v6</li> <li>v7</li> <li>v8</li> <li>v9</li> </ul> </li> </ul> </li> <li>workflow<ul> <li>core</li> <li>id_generator</li> <li>implementations</li> <li>mc</li> <li>process</li> <li>workflow_types</li> </ul> </li> </ul> </li> <li>results_manager<ul> <li>async_backends<ul> <li>base</li> <li>file_backend</li> <li>sqlite_backend</li> </ul> </li> <li>async_manager</li> <li>backends<ul> <li>base</li> <li>file_backend</li> <li>sqlite_backend</li> </ul> </li> <li>manager</li> <li>model_registry</li> </ul> </li> </ul>"},{"location":"reference/data_handlers/","title":"data_handlers","text":""},{"location":"reference/data_handlers/#data_handlers","title":"data_handlers","text":"<p>Data handlers for the process manager.</p>"},{"location":"reference/data_handlers/base/","title":"base","text":""},{"location":"reference/data_handlers/base/#data_handlers.base","title":"base","text":"<p>Base module for named objects and their collections. Provides common functionality for serialization and management of named objects.</p>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObject","title":"NamedObject","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for named objects with serialization support.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Name of object class type (computed field)</p> <code>name</code> <code>str</code> <p>Name of the object</p> Configuration <p>model_config (ConfigDict): Pydantic model configuration</p>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObject.type","title":"type  <code>property</code>","text":"<pre><code>type: str\n</code></pre> <p>Returns the name of the object type.</p>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObject.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(*, registry_category: str = None, **kwargs)\n</code></pre> <p>Register subclasses in appropriate registry category.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def __init_subclass__(cls, *, registry_category: str = None, **kwargs):\n    \"\"\"Register subclasses in appropriate registry category.\"\"\"\n    super().__init_subclass__(**kwargs)\n    if registry_category:\n        cls._registry_category = registry_category\n    ObjectRegistry.register(cls._registry_category, cls)\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectHash","title":"NamedObjectHash","text":"<p>               Bases: <code>BaseModel</code></p> <p>Dictionary of named objects with type checking and conflict prevention.</p> <p>Attributes:</p> Name Type Description <code>objects</code> <code>dict</code> <p>Dictionary of named objects</p>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectHash.deserialize_objects","title":"deserialize_objects  <code>classmethod</code>","text":"<pre><code>deserialize_objects(data: Any) -&gt; Any\n</code></pre> <p>Deserialize objects during validation.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>@model_validator(mode='before')\n@classmethod\ndef deserialize_objects(cls, data: Any) -&gt; Any:\n    \"\"\"Deserialize objects during validation.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    objects = data.get('objects', {})\n    if isinstance(objects, dict):\n        for name, obj_data in objects.items():\n            if isinstance(obj_data, dict):\n                type_name = obj_data.get('type')\n                if type_name:\n                    # Remove type as it's not part of the constructor\n                    obj_data = obj_data.copy()\n                    obj_data.pop('type')\n                    obj_type = ObjectRegistry.get(cls._registry_category, type_name)\n                    data['objects'][name] = obj_type(**obj_data)\n    return data\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectHash.get_object","title":"get_object","text":"<pre><code>get_object(name: str) -&gt; NamedObject\n</code></pre> <p>Get object by name.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def get_object(self, name: str) -&gt; NamedObject:\n    \"\"\"Get object by name.\"\"\"\n    return self.objects[name]\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectHash.get_object_names","title":"get_object_names","text":"<pre><code>get_object_names() -&gt; Iterable[str]\n</code></pre> <p>Get names of all objects.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def get_object_names(self) -&gt; Iterable[str]:\n    \"\"\"Get names of all objects.\"\"\"\n    return self.objects.keys()\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectHash.get_objects","title":"get_objects","text":"<pre><code>get_objects() -&gt; Iterable[NamedObject]\n</code></pre> <p>Get all objects.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def get_objects(self) -&gt; Iterable[NamedObject]:\n    \"\"\"Get all objects.\"\"\"\n    return self.objects.values()\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectHash.register_object","title":"register_object","text":"<pre><code>register_object(obj: NamedObject) -&gt; Self\n</code></pre> <p>Register a named object. Checks for naming conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>NamedObject</code> <p>Object to register</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If object with same name exists</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def register_object(self, obj: NamedObject) -&gt; Self:\n    \"\"\"\n    Register a named object. Checks for naming conflicts.\n\n    Args:\n        obj (NamedObject): Object to register\n\n    Raises:\n        ValueError: If object with same name exists\n    \"\"\"\n    if obj.name in self.objects:\n        raise ValueError(\n            f\"Naming conflict: An object named '{obj.name}' already exists.\"\n            f\"\\n\\tExisting: \\n{self.get_object(obj.name).model_dump_json(indent=4)}\"\n            f\"\\n\\tNew: \\n{obj.model_dump_json(indent=4)}\"\n        )\n    self.objects[obj.name] = obj\n    return self\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList","title":"NamedObjectList","text":"<p>               Bases: <code>BaseModel</code></p> <p>List of named objects with type checking.</p> <p>Attributes:</p> Name Type Description <code>objects</code> <code>list</code> <p>List of named objects</p> Example <pre><code>obj_list = NamedObjectList()\nobj_list.append(named_object)\nobj_list.extend([obj1, obj2, obj3])\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; NamedObject\n</code></pre> <p>Get object by index.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; NamedObject:\n    \"\"\"Get object by index.\"\"\"\n    return self.objects[idx]\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterable[NamedObject]\n</code></pre> <p>Iterate over objects in list.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def __iter__(self) -&gt; Iterable[NamedObject]:\n    \"\"\"Iterate over objects in list.\"\"\"\n    return iter(self.objects)\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return number of objects in list.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of objects in list.\"\"\"\n    return len(self.objects)\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.append","title":"append","text":"<pre><code>append(obj: NamedObject) -&gt; Self\n</code></pre> <p>Append a single object to the list.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>NamedObject</code> <p>Object to append</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>Returns self for chaining</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def append(self, obj: NamedObject) -&gt; Self:\n    \"\"\"\n    Append a single object to the list.\n\n    Args:\n        obj (NamedObject): Object to append\n\n    Returns:\n        Self: Returns self for chaining\n    \"\"\"\n    self.objects.append(obj)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.extend","title":"extend","text":"<pre><code>extend(objects: Iterable[NamedObject]) -&gt; Self\n</code></pre> <p>Extend list with multiple objects.</p> <p>Parameters:</p> Name Type Description Default <code>objects</code> <code>Iterable[NamedObject]</code> <p>Objects to add</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>Returns self for chaining</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>def extend(self, objects: Iterable[NamedObject]) -&gt; Self:\n    \"\"\"\n    Extend list with multiple objects.\n\n    Args:\n        objects (Iterable[NamedObject]): Objects to add\n\n    Returns:\n        Self: Returns self for chaining\n    \"\"\"\n    self.objects.extend(objects)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.from_iterable","title":"from_iterable  <code>classmethod</code>","text":"<pre><code>from_iterable(iterable: Iterable[NamedObject]) -&gt; Self\n</code></pre> <p>Create instance from an iterable of named objects.</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable[NamedObject]</code> <p>Objects to add to list</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>New instance containing the objects</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>@classmethod\ndef from_iterable(cls, iterable: Iterable[NamedObject]) -&gt; Self:\n    \"\"\"\n    Create instance from an iterable of named objects.\n\n    Args:\n        iterable (Iterable[NamedObject]): Objects to add to list\n\n    Returns:\n        Self: New instance containing the objects\n    \"\"\"\n    return cls(objects=list(iterable))\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.get_object","title":"get_object","text":"<pre><code>get_object(name: str) -&gt; NamedObject\n</code></pre> <p>Get a registered object by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the object to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedObject</code> <code>NamedObject</code> <p>The requested object</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no object exists with the given name</p> Example <pre><code>obj_list = NamedObjectList()\nobj_list.append(NamedObject(\"x\"))\nx = obj_list.get_object(\"x\")\n</code></pre> Source code in <code>src/data_handlers/base.py</code> <pre><code>def get_object(self, name: str) -&gt; NamedObject:\n    \"\"\"\n    Get a registered object by name.\n\n    Args:\n        name (str): Name of the object to retrieve\n\n    Returns:\n        NamedObject: The requested object\n\n    Raises:\n        KeyError: If no object exists with the given name\n\n    Example:\n        ```python\n        obj_list = NamedObjectList()\n        obj_list.append(NamedObject(\"x\"))\n        x = obj_list.get_object(\"x\")\n        ```\n    \"\"\"\n    for obj in self.objects:\n        if obj.name == name:\n            return obj\n    raise KeyError(f\"No object found with name '{name}'\")\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.get_objects","title":"get_objects","text":"<pre><code>get_objects() -&gt; Iterable[NamedObject]\n</code></pre> <p>Get all registered objects.</p> <p>Returns:</p> Type Description <code>Iterable[NamedObject]</code> <p>Iterable[NamedObject]: Iterator over all stored objects</p> Example <pre><code>obj_list = NamedObjectList()\nobj_list.extend([NamedObject(\"x\"), NamedObject(\"y\")])\nfor obj in obj_list.get_objects():\n    print(obj.name)\n</code></pre> Source code in <code>src/data_handlers/base.py</code> <pre><code>def get_objects(self) -&gt; Iterable[NamedObject]:\n    \"\"\"\n    Get all registered objects.\n\n    Returns:\n        Iterable[NamedObject]: Iterator over all stored objects\n\n    Example:\n        ```python\n        obj_list = NamedObjectList()\n        obj_list.extend([NamedObject(\"x\"), NamedObject(\"y\")])\n        for obj in obj_list.get_objects():\n            print(obj.name)\n        ```\n    \"\"\"\n    return iter(self.objects)\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.NamedObjectList.register_object","title":"register_object","text":"<pre><code>register_object(obj: NamedObject) -&gt; Self\n</code></pre> <p>Register a named object to the list with duplicate name checking.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>NamedObject</code> <p>Object to register</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>Returns self for method chaining</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an object with the same name already exists</p> Example <pre><code>obj_list = NamedObjectList()\nobj_list.register_object(NamedObject(\"x\"))\n</code></pre> Source code in <code>src/data_handlers/base.py</code> <pre><code>def register_object(self, obj: NamedObject) -&gt; Self:\n    \"\"\"\n    Register a named object to the list with duplicate name checking.\n\n    Args:\n        obj (NamedObject): Object to register\n\n    Returns:\n        Self: Returns self for method chaining\n\n    Raises:\n        ValueError: If an object with the same name already exists\n\n    Example:\n        ```python\n        obj_list = NamedObjectList()\n        obj_list.register_object(NamedObject(\"x\"))\n        ```\n    \"\"\"\n    # Check for duplicates\n    for existing_obj in self.objects:\n        if existing_obj.name == obj.name:\n            raise ValueError(\n                f\"Naming conflict: An object named '{obj.name}' already exists.\\n\"\n                f\"\\tExisting: \\n{existing_obj.model_dump_json(indent=4)}\\n\"\n                f\"\\tNew: \\n{obj.model_dump_json(indent=4)}\"\n            )\n    self.objects.append(obj)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.ObjectRegistry","title":"ObjectRegistry","text":"<p>Generic registry for named object types.</p> <p>Stores object types for deserialization from JSON files. Types are stored at the class level for consistent access across modules.</p> <p>Types are stored at the class level for consistent access across modules.</p> <p>Methods:</p> Name Description <code>register</code> <p>Register an object type</p> <code>get</code> <p>Get an object type by name</p> <code>get_all</code> <p>Get all registered object types</p>"},{"location":"reference/data_handlers/base/#data_handlers.base.ObjectRegistry.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(category: str, name: str) -&gt; Type[NamedObject]\n</code></pre> <p>Get an object type by category and name.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>@classmethod\ndef get(cls, category: str, name: str) -&gt; Type[NamedObject]:\n    \"\"\"Get an object type by category and name.\"\"\"\n    registry = cls.get_registry(category)\n    if name not in registry:\n        raise ValueError(f\"{name} not found in {category} registry\")\n    return registry[name]\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.ObjectRegistry.get_all","title":"get_all  <code>classmethod</code>","text":"<pre><code>get_all(category: str) -&gt; list[Type[NamedObject]]\n</code></pre> <p>Get all registered types for a category.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>@classmethod\ndef get_all(cls, category: str) -&gt; list[Type[NamedObject]]:\n    \"\"\"Get all registered types for a category.\"\"\"\n    return list(cls.get_registry(category).values())\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.ObjectRegistry.get_registry","title":"get_registry  <code>classmethod</code>","text":"<pre><code>get_registry(category: str) -&gt; Dict[str, Type[NamedObject]]\n</code></pre> <p>Get or create registry for a category.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>@classmethod\ndef get_registry(cls, category: str) -&gt; Dict[str, Type[NamedObject]]:\n    \"\"\"Get or create registry for a category.\"\"\"\n    # Get the actual string value if it's a PrivateAttr\n    if hasattr(category, 'default'):\n        category = category.default\n    if category not in cls._registries:\n        cls._registries[category] = {}\n    return cls._registries[category]\n</code></pre>"},{"location":"reference/data_handlers/base/#data_handlers.base.ObjectRegistry.register","title":"register  <code>classmethod</code>","text":"<pre><code>register(category: str, obj_type: Type[NamedObject]) -&gt; None\n</code></pre> <p>Register an object type in its category.</p> Source code in <code>src/data_handlers/base.py</code> <pre><code>@classmethod\ndef register(cls, category: str, obj_type: Type[NamedObject]) -&gt; None:\n    \"\"\"Register an object type in its category.\"\"\"\n    # Get the actual string value if it's a PrivateAttr\n    if hasattr(category, 'default'):\n        category = category.default\n    registry = cls.get_registry(category)\n    registry[obj_type.__name__] = obj_type\n</code></pre>"},{"location":"reference/data_handlers/mixins/","title":"mixins","text":""},{"location":"reference/data_handlers/mixins/#data_handlers.mixins","title":"mixins","text":"<p>Defines inputs</p>"},{"location":"reference/data_handlers/mixins/#data_handlers.mixins.ArrayDunders","title":"ArrayDunders","text":"<p>               Bases: <code>NumericDunders</code></p> <p>A mixin class that extends NumericDunders with additional array-like behavior.</p>"},{"location":"reference/data_handlers/mixins/#data_handlers.mixins.NumericDunders","title":"NumericDunders","text":"<p>A mixin class containing numeric dunder methods that can be applied to any class via composition</p> <p>Attributes:</p> Name Type Description <code>RESERVED_NAME</code> <code>str</code> <p>Name of the reserved attribute that holds the value</p>"},{"location":"reference/data_handlers/mixins/#data_handlers.mixins.NumericDunders.get_value","title":"get_value  <code>classmethod</code>","text":"<pre><code>get_value(instance)\n</code></pre> <p>Get the value of the instance</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Any</code> <p>Instance of the class</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Value of the instance stored in the reserved attribute or else returns the instance. For example, if the reserved attribute is 'value', then it returns <code>instance.value</code> else if the instance is just a float or an int or something like that, then it returns the instance itself.</p> Source code in <code>src/data_handlers/mixins.py</code> <pre><code>@classmethod\ndef get_value(cls, instance):\n    \"\"\"\n    Get the value of the instance\n\n    Args:\n        instance (Any): Instance of the class\n\n    Returns:\n        Any: Value of the instance stored in the reserved attribute or else returns the instance.\n            For example, if the reserved attribute is 'value', then it returns `instance.value` else\n            if the instance is just a float or an int or something like that, then it returns the instance itself.\n    \"\"\"\n    return getattr(instance, cls.RESERVED_NAME, instance)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/","title":"random_variables","text":""},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables","title":"random_variables","text":"<p>Random Variable Implementations for Process Analysis.</p> <p>This module provides a framework for working with random variables and probability distributions in a type-safe, numerically stable way. It includes implementations of common distributions (Normal, Uniform, Categorical) and infrastructure for managing collections of random variables.</p> <p>The module uses a metaclass-based approach to ensure consistent handling of array dimensions across all distributions, making it easy to work with both scalar and vector-valued random variables.</p> Key Features <ul> <li>Type-safe implementations of common probability distributions</li> <li>Automatic dimension handling via the squeezable decorator</li> <li>Support for reproducible sampling via seed management</li> <li>Collections for managing groups of random variables</li> <li>Serialization support via pydantic</li> </ul>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.CategoricalDistribution","title":"CategoricalDistribution","text":"<p>               Bases: <code>RandomVariable[T]</code></p> <p>Categorical distribution for discrete outcomes with specified probabilities.</p> <p>A categorical distribution (also called a discrete distribution) describes the probability of obtaining one of k possible outcomes. Each outcome has a probability between 0 and 1, and all probabilities must sum to 1.</p> <p>If probabilities are not specified, defaults to equal probabilities for all categories (uniform discrete distribution).</p> Key Properties <ul> <li>Support is finite set of categories</li> <li>PMF gives probability of each category</li> <li>CDF is step function</li> </ul> <p>Attributes:</p> Name Type Description <code>categories</code> <code>ndarray</code> <p>Array of possible outcomes (any type)</p> <code>probabilities</code> <code>ndarray</code> <p>Probability for each category</p> <code>name</code> <code>str</code> <p>Identifier for this distribution instance</p> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducible sampling</p> <code>replace</code> <code>bool</code> <p>Whether or not to allow multiple draws of the same value (allowed if True)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If probabilities don't sum to 1</p> <code>ValueError</code> <p>If lengths of categories and probabilities don't match</p> <code>ValueError</code> <p>If any probability is negative</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.CategoricalDistribution.cdf","title":"cdf","text":"<pre><code>cdf(x: ndarray, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Evaluate the cumulative distribution function.</p> <p>For categorical distributions, this is a step function that increases at each category by that category's probability.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the CDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: CDF values at the input points</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def cdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Evaluate the cumulative distribution function.\n\n    For categorical distributions, this is a step function that\n    increases at each category by that category's probability.\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the CDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: CDF values at the input points\n    \"\"\"\n    return np.array([\n        np.sum(self.probabilities[self.categories &lt;= val])\n        for val in x\n    ])\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.CategoricalDistribution.pdf","title":"pdf","text":"<pre><code>pdf(x: ndarray, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Evaluate the probability mass function (PMF).</p> <p>For categorical distributions, this gives the probability of each category occurring.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the PMF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: Probability of each input value</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def pdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Evaluate the probability mass function (PMF).\n\n    For categorical distributions, this gives the probability of\n    each category occurring.\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the PMF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: Probability of each input value\n    \"\"\"\n    return np.array([\n        self.probabilities[self.categories == val].item()\n        if val in self.categories else 0.0\n        for val in x\n    ])\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.CategoricalDistribution.sample","title":"sample","text":"<pre><code>sample(size: int = 1, **kwargs) -&gt; NDArray[Any, T]\n</code></pre> <p>Generate random samples from the categorical distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of samples to generate. Defaults to 1.</p> <code>1</code> <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> Notes <p>The squeeze parameter is added automatically by the metaclass and does not appear in the function signature, but can be passed as a keyword argument.</p> <p>Returns:</p> Type Description <code>NDArray[Any, T]</code> <p>NDArray[Any,T]: Array of samples from the categories</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def sample(self, size: int = 1, **kwargs) -&gt; NDArray[Any,T]:\n    \"\"\"Generate random samples from the categorical distribution.\n\n    Args:\n        size (int, optional): Number of samples to generate. Defaults to 1.\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Notes:\n        The squeeze parameter is added automatically by the metaclass and does not appear\n        in the function signature, but can be passed as a keyword argument.\n\n    Returns:\n        NDArray[Any,T]: Array of samples from the categories\n    \"\"\"\n    rng = np.random.default_rng(self.seed)\n    return rng.choice(self.categories, size=size, p=self.probabilities, replace=self.replace)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.CategoricalDistribution.validate_and_set_probabilities","title":"validate_and_set_probabilities","text":"<pre><code>validate_and_set_probabilities() -&gt; CategoricalDistribution\n</code></pre> <p>Validate probability values and set defaults if needed.</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>@model_validator(mode='after')\ndef validate_and_set_probabilities(self) -&gt; CategoricalDistribution:\n    \"\"\"Validate probability values and set defaults if needed.\"\"\"\n    if self.probabilities is None:\n        n_categories = len(self.categories)\n        self.probabilities = np.ones(n_categories) / n_categories\n        return self\n\n    if len(self.categories) != len(self.probabilities):\n        raise ValueError(\n            f\"Number of categories ({len(self.categories)}) must match \"\n            f\"number of probabilities ({len(self.probabilities)})\"\n        )\n    if not np.all(self.probabilities &gt;= 0):\n        raise ValueError(\"All probabilities must be non-negative\")\n    if not np.isclose(np.sum(self.probabilities), 1.0):\n        raise ValueError(\"Probabilities must sum to 1\")\n    return self\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.NormalDistribution","title":"NormalDistribution","text":"<p>               Bases: <code>RandomVariable[float]</code></p> <p>Normal (Gaussian) distribution with mean \u03bc and standard deviation \u03c3.</p> <p>The normal distribution is a continuous probability distribution that is symmetric about its mean, showing the familiar bell-shaped curve.</p> Key Properties <ul> <li>Symmetric about the mean</li> <li>~68% of values lie within 1\u03c3 of \u03bc</li> <li>~95% lie within 2\u03c3 of \u03bc</li> <li>~99.7% lie within 3\u03c3 of \u03bc</li> </ul> <p>Attributes:</p> Name Type Description <code>mu</code> <code>float</code> <p>Mean (\u03bc) of the distribution</p> <code>sigma</code> <code>float</code> <p>Standard deviation (\u03c3) of the distribution</p> <code>name</code> <code>str</code> <p>Identifier for this distribution instance</p> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducible sampling</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.NormalDistribution.cdf","title":"cdf","text":"<pre><code>cdf(x: ndarray, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Evaluate the normal cumulative distribution function.</p> <p>The CDF is computed using the error function: F(x) = 1/2 * (1 + erf((x-\u03bc)/(\u03c3\u221a2)))</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the CDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: CDF values at the input points</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def cdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Evaluate the normal cumulative distribution function.\n\n    The CDF is computed using the error function:\n    F(x) = 1/2 * (1 + erf((x-\u03bc)/(\u03c3\u221a2)))\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the CDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: CDF values at the input points\n    \"\"\"\n    return 0.5 * (1 + sp.erf((x - self.mu)/(self.sigma * np.sqrt(2))))\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.NormalDistribution.pdf","title":"pdf","text":"<pre><code>pdf(x: ndarray, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Evaluate the normal probability density function.</p> <p>The PDF is given by: f(x) = 1/(\u03c3\u221a(2\u03c0)) * exp(-(x-\u03bc)\u00b2/(2\u03c3\u00b2))</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the PDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: PDF values at the input points</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def pdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Evaluate the normal probability density function.\n\n    The PDF is given by:\n    f(x) = 1/(\u03c3\u221a(2\u03c0)) * exp(-(x-\u03bc)\u00b2/(2\u03c3\u00b2))\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the PDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: PDF values at the input points\n    \"\"\"\n    return 1/(self.sigma * np.sqrt(2*np.pi)) * np.exp(-(x - self.mu)**2 / (2*self.sigma**2))\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.NormalDistribution.sample","title":"sample","text":"<pre><code>sample(size: int | tuple[int, ...] = 1, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Generate random samples from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int | tuple[int, ...]</code> <p>Number or shape of samples</p> <code>1</code> <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: Array of samples from N(\u03bc, \u03c3)</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def sample(self, size: int | tuple[int, ...] = 1, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Generate random samples from the normal distribution.\n\n    Args:\n        size (int | tuple[int, ...]): Number or shape of samples\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: Array of samples from N(\u03bc, \u03c3)\n    \"\"\"\n    rng = np.random.default_rng(self.seed)\n    return rng.normal(self.mu, self.sigma, size=size)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariable","title":"RandomVariable","text":"<p>               Bases: <code>NamedObject</code>, <code>Generic[T]</code></p> <p>Base class for random variables.</p> <p>This class provides a common interface for random variable implementations. Subclasses must implement sample(), pdf(), and cdf() methods. The metaclass ensures these methods support dimension control via the squeeze parameter.</p> <p>The class is generic over the type of values it produces (T), which must be a subtype of SerializableValue to ensure proper serialization behavior.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category name for object registration</p> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducible sampling</p> <code>name</code> <code>str</code> <p>Identifier for this random variable instance</p> Type Variables <p>T: The type of values produced by this random variable</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariable.cdf","title":"cdf","text":"<pre><code>cdf(x: ndarray, **kwargs) -&gt; NDArray[Any, T]\n</code></pre> <p>Evaluate cumulative distribution function at specified points.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the CDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, T]</code> <p>CDF values at the input points</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def cdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any, T]:\n    \"\"\"Evaluate cumulative distribution function at specified points.\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the CDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        (NDArray[Any, T]): CDF values at the input points\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariable.pdf","title":"pdf","text":"<pre><code>pdf(x: ndarray, **kwargs) -&gt; NDArray[Any, T]\n</code></pre> <p>Evaluate probability density function at specified points.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the PDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, T]</code> <p>PDF values at the input points</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def pdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any, T]:\n    \"\"\"Evaluate probability density function at specified points.\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the PDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        (NDArray[Any, T]): PDF values at the input points\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariable.register_to_hash","title":"register_to_hash","text":"<pre><code>register_to_hash(\n    var_hash: RandomVariableHash, size: int = 1, sample: bool = True, squeeze: bool = True\n) -&gt; NamedValue[T | NDArray[Any, T]]\n</code></pre> <p>Register this random variable to a hash and return sampled values.</p> <p>This is a convenience method for adding a random variable to a collection and immediately sampling from it.</p> <p>Parameters:</p> Name Type Description Default <code>var_hash</code> <code>RandomVariableHash</code> <p>Hash object to register to</p> required <code>size</code> <code>int</code> <p>Number of samples to generate</p> <code>1</code> <p>Returns:</p> Type Description <code>NamedValue[T | NDArray[Any, T]]</code> <p>Named value containing samples</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def register_to_hash(\n        self, \n        var_hash: RandomVariableHash, \n        size: int = 1, \n        sample: bool = True,\n        squeeze: bool = True,\n    ) -&gt; NamedValue[T|NDArray[Any,T]]:\n    \"\"\"Register this random variable to a hash and return sampled values.\n\n    This is a convenience method for adding a random variable to a collection\n    and immediately sampling from it.\n\n    Args:\n        var_hash (RandomVariableHash): Hash object to register to\n        size (int): Number of samples to generate\n\n    Returns:\n        (NamedValue[T|NDArray[Any,T]]): Named value containing samples\n    \"\"\"\n    return var_hash.register_variable(self, size=size, sample=sample, squeeze=squeeze)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariable.sample","title":"sample","text":"<pre><code>sample(size: int = 1, **kwargs) -&gt; NDArray[Any, T]\n</code></pre> <p>Generate random samples from the categorical distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of samples to generate. Defaults to 1.</p> <code>1</code> <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, T]</code> <p>Array of samples from the categories</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def sample(self, size: int = 1, **kwargs) -&gt; NDArray[Any, T]:\n    \"\"\"Generate random samples from the categorical distribution.\n\n    Args:\n        size (int): Number of samples to generate. Defaults to 1.\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        (NDArray[Any, T]): Array of samples from the categories\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableHash","title":"RandomVariableHash","text":"<p>               Bases: <code>NamedObjectHash</code></p> <p>Collection of random variables.</p> <p>This class manages a collection of RandomVariable objects, providing methods to register, retrieve and sample from multiple distributions.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category name for object registration</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableHash.get_variables","title":"get_variables","text":"<pre><code>get_variables() -&gt; Iterable[RandomVariable]\n</code></pre> <p>Get all registered random variables.</p> <p>Returns:</p> Type Description <code>Iterable[RandomVariable]</code> <p>Iterable[RandomVariable]: Iterator over all registered variables</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def get_variables(self) -&gt; Iterable[RandomVariable]:\n    \"\"\"Get all registered random variables.\n\n    Returns:\n        Iterable[RandomVariable]: Iterator over all registered variables\n    \"\"\"\n    return self.get_objects()\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableHash.register_variable","title":"register_variable","text":"<pre><code>register_variable(\n    var: RandomVariable, size: int = 1, sample: bool = True, squeeze: bool = True\n) -&gt; NamedValue[SerializableValue | NDArray[Any, SerializableValue]]\n</code></pre> <p>Register a random variable and return its samples wrapped in a NamedValue.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>RandomVariable</code> <p>Random variable to register</p> required <code>size</code> <code>int</code> <p>Number of samples to generate</p> <code>1</code> <p>Returns:</p> Type Description <code>NamedValue[SerializableValue | NDArray[Any, SerializableValue]]</code> <p>NamedValue[SerializableValue|NDArray[Any,SerializableValue]]: Named value containing samples</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a variable with the same name already exists</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def register_variable(\n        self, \n        var: RandomVariable, \n        size: int = 1,\n        sample: bool = True,\n        squeeze: bool = True,\n    ) -&gt; NamedValue[SerializableValue|NDArray[Any,SerializableValue]]:\n    \"\"\"Register a random variable and return its samples wrapped in a NamedValue.\n\n    Args:\n        var (RandomVariable): Random variable to register\n        size (int): Number of samples to generate\n\n    Returns:\n        NamedValue[SerializableValue|NDArray[Any,SerializableValue]]: Named value containing samples\n\n    Raises:\n        ValueError: If a variable with the same name already exists\n    \"\"\"\n    if var.name in self.objects:\n        raise ValueError(f\"A variable with name '{var.name}' already exists in the collection\")\n\n    self.register_object(var)\n    if sample:\n        samples = var.sample(size=size)\n        if squeeze:\n            return NamedValue(name=var.name, value=samples.squeeze())\n        else:\n            return NamedValue(name=var.name, value=samples)\n    else:\n        return None\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableHash.sample_all","title":"sample_all","text":"<pre><code>sample_all(size: int = 1) -&gt; dict[str, ndarray]\n</code></pre> <p>Sample from all registered distributions.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of samples to generate per distribution</p> <code>1</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>dict[str, np.ndarray]: Dictionary mapping variable names to their samples</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def sample_all(self, size: int = 1) -&gt; dict[str, np.ndarray]:\n    \"\"\"Sample from all registered distributions.\n\n    Args:\n        size (int): Number of samples to generate per distribution\n\n    Returns:\n        dict[str, np.ndarray]: Dictionary mapping variable names to their samples\n    \"\"\"\n    return {name: var.sample(size) for name, var in self.objects.items()}\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList","title":"RandomVariableList","text":"<p>               Bases: <code>NamedObjectList</code></p> <p>List of random variables.</p> <p>This class manages an ordered list of RandomVariable objects, providing methods to add, access, and sample from multiple distributions while maintaining their order.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category name for object registration</p> <code>objects</code> <code>List[SerializeAsAny[InstanceOf[RandomVariable]]]</code> <p>List of random variable objects</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; RandomVariable\n</code></pre> <p>Get a random variable by its index in the list.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the random variable to retrieve</p> required <p>Returns:</p> Name Type Description <code>RandomVariable</code> <code>RandomVariable</code> <p>The random variable at the specified index</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the index is out of range</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; RandomVariable:\n    \"\"\"Get a random variable by its index in the list.\n\n    Args:\n        idx (int): Index of the random variable to retrieve\n\n    Returns:\n        RandomVariable: The random variable at the specified index\n\n    Raises:\n        IndexError: If the index is out of range\n    \"\"\"\n    return super().__getitem__(idx)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.append","title":"append","text":"<pre><code>append(variable: RandomVariable) -&gt; Self\n</code></pre> <p>Append a random variable to the end of the list.</p> <p>Parameters:</p> Name Type Description Default <code>variable</code> <code>RandomVariable</code> <p>Random variable to append</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The RandomVariableList instance for method chaining</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def append(self, variable: RandomVariable) -&gt; Self:\n    \"\"\"Append a random variable to the end of the list.\n\n    Args:\n        variable (RandomVariable): Random variable to append\n\n    Returns:\n        Self: The RandomVariableList instance for method chaining\n    \"\"\"\n    return super().append(variable)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.extend","title":"extend","text":"<pre><code>extend(variables: Iterable[RandomVariable]) -&gt; Self\n</code></pre> <p>Extend the list with multiple random variables.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>Iterable[RandomVariable]</code> <p>Collection of random variables to add</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The RandomVariableList instance for method chaining</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def extend(self, variables: Iterable[RandomVariable]) -&gt; Self:\n    \"\"\"Extend the list with multiple random variables.\n\n    Args:\n        variables (Iterable[RandomVariable]): Collection of random variables to add\n\n    Returns:\n        Self: The RandomVariableList instance for method chaining\n    \"\"\"\n    return super().extend(variables)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.get_variable","title":"get_variable","text":"<pre><code>get_variable(name: str) -&gt; RandomVariable\n</code></pre> <p>Get a registered random variable by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the random variable</p> required <p>Returns:</p> Name Type Description <code>RandomVariable</code> <code>RandomVariable</code> <p>The requested random variable</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no variable exists with the given name</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def get_variable(self, name: str) -&gt; RandomVariable:\n    \"\"\"Get a registered random variable by name.\n\n    Args:\n        name (str): Name of the random variable\n\n    Returns:\n        RandomVariable: The requested random variable\n\n    Raises:\n        KeyError: If no variable exists with the given name\n    \"\"\"\n    return self.get_object(name)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.get_variables","title":"get_variables","text":"<pre><code>get_variables() -&gt; Iterable[RandomVariable]\n</code></pre> <p>Get all registered random variables.</p> <p>Returns:</p> Type Description <code>Iterable[RandomVariable]</code> <p>Iterable[RandomVariable]: Iterator over all registered variables</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def get_variables(self) -&gt; Iterable[RandomVariable]:\n    \"\"\"Get all registered random variables.\n\n    Returns:\n        Iterable[RandomVariable]: Iterator over all registered variables\n    \"\"\"\n    return self.get_objects()\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.register_variable","title":"register_variable","text":"<pre><code>register_variable(var: RandomVariable) -&gt; Self\n</code></pre> <p>Register a random variable to the collection.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>RandomVariable</code> <p>Random variable to register</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The RandomVariableList instance</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def register_variable(self, var: RandomVariable) -&gt; Self:\n    \"\"\"Register a random variable to the collection.\n\n    Args:\n        var (RandomVariable): Random variable to register\n\n    Returns:\n        Self: The RandomVariableList instance\n    \"\"\"\n    return self.register_object(var)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableList.sample_all","title":"sample_all","text":"<pre><code>sample_all(size: int = 1) -&gt; dict[str, ndarray]\n</code></pre> <p>Sample from all variables in the list.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of samples to generate per variable</p> <code>1</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>dict[str, np.ndarray]: Dictionary mapping variable names to their samples</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def sample_all(self, size: int = 1) -&gt; dict[str, np.ndarray]:\n    \"\"\"Sample from all variables in the list.\n\n    Args:\n        size (int): Number of samples to generate per variable\n\n    Returns:\n        dict[str, np.ndarray]: Dictionary mapping variable names to their samples\n    \"\"\"\n    return {var.name: var.sample(size) for var in self.objects}\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.RandomVariableMeta","title":"RandomVariableMeta","text":"<p>               Bases: <code>type(BaseModel)</code></p> <p>Metaclass for random variable implementations that automatically adds array handling functionality.</p> <p>This metaclass inherits from pydantic's model metaclass to maintain compatibility with the  BaseModel validation system while adding automatic array handling capabilities to all random  variable implementations.</p> Key Features <ul> <li>Automatically applies the <code>squeezable</code> decorator to sample(), pdf(), and cdf() methods</li> <li>Maintains compatibility with pydantic's model validation system</li> <li>Ensures consistent array handling across all random variable implementations</li> </ul> The metaclass processes each new random variable class during its creation by <ol> <li>Identifying the standard distribution methods (sample, pdf, cdf)</li> <li>If these methods are defined in the class (not inherited), wrapping them with    the squeezable decorator</li> <li>Preserving the original method docstrings while adding squeeze parameter documentation</li> </ol> Example <pre><code>class NormalDistribution(RandomVariable[float]):\n    def sample(self, size: int = 1) -&gt; NDArray[Any, float]:\n        # Method will automatically get squeeze functionality\n        # and accept an optional `bool` defaulting to `squeeze=True`\n        return rng.normal(self.mu, self.sigma, size=size)\n</code></pre> Technical Details <ul> <li>Inherits from type(BaseModel) to maintain pydantic compatibility</li> <li>Uses new to modify class attributes during class creation</li> <li>Preserves method signatures while adding the squeeze parameter</li> <li>Ensures proper type hints and docstring updates</li> </ul> Notes <ul> <li>The squeezable decorator adds a <code>squeeze</code> parameter to wrapped methods</li> <li>When squeeze=True (default), output arrays are squeezed and 0-d arrays   are converted to scalar values</li> <li>Original method behavior is preserved when squeeze=False</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mcs</code> <p>The metaclass instance</p> required <code>name</code> <code>str</code> <p>Name of the class being created</p> required <code>bases</code> <code>tuple</code> <p>Base classes</p> required <code>namespace</code> <code>dict</code> <p>Class namespace dictionary</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to type(BaseModel)</p> required <p>Returns:</p> Type Description <code>type</code> <p>The created class with enhanced array handling capabilities</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.UniformDistribution","title":"UniformDistribution","text":"<p>               Bases: <code>RandomVariable[float]</code></p> <p>Continuous uniform distribution over an interval [low, high].</p> <p>The uniform distribution describes equal probability over a continuous interval. Any value between low and high is equally likely to be drawn.</p> Key Properties <ul> <li>Mean = (low + high)/2</li> <li>Variance = (high - low)\u00b2/12</li> <li>Constant PDF over [low, high]</li> <li>Linear CDF over [low, high]</li> </ul> <p>Attributes:</p> Name Type Description <code>low</code> <code>float</code> <p>Lower bound of the interval</p> <code>high</code> <code>float</code> <p>Upper bound of the interval</p> <code>name</code> <code>str</code> <p>Identifier for this distribution instance</p> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducible sampling</p>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.UniformDistribution.cdf","title":"cdf","text":"<pre><code>cdf(x: ndarray, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Evaluate the uniform cumulative distribution function.</p> <p>The CDF is: - 0 for x &lt; low - (x-low)/(high-low) for low \u2264 x \u2264 high - 1 for x &gt; high</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the CDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: CDF values at the input points</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def cdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Evaluate the uniform cumulative distribution function.\n\n    The CDF is:\n    - 0 for x &lt; low\n    - (x-low)/(high-low) for low \u2264 x \u2264 high\n    - 1 for x &gt; high\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the CDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: CDF values at the input points\n    \"\"\"\n    return np.where(\n        x &lt; self.low,\n        0.0,\n        np.where(\n            x &gt; self.high,\n            1.0,\n            (x - self.low) / (self.high - self.low)\n        )\n    )\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.UniformDistribution.pdf","title":"pdf","text":"<pre><code>pdf(x: ndarray, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Evaluate the uniform probability density function.</p> <p>The PDF is 1/(high-low) for x in [low,high] and 0 elsewhere.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Points at which to evaluate the PDF</p> required <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: PDF values at the input points</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def pdf(self, x: np.ndarray, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Evaluate the uniform probability density function.\n\n    The PDF is 1/(high-low) for x in [low,high] and 0 elsewhere.\n\n    Args:\n        x (np.ndarray): Points at which to evaluate the PDF\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: PDF values at the input points\n    \"\"\"\n    return np.where(\n        (x &gt;= self.low) &amp; (x &lt;= self.high),\n        1.0 / (self.high - self.low),\n        0.0\n    )\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.UniformDistribution.sample","title":"sample","text":"<pre><code>sample(size: int = 1, **kwargs) -&gt; NDArray[Any, float]\n</code></pre> <p>Generate random samples from the uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of samples to generate</p> <code>1</code> <p>Other Parameters:</p> Name Type Description <code>squeeze</code> <code>bool</code> <p>Whether to remove unnecessary dimensions. Added by RandomVariableMeta. Defaults is <code>True</code>.</p> <p>Returns:</p> Type Description <code>NDArray[Any, float]</code> <p>NDArray[Any,float]: Array of samples from U(low,high)</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def sample(self, size: int = 1, **kwargs) -&gt; NDArray[Any,float]:\n    \"\"\"Generate random samples from the uniform distribution.\n\n    Args:\n        size (int): Number of samples to generate\n\n    Other Parameters:\n        squeeze (bool, optional): Whether to remove unnecessary dimensions.\n            Added by RandomVariableMeta. Defaults is `True`.\n\n    Returns:\n        NDArray[Any,float]: Array of samples from U(low,high)\n    \"\"\"\n    rng = np.random.default_rng(self.seed)\n    return rng.uniform(self.low, self.high, size=size)\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.UniformDistribution.validate_bounds","title":"validate_bounds","text":"<pre><code>validate_bounds() -&gt; UniformDistribution\n</code></pre> <p>Validate that high &gt; low.</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>@model_validator(mode='after')\ndef validate_bounds(self) -&gt; UniformDistribution:\n    \"\"\"Validate that high &gt; low.\"\"\"\n    if self.high &lt;= self.low:\n        raise ValueError(f\"Upper bound ({self.high}) must be greater than lower bound ({self.low})\")\n    return self\n</code></pre>"},{"location":"reference/data_handlers/random_variables/#data_handlers.random_variables.squeezable","title":"squeezable","text":"<pre><code>squeezable(func: Callable[P, R], squeeze_by_default: bool = False) -&gt; Callable[P, R]\n</code></pre> <p>Decorator that makes a function's output array squeezable via an added keyword argument <code>squeeze</code>.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[P, R]</code> <p>The function to be decorated.</p> required <code>squeeze_by_default</code> <code>bool</code> <p>Whether or not to squeeze by default</p> <code>False</code> <p>Returns:</p> Type Description <code>Callable[P, R]</code> <p>A new function that  squeezes the output of <code>func</code> if added keyword <code>squeeze</code> is True (default)</p> Source code in <code>src/data_handlers/random_variables.py</code> <pre><code>def squeezable(func: Callable[P, R], squeeze_by_default: bool = False) -&gt; Callable[P, R]:\n    \"\"\"\n    Decorator that makes a function's output array squeezable\n    via an added keyword argument `squeeze`.\n\n    Args:\n        func (Callable[P, R]): The function to be decorated.\n        squeeze_by_default (bool): Whether or not to squeeze by default\n\n    Returns:\n        (Callable[P, R]): A new function that \n            squeezes the output of `func` if added keyword `squeeze` is True (default)\n    \"\"\"\n    # Get the original signature\n    sig = inspect.signature(func)\n\n    # Create new parameters list with correct ordering\n    parameters = []\n    has_var_kwargs = False\n\n    # First add all non-variadic parameters\n    for param in sig.parameters.values():\n        if param.kind != Parameter.VAR_KEYWORD:\n            parameters.append(param)\n        else:\n            has_var_kwargs = True\n\n    # Add squeeze parameter as keyword-only\n    parameters.append(\n        Parameter(\n            'squeeze',\n            Parameter.KEYWORD_ONLY,\n            default=squeeze_by_default,\n            annotation=bool\n        )\n    )\n\n    # Add var_kwargs at the end if it exists\n    if has_var_kwargs:\n        parameters.append(\n            Parameter(\n                'kwargs',\n                Parameter.VAR_KEYWORD\n            )\n        )\n\n    # Create new signature\n    new_sig = sig.replace(parameters=parameters)\n\n    @wraps(func)\n    def wrapper(*args: P.args, squeeze: bool = squeeze_by_default, **kwargs: P.kwargs) -&gt; R:\n        result = func(*args, **kwargs)\n        if squeeze:\n            result = result.squeeze()\n            if isinstance(result, np.ndarray) and result.ndim == 0:\n                result = result.item()\n        return result\n\n    # Update the wrapper's signature\n    wrapper.__signature__ = new_sig\n    return wrapper\n</code></pre>"},{"location":"reference/data_handlers/values/","title":"values","text":""},{"location":"reference/data_handlers/values/#data_handlers.values","title":"values","text":"<p>Module for generating, sorting, and managing named values. This uses pydantic dataclasses for JSON serialization to avoid overloading system memory.</p> <p>The module provides a robust framework for managing named values with type safety, serialization, and state management. It includes classes for individual named values, collections of named values in both list and hash (dictionary) formats, and utilities for type validation and serialization.</p> <p>Classes:</p> Name Description <code>NamedValueState</code> <p>Enum for tracking the state of named values</p> <code>NamedValue</code> <p>Base class for type-safe named values with state management</p> <code>NamedValueHash</code> <p>Dictionary-like container for managing named values</p> <code>NamedValueList</code> <p>List-like container for managing ordered named values</p> Types <p>SerializableValue: Union type defining all allowed value types T: Generic type variable bound to SerializableValue</p>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue","title":"NamedValue","text":"<pre><code>NamedValue(name: str, value: T | None = None, **data)\n</code></pre> <p>               Bases: <code>NamedObject</code>, <code>Generic[T]</code></p> <p>A named value container with type safety and state management.</p> <p>NamedValue provides a type-safe way to store and manage values with built-in state tracking, serialization, and validation. Values can be frozen after initial setting to prevent accidental modification.</p> Type Parameters <p>T: The type of value to store, must be a SerializableValue</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for the value</p> <code>_stored_value</code> <code>T | NamedValueState</code> <p>The actual stored value or UNSET state</p> <code>_state</code> <code>NamedValueState</code> <p>Current state of the value</p> <code>_type</code> <code>type</code> <p>Runtime type information for validation</p> Properties <p>value (T): Access or modify the stored value</p> Example <pre><code># Create a named integer value\ncount = NamedValue[int](\"item_count\")\ncount.value = 42  # Sets and freezes the value\nprint(count.value)  # Outputs: 42\ncount.value = 50  # Raises ValueError - value is frozen\ncount.force_set_value(50)  # Allows value change\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def __init__(self, name: str, value: T | None = None, **data):\n    # print(f\"Initializing NamedValue with class: {self.__class__}\")\n    # print(f\"Class __args__: {getattr(self.__class__, '__args__', None)}\")\n    # print(f\"Bases: {self.__class__.__bases__}\")\n    # for base in self.__class__.__bases__:\n    #     print(f\"Base __args__: {getattr(base, '__args__', None)}\")\n\n    data.pop('stored_value', None)\n    data.pop('_stored_value', None)\n\n    super().__init__(name=name, **data)\n    self._type = self._extract_value_type()\n    # print(f\"Extracted type: {self._type}\")\n    object.__setattr__(self, '_stored_value', NamedValueState.UNSET)\n\n    if value is not None:\n        self.value = value\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.value","title":"value  <code>property</code> <code>writable</code>","text":"<pre><code>value: T\n</code></pre> <p>Get the stored value.</p> <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The currently stored value</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If attempting to access before a value has been set</p> Note <p>This property provides read access to the stored value. Once set, the value is frozen and can only be changed using force_set_value().</p>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name: str, value: Any) -&gt; None\n</code></pre> <p>Prevent direct modification of protected attributes.</p> <p>Overrides attribute setting to prevent direct modification of internal state attributes. These attributes should only be modified through appropriate methods.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to set</p> required <code>value</code> <code>Any</code> <p>Value to set</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If attempting to modify protected attributes directly</p> Example <pre><code>value = NamedValue(\"example\")\nvalue._stored_value = 42  # Raises AttributeError\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"\n    Prevent direct modification of protected attributes.\n\n    Overrides attribute setting to prevent direct modification of internal\n    state attributes. These attributes should only be modified through\n    appropriate methods.\n\n    Args:\n        name (str): Name of the attribute to set\n        value (Any): Value to set\n\n    Raises:\n        AttributeError: If attempting to modify protected attributes directly\n\n    Example:\n        ```python\n        value = NamedValue(\"example\")\n        value._stored_value = 42  # Raises AttributeError\n        ```\n    \"\"\"\n    if name in ('_stored_value', '_state'):\n        raise AttributeError(f\"Cannot modify {name} directly. Use appropriate methods instead.\")\n    super().__setattr__(name, value)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.append_to_value_list","title":"append_to_value_list","text":"<pre><code>append_to_value_list(l: NamedValueList) -&gt; Self\n</code></pre> <p>Appends this value instance to a NamedValueList.</p> <p>Convenience method for adding this value to a list while enabling method chaining.</p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>NamedValueList</code> <p>The list to append this value to</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>This instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nvalue = NamedValue(\"example\", 42)\nvalue.append_to_value_list(value_list).force_set_value(43)\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def append_to_value_list(self, l: NamedValueList) -&gt; Self:\n    \"\"\"\n    Appends this value instance to a NamedValueList.\n\n    Convenience method for adding this value to a list while enabling\n    method chaining.\n\n    Args:\n        l (NamedValueList): The list to append this value to\n\n    Returns:\n        Self: This instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value = NamedValue(\"example\", 42)\n        value.append_to_value_list(value_list).force_set_value(43)\n        ```\n    \"\"\"\n    l.append(self)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.force_set_value","title":"force_set_value","text":"<pre><code>force_set_value(new_value: T) -&gt; None\n</code></pre> <p>Force set the value regardless of its current state.</p> <p>This method bypasses the normal freezing mechanism and allows changing an already-set value.</p> <p>Parameters:</p> Name Type Description Default <code>new_value</code> <code>T</code> <p>New value to store</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If value doesn't match the expected type T</p> Source code in <code>src/data_handlers/values.py</code> <pre><code>def force_set_value(self, new_value: T) -&gt; None:\n    \"\"\"\n    Force set the value regardless of its current state.\n\n    This method bypasses the normal freezing mechanism and allows\n    changing an already-set value.\n\n    Args:\n        new_value (T): New value to store\n\n    Raises:\n        TypeError: If value doesn't match the expected type T\n    \"\"\"\n    object.__setattr__(self, '_stored_value', NamedValueState.UNSET)\n    object.__setattr__(self, '_state', NamedValueState.UNSET)\n\n    # if new_value == 'not a series':\n    #     breakpoint()\n    self.value = new_value\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.model_dump","title":"model_dump","text":"<pre><code>model_dump(**kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Custom serialization to include value state and stored value.</p> <p>Extends the parent class serialization to include the value's state and stored value (if set) in the serialized data.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to parent serialization</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing serialized state</p> Example <pre><code>value = NamedValue(\"example\", 42)\ndata = value.model_dump()\nprint(data)  # Contains 'state' and 'stored_value'\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom serialization to include value state and stored value.\n\n    Extends the parent class serialization to include the value's state\n    and stored value (if set) in the serialized data.\n\n    Args:\n        **kwargs: Additional arguments passed to parent serialization\n\n    Returns:\n        dict[str, Any]: Dictionary containing serialized state\n\n    Example:\n        ```python\n        value = NamedValue(\"example\", 42)\n        data = value.model_dump()\n        print(data)  # Contains 'state' and 'stored_value'\n        ```\n    \"\"\"\n    data = super().model_dump(**kwargs)\n    data['state'] = self._state\n    if self._state == NamedValueState.SET:\n        data['stored_value'] = self._stored_value\n    return data\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(**kwargs) -&gt; str\n</code></pre> <p>Custom JSON serialization of the named value.</p> <p>Serializes the named value instance to a JSON string, including all state information and stored value.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>JSON serialization options like indent, ensure_ascii, etc.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation</p> Example <pre><code>value = NamedValue(\"example\", 42)\njson_str = value.model_dump_json(indent=2)\nprint(json_str)  # Pretty-printed JSON\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def model_dump_json(self, **kwargs) -&gt; str:\n    \"\"\"\n    Custom JSON serialization of the named value.\n\n    Serializes the named value instance to a JSON string, including\n    all state information and stored value.\n\n    Args:\n        **kwargs: JSON serialization options like indent, ensure_ascii, etc.\n\n    Returns:\n        str: JSON string representation\n\n    Example:\n        ```python\n        value = NamedValue(\"example\", 42)\n        json_str = value.model_dump_json(indent=2)\n        print(json_str)  # Pretty-printed JSON\n        ```\n    \"\"\"\n    # Separate JSON-specific kwargs from model_dump kwargs\n    json_kwargs = {k: v for k, v in kwargs.items() if k in {'indent', 'ensure_ascii', 'separators'}}\n    dump_kwargs = {k: v for k, v in kwargs.items() if k not in json_kwargs}\n\n    # Get model data with stored value\n    data = self.model_dump(**dump_kwargs)\n    return json.dumps(data, **json_kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(data: Any) -&gt; NamedValue\n</code></pre> <p>Custom deserialization to restore value state and stored value.</p> <p>Reconstructs a NamedValue instance from serialized data, properly restoring both the value state and any stored value.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Serialized data to deserialize</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>New instance with restored state</p> Example <pre><code>data = {'name': 'example', 'state': 'set', 'stored_value': 42}\nvalue = NamedValue.model_validate(data)\nprint(value.value)  # Outputs: 42\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>@classmethod\ndef model_validate(cls, data: Any) -&gt; NamedValue:\n    \"\"\"\n    Custom deserialization to restore value state and stored value.\n\n    Reconstructs a NamedValue instance from serialized data, properly\n    restoring both the value state and any stored value.\n\n    Args:\n        data (Any): Serialized data to deserialize\n\n    Returns:\n        NamedValue: New instance with restored state\n\n    Example:\n        ```python\n        data = {'name': 'example', 'state': 'set', 'stored_value': 42}\n        value = NamedValue.model_validate(data)\n        print(value.value)  # Outputs: 42\n        ```\n    \"\"\"\n    if not isinstance(data, dict):\n        return super().model_validate(data)\n\n    data_copy = data.copy()\n    state = NamedValueState(data_copy.pop('state', NamedValueState.UNSET))\n    stored_value = data_copy.pop('stored_value', None)\n\n    instance = super().model_validate(data_copy)\n\n    # Only set the value if state was SET\n    if state == NamedValueState.SET and stored_value is not None:\n        instance.force_set_value(stored_value)\n\n    return instance\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(json_data: str, **kwargs) -&gt; NamedValue\n</code></pre> <p>Custom JSON deserialization to NamedValue instance.</p> <p>Reconstructs a NamedValue instance from a JSON string representation, restoring all state and stored value information.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string to deserialize</p> required <code>**kwargs</code> <p>Additional validation options</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>New instance with restored state</p> Example <pre><code>json_str = '{\"name\": \"example\", \"state\": \"set\", \"stored_value\": 42}'\nvalue = NamedValue.model_validate_json(json_str)\nprint(value.value)  # Outputs: 42\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>@classmethod\ndef model_validate_json(cls, json_data: str, **kwargs) -&gt; NamedValue:\n    \"\"\"\n    Custom JSON deserialization to NamedValue instance.\n\n    Reconstructs a NamedValue instance from a JSON string representation,\n    restoring all state and stored value information.\n\n    Args:\n        json_data (str): JSON string to deserialize\n        **kwargs: Additional validation options\n\n    Returns:\n        NamedValue: New instance with restored state\n\n    Example:\n        ```python\n        json_str = '{\"name\": \"example\", \"state\": \"set\", \"stored_value\": 42}'\n        value = NamedValue.model_validate_json(json_str)\n        print(value.value)  # Outputs: 42\n        ```\n    \"\"\"\n    data = json.loads(json_data)\n    return cls.model_validate(data, **kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValue.register_to_value_hash","title":"register_to_value_hash","text":"<pre><code>register_to_value_hash(h: NamedValueHash) -&gt; Self\n</code></pre> <p>Registers this value instance in a NamedValueHash.</p> <p>Registers this value in the provided hash container. If the hash contains value overrides, this value's current value may be overridden during registration.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>NamedValueHash</code> <p>The hash to register this value in</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>This instance for method chaining</p> Example <pre><code>value_hash = NamedValueHash()\nvalue = NamedValue(\"example\", 42)\nvalue.register_to_value_hash(value_hash).force_set_value(43)\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def register_to_value_hash(self, h: NamedValueHash) -&gt; Self:\n    \"\"\"\n    Registers this value instance in a NamedValueHash.\n\n    Registers this value in the provided hash container. If the hash contains\n    value overrides, this value's current value may be overridden during\n    registration.\n\n    Args:\n        h (NamedValueHash): The hash to register this value in\n\n    Returns:\n        Self: This instance for method chaining\n\n    Example:\n        ```python\n        value_hash = NamedValueHash()\n        value = NamedValue(\"example\", 42)\n        value.register_to_value_hash(value_hash).force_set_value(43)\n        ```\n    \"\"\"\n    h.register_value(self)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash","title":"NamedValueHash","text":"<p>               Bases: <code>NamedObjectHash</code></p> <p>A type-safe dictionary for storing and managing NamedValue objects.</p> <p>NamedValueHash provides a dictionary-like interface for managing a collection of NamedValue instances, using their names as keys. It ensures type safety and provides convenient methods for accessing and managing the stored values.</p> <p>The hash maintains unique naming across all stored values and supports serialization/deserialization of the entire collection.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category identifier for object registration</p> <code>model_config</code> <code>ConfigDict</code> <p>Pydantic configuration for model behavior</p> Example <pre><code>value_hash = NamedValueHash()\nvalue_hash.register_value(NamedValue(\"count\", 42))\nprint(value_hash.get_raw_value(\"count\"))  # Outputs: 42\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.get_raw_value","title":"get_raw_value","text":"<pre><code>get_raw_value(name: str) -&gt; Any\n</code></pre> <p>Get the underlying value by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to retrieve</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The actual value stored in the named value</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> <code>ValueError</code> <p>If the value hasn't been set yet</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"price\", 10.99))\nprint(hash.get_raw_value(\"price\"))  # Outputs: 10.99\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_raw_value(self, name: str) -&gt; Any:\n    \"\"\"\n    Get the underlying value by name.\n\n    Args:\n        name (str): Name of the value to retrieve\n\n    Returns:\n        Any: The actual value stored in the named value\n\n    Raises:\n        KeyError: If no value exists with the given name\n        ValueError: If the value hasn't been set yet\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"price\", 10.99))\n        print(hash.get_raw_value(\"price\"))  # Outputs: 10.99\n        ```\n    \"\"\"\n    return self.get_value(name).value\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.get_raw_values","title":"get_raw_values","text":"<pre><code>get_raw_values() -&gt; Iterable[Any]\n</code></pre> <p>Get the underlying values of all named values.</p> <p>Returns:</p> Type Description <code>Iterable[Any]</code> <p>Iterable[Any]: Iterator over the actual values stored in each NamedValue</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"y\", 2))\nprint(list(hash.get_raw_values()))  # Outputs: [1, 2]\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_raw_values(self) -&gt; Iterable[Any]:\n    \"\"\"\n    Get the underlying values of all named values.\n\n    Returns:\n        Iterable[Any]: Iterator over the actual values stored in each NamedValue\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"y\", 2))\n        print(list(hash.get_raw_values()))  # Outputs: [1, 2]\n        ```\n    \"\"\"\n    return (val.value for val in self.get_values())\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.get_value","title":"get_value","text":"<pre><code>get_value(name: str) -&gt; NamedValue\n</code></pre> <p>Retrieve a named value by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>The requested named value</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"price\", 10.99))\nprice = hash.get_value(\"price\")\nprint(price.value)  # Outputs: 10.99\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_value(self, name: str) -&gt; NamedValue:\n    \"\"\"\n    Retrieve a named value by its name.\n\n    Args:\n        name (str): Name of the value to retrieve\n\n    Returns:\n        NamedValue: The requested named value\n\n    Raises:\n        KeyError: If no value exists with the given name\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"price\", 10.99))\n        price = hash.get_value(\"price\")\n        print(price.value)  # Outputs: 10.99\n        ```\n    \"\"\"\n    return self.get_object(name)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.get_value_by_type","title":"get_value_by_type","text":"<pre><code>get_value_by_type(value_type: Type) -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all values of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>value_type</code> <code>Type</code> <p>Type to filter values by</p> required <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: Values matching the specified type</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"name\", \"test\"))\nintegers = list(hash.get_value_by_type(int))\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_value_by_type(self, value_type: Type) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all values of a specific type.\n\n    Args:\n        value_type (Type): Type to filter values by\n\n    Returns:\n        Iterable[NamedValue]: Values matching the specified type\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"name\", \"test\"))\n        integers = list(hash.get_value_by_type(int))\n        ```\n    \"\"\"\n    return [val for val in self.get_values() if isinstance(val, value_type)]\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.get_value_names","title":"get_value_names","text":"<pre><code>get_value_names() -&gt; Iterable[str]\n</code></pre> <p>Get names of all registered values.</p> <p>Returns:</p> Type Description <code>Iterable[str]</code> <p>Iterable[str]: An iterator over all value names</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"y\", 2))\nprint(list(hash.get_value_names()))  # Outputs: ['x', 'y']\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_value_names(self) -&gt; Iterable[str]:\n    \"\"\"\n    Get names of all registered values.\n\n    Returns:\n        Iterable[str]: An iterator over all value names\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"y\", 2))\n        print(list(hash.get_value_names()))  # Outputs: ['x', 'y']\n        ```\n    \"\"\"\n    return self.get_object_names()\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.get_values","title":"get_values","text":"<pre><code>get_values() -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all registered named values.</p> <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: An iterator over all stored named values</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"y\", 2))\nfor value in hash.get_values():\n    print(f\"{value.name}: {value.value}\")\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_values(self) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all registered named values.\n\n    Returns:\n        Iterable[NamedValue]: An iterator over all stored named values\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"y\", 2))\n        for value in hash.get_values():\n            print(f\"{value.name}: {value.value}\")\n        ```\n    \"\"\"\n    return self.get_objects()\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.model_dump","title":"model_dump","text":"<pre><code>model_dump(**kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Custom serialization to preserve stored values and their states.</p> <p>Creates a dictionary representation of the hash that includes full serialization of all contained NamedValue objects, preserving their values and states.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional serialization options passed to all nested objects</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing the complete hash state</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\ndata = hash.model_dump()\nprint(data['objects']['x']['stored_value'])  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom serialization to preserve stored values and their states.\n\n    Creates a dictionary representation of the hash that includes full\n    serialization of all contained NamedValue objects, preserving their\n    values and states.\n\n    Args:\n        **kwargs: Additional serialization options passed to all nested objects\n\n    Returns:\n        dict[str, Any]: Dictionary containing the complete hash state\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        data = hash.model_dump()\n        print(data['objects']['x']['stored_value'])  # Outputs: 1\n        ```\n    \"\"\"\n    data = super().model_dump(**kwargs)\n    # Ensure each object's stored value is included\n    if 'objects' in data:\n        for name, obj in self.objects.items():\n            if isinstance(obj, NamedValue):\n                # Get the full dump including stored value\n                obj_data = obj.model_dump(**kwargs)\n                data['objects'][name] = obj_data\n    return data\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(**kwargs) -&gt; str\n</code></pre> <p>Custom JSON serialization of the entire hash.</p> <p>Serializes the NamedValueHash instance and all contained NamedValue objects to a JSON string representation. Handles both the hash structure and the nested value serialization.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>JSON serialization options such as: - indent: Number of spaces for pretty printing - ensure_ascii: Escape non-ASCII characters - separators: Tuple of (item_sep, key_sep) for custom formatting</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation of the hash</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\njson_str = hash.model_dump_json(indent=2)\nprint(json_str)  # Pretty-printed JSON with nested values\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def model_dump_json(self, **kwargs) -&gt; str:\n    \"\"\"\n    Custom JSON serialization of the entire hash.\n\n    Serializes the NamedValueHash instance and all contained NamedValue\n    objects to a JSON string representation. Handles both the hash structure\n    and the nested value serialization.\n\n    Args:\n        **kwargs: JSON serialization options such as:\n            - indent: Number of spaces for pretty printing\n            - ensure_ascii: Escape non-ASCII characters\n            - separators: Tuple of (item_sep, key_sep) for custom formatting\n\n    Returns:\n        str: JSON string representation of the hash\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        json_str = hash.model_dump_json(indent=2)\n        print(json_str)  # Pretty-printed JSON with nested values\n        ```\n    \"\"\"\n    # Separate JSON-specific kwargs from model_dump kwargs\n    json_kwargs = {k: v for k, v in kwargs.items() if k in {'indent', 'ensure_ascii', 'separators'}}\n    dump_kwargs = {k: v for k, v in kwargs.items() if k not in json_kwargs}\n\n    # Get model data\n    data = self.model_dump(**dump_kwargs)\n    # Serialize to JSON\n    return json.dumps(data, **json_kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(data: Any) -&gt; NamedValueHash\n</code></pre> <p>Custom validation to restore hash state from serialized data.</p> <p>Reconstructs a NamedValueHash instance from serialized data, including all contained NamedValue objects with their values and states.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Serialized data to deserialize. Should be a dictionary containing an 'objects' key with serialized NamedValue instances</p> required <p>Returns:</p> Name Type Description <code>NamedValueHash</code> <code>NamedValueHash</code> <p>New instance with all values restored</p> Example <pre><code>data = {\n    'objects': {\n        'x': {'name': 'x', 'type': 'NamedValue', 'stored_value': 1}\n    }\n}\nhash = NamedValueHash.model_validate(data)\nprint(hash.get_raw_value('x'))  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>@classmethod\ndef model_validate(cls, data: Any) -&gt; NamedValueHash:\n    \"\"\"\n    Custom validation to restore hash state from serialized data.\n\n    Reconstructs a NamedValueHash instance from serialized data, including\n    all contained NamedValue objects with their values and states.\n\n    Args:\n        data (Any): Serialized data to deserialize. Should be a dictionary\n            containing an 'objects' key with serialized NamedValue instances\n\n    Returns:\n        NamedValueHash: New instance with all values restored\n\n    Example:\n        ```python\n        data = {\n            'objects': {\n                'x': {'name': 'x', 'type': 'NamedValue', 'stored_value': 1}\n            }\n        }\n        hash = NamedValueHash.model_validate(data)\n        print(hash.get_raw_value('x'))  # Outputs: 1\n        ```\n    \"\"\"\n    if not isinstance(data, dict):\n        return super().model_validate(data)\n\n    instance = cls()\n\n    # Process each object in the data\n    for name, obj_data in data.get('objects', {}).items():\n        if isinstance(obj_data, dict):\n            obj_type = obj_data.get('type')\n            if obj_type:\n                # Get the appropriate class from registry\n                value_class = ObjectRegistry.get(cls._registry_category, obj_type)\n                # Create and validate the object with its stored value\n                value_obj = value_class.model_validate(obj_data)\n                instance.register_value(value_obj)\n\n    return instance\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(json_data: str, **kwargs) -&gt; NamedValueHash\n</code></pre> <p>Custom JSON deserialization to NamedValueHash instance.</p> <p>Reconstructs a NamedValueHash instance from a JSON string representation, including all contained NamedValue objects with their complete state.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string containing serialized hash data</p> required <code>**kwargs</code> <p>Additional validation options for nested objects</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>NamedValueHash</code> <code>NamedValueHash</code> <p>New instance with all values restored</p> Example <pre><code>json_str = '''\n{\n    \"objects\": {\n        \"x\": {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1}\n    }\n}\n'''\nhash = NamedValueHash.model_validate_json(json_str)\nprint(hash.get_raw_value('x'))  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>@classmethod\ndef model_validate_json(cls, json_data: str, **kwargs) -&gt; NamedValueHash:\n    \"\"\"\n    Custom JSON deserialization to NamedValueHash instance.\n\n    Reconstructs a NamedValueHash instance from a JSON string representation,\n    including all contained NamedValue objects with their complete state.\n\n    Args:\n        json_data (str): JSON string containing serialized hash data\n        **kwargs: Additional validation options for nested objects\n\n    Returns:\n        NamedValueHash: New instance with all values restored\n\n    Example:\n        ```python\n        json_str = '''\n        {\n            \"objects\": {\n                \"x\": {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1}\n            }\n        }\n        '''\n        hash = NamedValueHash.model_validate_json(json_str)\n        print(hash.get_raw_value('x'))  # Outputs: 1\n        ```\n    \"\"\"\n    data = json.loads(json_data)\n    return cls.model_validate(data, **kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.register_value","title":"register_value","text":"<pre><code>register_value(value: NamedValue) -&gt; Self\n</code></pre> <p>Register a named value in the hash.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NamedValue</code> <p>The value to register</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>Returns self for method chaining</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a value with the same name already exists</p> Example <pre><code>hash = NamedValueHash()\nvalue = NamedValue(\"price\", 10.99)\nhash.register_value(value).register_value(NamedValue(\"qty\", 5))\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def register_value(self, value: NamedValue) -&gt; Self:\n    \"\"\"\n    Register a named value in the hash.\n\n    Args:\n        value (NamedValue): The value to register\n\n    Returns:\n        Self: Returns self for method chaining\n\n    Raises:\n        ValueError: If a value with the same name already exists\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        value = NamedValue(\"price\", 10.99)\n        hash.register_value(value).register_value(NamedValue(\"qty\", 5))\n        ```\n    \"\"\"\n    return self.register_object(value)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueHash.set_raw_value","title":"set_raw_value","text":"<pre><code>set_raw_value(name: str, value: Any) -&gt; None\n</code></pre> <p>Set the underlying value for a named value.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to update</p> required <code>value</code> <code>Any</code> <p>New value to set</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> <code>TypeError</code> <p>If value type doesn't match the expected type</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"price\", 10.99))\nhash.set_raw_value(\"price\", 11.99)\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def set_raw_value(self, name: str, value: Any) -&gt; None:\n    \"\"\"\n    Set the underlying value for a named value.\n\n    Args:\n        name (str): Name of the value to update\n        value (Any): New value to set\n\n    Raises:\n        KeyError: If no value exists with the given name\n        TypeError: If value type doesn't match the expected type\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"price\", 10.99))\n        hash.set_raw_value(\"price\", 11.99)\n        ```\n    \"\"\"\n    self.get_value(name).value = value\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList","title":"NamedValueList","text":"<p>               Bases: <code>NamedObjectList</code></p> <p>An ordered list container for managing NamedValue objects.</p> <p>NamedValueList maintains an ordered collection of NamedValue objects while providing type safety and convenient access methods. It preserves insertion order while also allowing access by name.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category identifier for object registration</p> <code>objects</code> <code>List[SerializeAsAny[InstanceOf[NamedValue]]]</code> <p>The list of stored values</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"first\", 1))\nvalue_list.append(NamedValue(\"second\", 2))\nprint([v.value for v in value_list])  # Outputs: [1, 2]\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; NamedValue\n</code></pre> <p>Get a named value by its index in the list.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the named value to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>The named value at the specified index</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the index is out of range</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(name=\"price\", value=10.5))\nfirst_value = value_list[0] # Get first named value\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; NamedValue:\n    \"\"\"Get a named value by its index in the list.\n\n    Args:\n        idx (int): Index of the named value to retrieve\n\n    Returns:\n        NamedValue: The named value at the specified index\n\n    Raises:\n        IndexError: If the index is out of range\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(name=\"price\", value=10.5))\n        first_value = value_list[0] # Get first named value\n        ```\n    \"\"\"\n    return super().__getitem__(idx)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.append","title":"append","text":"<pre><code>append(value: NamedValue) -&gt; Self\n</code></pre> <p>Append a named value to the end of the list.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NamedValue</code> <p>Named value to append</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The list instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1)).append(NamedValue(\"y\", 2))\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def append(self, value: NamedValue) -&gt; Self:\n    \"\"\"\n    Append a named value to the end of the list.\n\n    Args:\n        value (NamedValue): Named value to append\n\n    Returns:\n        Self: The list instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1)).append(NamedValue(\"y\", 2))\n        ```\n    \"\"\"\n    return super().append(value)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.extend","title":"extend","text":"<pre><code>extend(values: Iterable[NamedValue]) -&gt; Self\n</code></pre> <p>Extend the list with multiple named values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Iterable[NamedValue]</code> <p>Collection of named values to add</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The list instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nnew_values = [NamedValue(\"x\", 1), NamedValue(\"y\", 2)]\nvalue_list.extend(new_values)\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def extend(self, values: Iterable[NamedValue]) -&gt; Self:\n    \"\"\"\n    Extend the list with multiple named values.\n\n    Args:\n        values (Iterable[NamedValue]): Collection of named values to add\n\n    Returns:\n        Self: The list instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        new_values = [NamedValue(\"x\", 1), NamedValue(\"y\", 2)]\n        value_list.extend(new_values)\n        ```\n    \"\"\"\n    return super().extend(values)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.get_value","title":"get_value","text":"<pre><code>get_value(name: str) -&gt; NamedValue\n</code></pre> <p>Get a registered named value by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>The requested named value</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1))\nx = value_list.get_value(\"x\")\nprint(x.value)  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_value(self, name: str) -&gt; NamedValue:\n    \"\"\"\n    Get a registered named value by name.\n\n    Args:\n        name (str): Name of the value to retrieve\n\n    Returns:\n        NamedValue: The requested named value\n\n    Raises:\n        KeyError: If no value exists with the given name\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1))\n        x = value_list.get_value(\"x\")\n        print(x.value)  # Outputs: 1\n        ```\n    \"\"\"\n    return self.get_object(name)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.get_value_by_type","title":"get_value_by_type","text":"<pre><code>get_value_by_type(value_type: Type) -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all values whose stored value is of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>value_type</code> <code>Type</code> <p>Type to filter values by</p> required <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: Values whose stored value matches the specified type</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1))\nvalue_list.append(NamedValue(\"name\", \"test\"))\nintegers = list(value_list.get_value_by_type(int))\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_value_by_type(self, value_type: Type) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all values whose stored value is of a specific type.\n\n    Args:\n        value_type (Type): Type to filter values by\n\n    Returns:\n        Iterable[NamedValue]: Values whose stored value matches the specified type\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1))\n        value_list.append(NamedValue(\"name\", \"test\"))\n        integers = list(value_list.get_value_by_type(int))\n        ```\n    \"\"\"\n    for value in self.get_values():\n        try:\n            if isinstance(value.value, value_type):\n                yield value\n        except ValueError:\n            # Skip unset values\n            continue\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.get_values","title":"get_values","text":"<pre><code>get_values() -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all registered named values.</p> <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: Iterator over all stored named values</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.extend([NamedValue(\"x\", 1), NamedValue(\"y\", 2)])\nfor value in value_list.get_values():\n    print(f\"{value.name}: {value.value}\")\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def get_values(self) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all registered named values.\n\n    Returns:\n        Iterable[NamedValue]: Iterator over all stored named values\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.extend([NamedValue(\"x\", 1), NamedValue(\"y\", 2)])\n        for value in value_list.get_values():\n            print(f\"{value.name}: {value.value}\")\n        ```\n    \"\"\"\n    return self.get_objects()\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.model_dump","title":"model_dump","text":"<pre><code>model_dump(**kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Custom serialization to preserve stored values.</p> <p>Extends the parent class serialization to ensure proper serialization of all stored named values and their states.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional serialization options</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing serialized state</p> Source code in <code>src/data_handlers/values.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom serialization to preserve stored values.\n\n    Extends the parent class serialization to ensure proper serialization\n    of all stored named values and their states.\n\n    Args:\n        **kwargs: Additional serialization options\n\n    Returns:\n        dict[str, Any]: Dictionary containing serialized state\n    \"\"\"\n    data = super().model_dump(**kwargs)\n    if 'objects' in data:\n        # Ensure each object's stored value is included\n        data['objects'] = [\n            obj.model_dump(**kwargs) if isinstance(obj, NamedValue) else obj\n            for obj in self.objects\n        ]\n    return data\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(**kwargs) -&gt; str\n</code></pre> <p>Custom JSON serialization of the value list.</p> <p>Serializes the NamedValueList instance and all contained NamedValue objects to a JSON string representation. Preserves the order of values and their complete state.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>JSON serialization options such as: - indent: Number of spaces for pretty printing - ensure_ascii: Escape non-ASCII characters - separators: Tuple of (item_sep, key_sep) for custom formatting</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation of the list</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1))\nvalue_list.append(NamedValue(\"y\", 2))\njson_str = value_list.model_dump_json(indent=2)\nprint(json_str)  # Pretty-printed JSON with ordered values\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def model_dump_json(self, **kwargs) -&gt; str:\n    \"\"\"\n    Custom JSON serialization of the value list.\n\n    Serializes the NamedValueList instance and all contained NamedValue\n    objects to a JSON string representation. Preserves the order of values\n    and their complete state.\n\n    Args:\n        **kwargs: JSON serialization options such as:\n            - indent: Number of spaces for pretty printing\n            - ensure_ascii: Escape non-ASCII characters\n            - separators: Tuple of (item_sep, key_sep) for custom formatting\n\n    Returns:\n        str: JSON string representation of the list\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1))\n        value_list.append(NamedValue(\"y\", 2))\n        json_str = value_list.model_dump_json(indent=2)\n        print(json_str)  # Pretty-printed JSON with ordered values\n        ```\n    \"\"\"\n    # Separate JSON-specific kwargs from model_dump kwargs\n    json_kwargs = {k: v for k, v in kwargs.items() if k in {'indent', 'ensure_ascii', 'separators'}}\n    dump_kwargs = {k: v for k, v in kwargs.items() if k not in json_kwargs}\n\n    # Get model data\n    data = self.model_dump(**dump_kwargs)\n    # Serialize to JSON\n    return json.dumps(data, **json_kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(data: Any) -&gt; NamedValueList\n</code></pre> <p>Custom validation to restore stored values.</p> <p>Reconstructs a NamedValueList instance from serialized data, properly restoring all contained named values and their states.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Serialized data to deserialize</p> required <p>Returns:</p> Name Type Description <code>NamedValueList</code> <code>NamedValueList</code> <p>New instance with restored values</p> Source code in <code>src/data_handlers/values.py</code> <pre><code>@classmethod\ndef model_validate(cls, data: Any) -&gt; NamedValueList:\n    \"\"\"\n    Custom validation to restore stored values.\n\n    Reconstructs a NamedValueList instance from serialized data,\n    properly restoring all contained named values and their states.\n\n    Args:\n        data (Any): Serialized data to deserialize\n\n    Returns:\n        NamedValueList: New instance with restored values\n    \"\"\"\n    if not isinstance(data, dict):\n        return super().model_validate(data)\n\n    instance = cls()\n\n    # Process each object in the data\n    for obj_data in data.get('objects', []):\n        if isinstance(obj_data, dict):\n            obj_type = obj_data.get('type')\n            if obj_type:\n                # Get the appropriate class from registry\n                value_class = ObjectRegistry.get(cls._registry_category, obj_type)\n                # Create and validate the object\n                value_obj = value_class.model_validate(obj_data)\n                instance.append(value_obj)\n\n    return instance\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(json_data: str, **kwargs) -&gt; NamedValueList\n</code></pre> <p>Custom JSON deserialization to NamedValueList instance.</p> <p>Reconstructs a NamedValueList instance from a JSON string representation, preserving the order of values and restoring their complete state.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string containing serialized list data</p> required <code>**kwargs</code> <p>Additional validation options for nested objects</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>NamedValueList</code> <code>NamedValueList</code> <p>New instance with all values restored in order</p> Example <pre><code>json_str = '''\n{\n    \"objects\": [\n        {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1},\n        {\"name\": \"y\", \"type\": \"NamedValue\", \"stored_value\": 2}\n    ]\n}\n'''\nvalue_list = NamedValueList.model_validate_json(json_str)\nprint([v.value for v in value_list])  # Outputs: [1, 2]\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>@classmethod\ndef model_validate_json(cls, json_data: str, **kwargs) -&gt; NamedValueList:\n    \"\"\"\n    Custom JSON deserialization to NamedValueList instance.\n\n    Reconstructs a NamedValueList instance from a JSON string representation,\n    preserving the order of values and restoring their complete state.\n\n    Args:\n        json_data (str): JSON string containing serialized list data\n        **kwargs: Additional validation options for nested objects\n\n    Returns:\n        NamedValueList: New instance with all values restored in order\n\n    Example:\n        ```python\n        json_str = '''\n        {\n            \"objects\": [\n                {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1},\n                {\"name\": \"y\", \"type\": \"NamedValue\", \"stored_value\": 2}\n            ]\n        }\n        '''\n        value_list = NamedValueList.model_validate_json(json_str)\n        print([v.value for v in value_list])  # Outputs: [1, 2]\n        ```\n    \"\"\"\n    data = json.loads(json_data)\n    return cls.model_validate(data, **kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueList.register_value","title":"register_value","text":"<pre><code>register_value(value: NamedValue) -&gt; Self\n</code></pre> <p>Register a named value to the list.</p> <p>Similar to append but uses the register_object method internally, which may perform additional validation.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NamedValue</code> <p>Named value to register</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The list instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.register_value(NamedValue(\"x\", 1))\n</code></pre> Source code in <code>src/data_handlers/values.py</code> <pre><code>def register_value(self, value: NamedValue) -&gt; Self:\n    \"\"\"\n    Register a named value to the list.\n\n    Similar to append but uses the register_object method internally,\n    which may perform additional validation.\n\n    Args:\n        value (NamedValue): Named value to register\n\n    Returns:\n        Self: The list instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.register_value(NamedValue(\"x\", 1))\n        ```\n    \"\"\"\n    return self.register_object(value)\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueState","title":"NamedValueState","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>State enumeration for NamedValue objects.</p> <p>This enum tracks whether a named value has been set or remains unset. Once set, values are typically frozen unless explicitly forced to change.</p> <p>Attributes:</p> Name Type Description <code>UNSET</code> <p>Indicates no value has been set yet</p> <code>SET</code> <p>Indicates value has been set and is frozen</p>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueState.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Get string representation for debugging.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The state value as a string (\"unset\" or \"set\")</p> Source code in <code>src/data_handlers/values.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Get string representation for debugging.\n\n    Returns:\n        str: The state value as a string (\"unset\" or \"set\")\n    \"\"\"\n    return self.value  # Returns just \"unset\" or \"set\"\n</code></pre>"},{"location":"reference/data_handlers/values/#data_handlers.values.NamedValueState.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Convert state to string representation.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The state value as a string (\"unset\" or \"set\")</p> Source code in <code>src/data_handlers/values.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Convert state to string representation.\n\n    Returns:\n        str: The state value as a string (\"unset\" or \"set\")\n    \"\"\"\n    return self.value  # Returns just \"unset\" or \"set\"\n</code></pre>"},{"location":"reference/data_handlers/values_save/","title":"values_save","text":""},{"location":"reference/data_handlers/values_save/#data_handlers.values_save","title":"values_save","text":"<p>Module for generating, sorting, and managing named values. This uses pydantic dataclasses for JSON serialization to avoid overloading system memory.</p> <p>The module provides a robust framework for managing named values with type safety, serialization, and state management. It includes classes for individual named values, collections of named values in both list and hash (dictionary) formats, and utilities for type validation and serialization.</p> <p>Classes:</p> Name Description <code>NamedValueState</code> <p>Enum for tracking the state of named values</p> <code>NamedValue</code> <p>Base class for type-safe named values with state management</p> <code>NamedValueHash</code> <p>Dictionary-like container for managing named values</p> <code>NamedValueList</code> <p>List-like container for managing ordered named values</p> Types <p>SerializableValue: Union type defining all allowed value types T: Generic type variable bound to SerializableValue</p>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue","title":"NamedValue","text":"<pre><code>NamedValue(name: str, value: T | None = None, **data)\n</code></pre> <p>               Bases: <code>NamedObject</code>, <code>Generic[T]</code></p> <p>A named value container with type safety and state management.</p> <p>NamedValue provides a type-safe way to store and manage values with built-in state tracking, serialization, and validation. Values can be frozen after initial setting to prevent accidental modification.</p> Type Parameters <p>T: The type of value to store, must be a SerializableValue</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for the value</p> <code>_stored_value</code> <code>T | NamedValueState</code> <p>The actual stored value or UNSET state</p> <code>_state</code> <code>NamedValueState</code> <p>Current state of the value</p> <code>_type</code> <code>type</code> <p>Runtime type information for validation</p> Properties <p>value (T): Access or modify the stored value</p> Example <pre><code># Create a named integer value\ncount = NamedValue[int](\"item_count\")\ncount.value = 42  # Sets and freezes the value\nprint(count.value)  # Outputs: 42\ncount.value = 50  # Raises ValueError - value is frozen\ncount.force_set_value(50)  # Allows value change\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def __init__(self, name: str, value: T | None = None, **data):\n    # print(f\"Initializing NamedValue with class: {self.__class__}\")\n    # print(f\"Has __orig_class__: {hasattr(self, '__orig_class__')}\")\n    # if hasattr(self, '__orig_class__'):\n    #     print(f\"__orig_class__: {self.__orig_class__}\")\n    #     print(f\"__orig_class__.__args__: {self.__orig_class__.__args__}\")\n    # print(f\"Bases: {self.__class__.__bases__}\")\n    # for base in self.__class__.__bases__:\n    #     if hasattr(base, '__origin__'):\n    #         print(f\"Base origin: {base.__origin__}\")\n    #         if hasattr(base, '__args__'):\n    #             print(f\"Base args: {base.__args__}\")\n\n    data.pop('stored_value', None)\n    data.pop('_stored_value', None)\n\n    super().__init__(name=name, **data)\n    self._type = self._extract_value_type()\n    # print(f\"Extracted type: {self._type}\")\n    object.__setattr__(self, '_stored_value', NamedValueState.UNSET)\n\n    if value is not None:\n        self.value = value\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.value","title":"value  <code>property</code> <code>writable</code>","text":"<pre><code>value: T\n</code></pre> <p>Get the stored value.</p> <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The currently stored value</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If attempting to access before a value has been set</p> Note <p>This property provides read access to the stored value. Once set, the value is frozen and can only be changed using force_set_value().</p>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name: str, value: Any) -&gt; None\n</code></pre> <p>Prevent direct modification of protected attributes.</p> <p>Overrides attribute setting to prevent direct modification of internal state attributes. These attributes should only be modified through appropriate methods.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to set</p> required <code>value</code> <code>Any</code> <p>Value to set</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If attempting to modify protected attributes directly</p> Example <pre><code>value = NamedValue(\"example\")\nvalue._stored_value = 42  # Raises AttributeError\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"\n    Prevent direct modification of protected attributes.\n\n    Overrides attribute setting to prevent direct modification of internal\n    state attributes. These attributes should only be modified through\n    appropriate methods.\n\n    Args:\n        name (str): Name of the attribute to set\n        value (Any): Value to set\n\n    Raises:\n        AttributeError: If attempting to modify protected attributes directly\n\n    Example:\n        ```python\n        value = NamedValue(\"example\")\n        value._stored_value = 42  # Raises AttributeError\n        ```\n    \"\"\"\n    if name in ('_stored_value', '_state'):\n        raise AttributeError(f\"Cannot modify {name} directly. Use appropriate methods instead.\")\n    super().__setattr__(name, value)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.append_to_value_list","title":"append_to_value_list","text":"<pre><code>append_to_value_list(l: NamedValueList) -&gt; Self\n</code></pre> <p>Appends this value instance to a NamedValueList.</p> <p>Convenience method for adding this value to a list while enabling method chaining.</p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>NamedValueList</code> <p>The list to append this value to</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>This instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nvalue = NamedValue(\"example\", 42)\nvalue.append_to_value_list(value_list).force_set_value(43)\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def append_to_value_list(self, l: NamedValueList) -&gt; Self:\n    \"\"\"\n    Appends this value instance to a NamedValueList.\n\n    Convenience method for adding this value to a list while enabling\n    method chaining.\n\n    Args:\n        l (NamedValueList): The list to append this value to\n\n    Returns:\n        Self: This instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value = NamedValue(\"example\", 42)\n        value.append_to_value_list(value_list).force_set_value(43)\n        ```\n    \"\"\"\n    l.append(self)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.force_set_value","title":"force_set_value","text":"<pre><code>force_set_value(new_value: T) -&gt; None\n</code></pre> <p>Force set the value regardless of its current state.</p> <p>This method bypasses the normal freezing mechanism and allows changing an already-set value.</p> <p>Parameters:</p> Name Type Description Default <code>new_value</code> <code>T</code> <p>New value to store</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If value doesn't match the expected type T</p> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def force_set_value(self, new_value: T) -&gt; None:\n    \"\"\"\n    Force set the value regardless of its current state.\n\n    This method bypasses the normal freezing mechanism and allows\n    changing an already-set value.\n\n    Args:\n        new_value (T): New value to store\n\n    Raises:\n        TypeError: If value doesn't match the expected type T\n    \"\"\"\n    object.__setattr__(self, '_stored_value', NamedValueState.UNSET)\n    object.__setattr__(self, '_state', NamedValueState.UNSET)\n    self.value = new_value\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.model_dump","title":"model_dump","text":"<pre><code>model_dump(**kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Custom serialization to include value state and stored value.</p> <p>Extends the parent class serialization to include the value's state and stored value (if set) in the serialized data.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to parent serialization</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing serialized state</p> Example <pre><code>value = NamedValue(\"example\", 42)\ndata = value.model_dump()\nprint(data)  # Contains 'state' and 'stored_value'\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom serialization to include value state and stored value.\n\n    Extends the parent class serialization to include the value's state\n    and stored value (if set) in the serialized data.\n\n    Args:\n        **kwargs: Additional arguments passed to parent serialization\n\n    Returns:\n        dict[str, Any]: Dictionary containing serialized state\n\n    Example:\n        ```python\n        value = NamedValue(\"example\", 42)\n        data = value.model_dump()\n        print(data)  # Contains 'state' and 'stored_value'\n        ```\n    \"\"\"\n    data = super().model_dump(**kwargs)\n    data['state'] = self._state\n    if self._state == NamedValueState.SET:\n        data['stored_value'] = self._stored_value\n    return data\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(**kwargs) -&gt; str\n</code></pre> <p>Custom JSON serialization of the named value.</p> <p>Serializes the named value instance to a JSON string, including all state information and stored value.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>JSON serialization options like indent, ensure_ascii, etc.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation</p> Example <pre><code>value = NamedValue(\"example\", 42)\njson_str = value.model_dump_json(indent=2)\nprint(json_str)  # Pretty-printed JSON\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def model_dump_json(self, **kwargs) -&gt; str:\n    \"\"\"\n    Custom JSON serialization of the named value.\n\n    Serializes the named value instance to a JSON string, including\n    all state information and stored value.\n\n    Args:\n        **kwargs: JSON serialization options like indent, ensure_ascii, etc.\n\n    Returns:\n        str: JSON string representation\n\n    Example:\n        ```python\n        value = NamedValue(\"example\", 42)\n        json_str = value.model_dump_json(indent=2)\n        print(json_str)  # Pretty-printed JSON\n        ```\n    \"\"\"\n    # Separate JSON-specific kwargs from model_dump kwargs\n    json_kwargs = {k: v for k, v in kwargs.items() if k in {'indent', 'ensure_ascii', 'separators'}}\n    dump_kwargs = {k: v for k, v in kwargs.items() if k not in json_kwargs}\n\n    # Get model data with stored value\n    data = self.model_dump(**dump_kwargs)\n    return json.dumps(data, **json_kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(data: Any) -&gt; NamedValue\n</code></pre> <p>Custom deserialization to restore value state and stored value.</p> <p>Reconstructs a NamedValue instance from serialized data, properly restoring both the value state and any stored value.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Serialized data to deserialize</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>New instance with restored state</p> Example <pre><code>data = {'name': 'example', 'state': 'set', 'stored_value': 42}\nvalue = NamedValue.model_validate(data)\nprint(value.value)  # Outputs: 42\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>@classmethod\ndef model_validate(cls, data: Any) -&gt; NamedValue:\n    \"\"\"\n    Custom deserialization to restore value state and stored value.\n\n    Reconstructs a NamedValue instance from serialized data, properly\n    restoring both the value state and any stored value.\n\n    Args:\n        data (Any): Serialized data to deserialize\n\n    Returns:\n        NamedValue: New instance with restored state\n\n    Example:\n        ```python\n        data = {'name': 'example', 'state': 'set', 'stored_value': 42}\n        value = NamedValue.model_validate(data)\n        print(value.value)  # Outputs: 42\n        ```\n    \"\"\"\n    if not isinstance(data, dict):\n        return super().model_validate(data)\n\n    data_copy = data.copy()\n    state = NamedValueState(data_copy.pop('state', NamedValueState.UNSET))\n    stored_value = data_copy.pop('stored_value', None)\n\n    instance = super().model_validate(data_copy)\n\n    # Only set the value if state was SET\n    if state == NamedValueState.SET and stored_value is not None:\n        instance.force_set_value(stored_value)\n\n    return instance\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(json_data: str, **kwargs) -&gt; NamedValue\n</code></pre> <p>Custom JSON deserialization to NamedValue instance.</p> <p>Reconstructs a NamedValue instance from a JSON string representation, restoring all state and stored value information.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string to deserialize</p> required <code>**kwargs</code> <p>Additional validation options</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>New instance with restored state</p> Example <pre><code>json_str = '{\"name\": \"example\", \"state\": \"set\", \"stored_value\": 42}'\nvalue = NamedValue.model_validate_json(json_str)\nprint(value.value)  # Outputs: 42\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>@classmethod\ndef model_validate_json(cls, json_data: str, **kwargs) -&gt; NamedValue:\n    \"\"\"\n    Custom JSON deserialization to NamedValue instance.\n\n    Reconstructs a NamedValue instance from a JSON string representation,\n    restoring all state and stored value information.\n\n    Args:\n        json_data (str): JSON string to deserialize\n        **kwargs: Additional validation options\n\n    Returns:\n        NamedValue: New instance with restored state\n\n    Example:\n        ```python\n        json_str = '{\"name\": \"example\", \"state\": \"set\", \"stored_value\": 42}'\n        value = NamedValue.model_validate_json(json_str)\n        print(value.value)  # Outputs: 42\n        ```\n    \"\"\"\n    data = json.loads(json_data)\n    return cls.model_validate(data, **kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValue.register_to_value_hash","title":"register_to_value_hash","text":"<pre><code>register_to_value_hash(h: NamedValueHash) -&gt; Self\n</code></pre> <p>Registers this value instance in a NamedValueHash.</p> <p>Registers this value in the provided hash container. If the hash contains value overrides, this value's current value may be overridden during registration.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>NamedValueHash</code> <p>The hash to register this value in</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>This instance for method chaining</p> Example <pre><code>value_hash = NamedValueHash()\nvalue = NamedValue(\"example\", 42)\nvalue.register_to_value_hash(value_hash).force_set_value(43)\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def register_to_value_hash(self, h: NamedValueHash) -&gt; Self:\n    \"\"\"\n    Registers this value instance in a NamedValueHash.\n\n    Registers this value in the provided hash container. If the hash contains\n    value overrides, this value's current value may be overridden during\n    registration.\n\n    Args:\n        h (NamedValueHash): The hash to register this value in\n\n    Returns:\n        Self: This instance for method chaining\n\n    Example:\n        ```python\n        value_hash = NamedValueHash()\n        value = NamedValue(\"example\", 42)\n        value.register_to_value_hash(value_hash).force_set_value(43)\n        ```\n    \"\"\"\n    h.register_value(self)\n    return self\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash","title":"NamedValueHash","text":"<p>               Bases: <code>NamedObjectHash</code></p> <p>A type-safe dictionary for storing and managing NamedValue objects.</p> <p>NamedValueHash provides a dictionary-like interface for managing a collection of NamedValue instances, using their names as keys. It ensures type safety and provides convenient methods for accessing and managing the stored values.</p> <p>The hash maintains unique naming across all stored values and supports serialization/deserialization of the entire collection.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category identifier for object registration</p> <code>model_config</code> <code>ConfigDict</code> <p>Pydantic configuration for model behavior</p> Example <pre><code>value_hash = NamedValueHash()\nvalue_hash.register_value(NamedValue(\"count\", 42))\nprint(value_hash.get_raw_value(\"count\"))  # Outputs: 42\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.get_raw_value","title":"get_raw_value","text":"<pre><code>get_raw_value(name: str) -&gt; Any\n</code></pre> <p>Get the underlying value by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to retrieve</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The actual value stored in the named value</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> <code>ValueError</code> <p>If the value hasn't been set yet</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"price\", 10.99))\nprint(hash.get_raw_value(\"price\"))  # Outputs: 10.99\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_raw_value(self, name: str) -&gt; Any:\n    \"\"\"\n    Get the underlying value by name.\n\n    Args:\n        name (str): Name of the value to retrieve\n\n    Returns:\n        Any: The actual value stored in the named value\n\n    Raises:\n        KeyError: If no value exists with the given name\n        ValueError: If the value hasn't been set yet\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"price\", 10.99))\n        print(hash.get_raw_value(\"price\"))  # Outputs: 10.99\n        ```\n    \"\"\"\n    return self.get_value(name).value\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.get_raw_values","title":"get_raw_values","text":"<pre><code>get_raw_values() -&gt; Iterable[Any]\n</code></pre> <p>Get the underlying values of all named values.</p> <p>Returns:</p> Type Description <code>Iterable[Any]</code> <p>Iterable[Any]: Iterator over the actual values stored in each NamedValue</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"y\", 2))\nprint(list(hash.get_raw_values()))  # Outputs: [1, 2]\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_raw_values(self) -&gt; Iterable[Any]:\n    \"\"\"\n    Get the underlying values of all named values.\n\n    Returns:\n        Iterable[Any]: Iterator over the actual values stored in each NamedValue\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"y\", 2))\n        print(list(hash.get_raw_values()))  # Outputs: [1, 2]\n        ```\n    \"\"\"\n    return (val.value for val in self.get_values())\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.get_value","title":"get_value","text":"<pre><code>get_value(name: str) -&gt; NamedValue\n</code></pre> <p>Retrieve a named value by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>The requested named value</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"price\", 10.99))\nprice = hash.get_value(\"price\")\nprint(price.value)  # Outputs: 10.99\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_value(self, name: str) -&gt; NamedValue:\n    \"\"\"\n    Retrieve a named value by its name.\n\n    Args:\n        name (str): Name of the value to retrieve\n\n    Returns:\n        NamedValue: The requested named value\n\n    Raises:\n        KeyError: If no value exists with the given name\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"price\", 10.99))\n        price = hash.get_value(\"price\")\n        print(price.value)  # Outputs: 10.99\n        ```\n    \"\"\"\n    return self.get_object(name)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.get_value_by_type","title":"get_value_by_type","text":"<pre><code>get_value_by_type(value_type: Type) -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all values of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>value_type</code> <code>Type</code> <p>Type to filter values by</p> required <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: Values matching the specified type</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"name\", \"test\"))\nintegers = list(hash.get_value_by_type(int))\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_value_by_type(self, value_type: Type) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all values of a specific type.\n\n    Args:\n        value_type (Type): Type to filter values by\n\n    Returns:\n        Iterable[NamedValue]: Values matching the specified type\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"name\", \"test\"))\n        integers = list(hash.get_value_by_type(int))\n        ```\n    \"\"\"\n    return [val for val in self.get_values() if isinstance(val, value_type)]\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.get_value_names","title":"get_value_names","text":"<pre><code>get_value_names() -&gt; Iterable[str]\n</code></pre> <p>Get names of all registered values.</p> <p>Returns:</p> Type Description <code>Iterable[str]</code> <p>Iterable[str]: An iterator over all value names</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"y\", 2))\nprint(list(hash.get_value_names()))  # Outputs: ['x', 'y']\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_value_names(self) -&gt; Iterable[str]:\n    \"\"\"\n    Get names of all registered values.\n\n    Returns:\n        Iterable[str]: An iterator over all value names\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"y\", 2))\n        print(list(hash.get_value_names()))  # Outputs: ['x', 'y']\n        ```\n    \"\"\"\n    return self.get_object_names()\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.get_values","title":"get_values","text":"<pre><code>get_values() -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all registered named values.</p> <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: An iterator over all stored named values</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\nhash.register_value(NamedValue(\"y\", 2))\nfor value in hash.get_values():\n    print(f\"{value.name}: {value.value}\")\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_values(self) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all registered named values.\n\n    Returns:\n        Iterable[NamedValue]: An iterator over all stored named values\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        hash.register_value(NamedValue(\"y\", 2))\n        for value in hash.get_values():\n            print(f\"{value.name}: {value.value}\")\n        ```\n    \"\"\"\n    return self.get_objects()\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.model_dump","title":"model_dump","text":"<pre><code>model_dump(**kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Custom serialization to preserve stored values and their states.</p> <p>Creates a dictionary representation of the hash that includes full serialization of all contained NamedValue objects, preserving their values and states.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional serialization options passed to all nested objects</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing the complete hash state</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\ndata = hash.model_dump()\nprint(data['objects']['x']['stored_value'])  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom serialization to preserve stored values and their states.\n\n    Creates a dictionary representation of the hash that includes full\n    serialization of all contained NamedValue objects, preserving their\n    values and states.\n\n    Args:\n        **kwargs: Additional serialization options passed to all nested objects\n\n    Returns:\n        dict[str, Any]: Dictionary containing the complete hash state\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        data = hash.model_dump()\n        print(data['objects']['x']['stored_value'])  # Outputs: 1\n        ```\n    \"\"\"\n    data = super().model_dump(**kwargs)\n    # Ensure each object's stored value is included\n    if 'objects' in data:\n        for name, obj in self.objects.items():\n            if isinstance(obj, NamedValue):\n                # Get the full dump including stored value\n                obj_data = obj.model_dump(**kwargs)\n                data['objects'][name] = obj_data\n    return data\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(**kwargs) -&gt; str\n</code></pre> <p>Custom JSON serialization of the entire hash.</p> <p>Serializes the NamedValueHash instance and all contained NamedValue objects to a JSON string representation. Handles both the hash structure and the nested value serialization.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>JSON serialization options such as: - indent: Number of spaces for pretty printing - ensure_ascii: Escape non-ASCII characters - separators: Tuple of (item_sep, key_sep) for custom formatting</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation of the hash</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"x\", 1))\njson_str = hash.model_dump_json(indent=2)\nprint(json_str)  # Pretty-printed JSON with nested values\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def model_dump_json(self, **kwargs) -&gt; str:\n    \"\"\"\n    Custom JSON serialization of the entire hash.\n\n    Serializes the NamedValueHash instance and all contained NamedValue\n    objects to a JSON string representation. Handles both the hash structure\n    and the nested value serialization.\n\n    Args:\n        **kwargs: JSON serialization options such as:\n            - indent: Number of spaces for pretty printing\n            - ensure_ascii: Escape non-ASCII characters\n            - separators: Tuple of (item_sep, key_sep) for custom formatting\n\n    Returns:\n        str: JSON string representation of the hash\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"x\", 1))\n        json_str = hash.model_dump_json(indent=2)\n        print(json_str)  # Pretty-printed JSON with nested values\n        ```\n    \"\"\"\n    # Separate JSON-specific kwargs from model_dump kwargs\n    json_kwargs = {k: v for k, v in kwargs.items() if k in {'indent', 'ensure_ascii', 'separators'}}\n    dump_kwargs = {k: v for k, v in kwargs.items() if k not in json_kwargs}\n\n    # Get model data\n    data = self.model_dump(**dump_kwargs)\n    # Serialize to JSON\n    return json.dumps(data, **json_kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(data: Any) -&gt; NamedValueHash\n</code></pre> <p>Custom validation to restore hash state from serialized data.</p> <p>Reconstructs a NamedValueHash instance from serialized data, including all contained NamedValue objects with their values and states.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Serialized data to deserialize. Should be a dictionary containing an 'objects' key with serialized NamedValue instances</p> required <p>Returns:</p> Name Type Description <code>NamedValueHash</code> <code>NamedValueHash</code> <p>New instance with all values restored</p> Example <pre><code>data = {\n    'objects': {\n        'x': {'name': 'x', 'type': 'NamedValue', 'stored_value': 1}\n    }\n}\nhash = NamedValueHash.model_validate(data)\nprint(hash.get_raw_value('x'))  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>@classmethod\ndef model_validate(cls, data: Any) -&gt; NamedValueHash:\n    \"\"\"\n    Custom validation to restore hash state from serialized data.\n\n    Reconstructs a NamedValueHash instance from serialized data, including\n    all contained NamedValue objects with their values and states.\n\n    Args:\n        data (Any): Serialized data to deserialize. Should be a dictionary\n            containing an 'objects' key with serialized NamedValue instances\n\n    Returns:\n        NamedValueHash: New instance with all values restored\n\n    Example:\n        ```python\n        data = {\n            'objects': {\n                'x': {'name': 'x', 'type': 'NamedValue', 'stored_value': 1}\n            }\n        }\n        hash = NamedValueHash.model_validate(data)\n        print(hash.get_raw_value('x'))  # Outputs: 1\n        ```\n    \"\"\"\n    if not isinstance(data, dict):\n        return super().model_validate(data)\n\n    instance = cls()\n\n    # Process each object in the data\n    for name, obj_data in data.get('objects', {}).items():\n        if isinstance(obj_data, dict):\n            obj_type = obj_data.get('type')\n            if obj_type:\n                # Get the appropriate class from registry\n                value_class = ObjectRegistry.get(cls._registry_category, obj_type)\n                # Create and validate the object with its stored value\n                value_obj = value_class.model_validate(obj_data)\n                instance.register_value(value_obj)\n\n    return instance\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(json_data: str, **kwargs) -&gt; NamedValueHash\n</code></pre> <p>Custom JSON deserialization to NamedValueHash instance.</p> <p>Reconstructs a NamedValueHash instance from a JSON string representation, including all contained NamedValue objects with their complete state.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string containing serialized hash data</p> required <code>**kwargs</code> <p>Additional validation options for nested objects</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>NamedValueHash</code> <code>NamedValueHash</code> <p>New instance with all values restored</p> Example <pre><code>json_str = '''\n{\n    \"objects\": {\n        \"x\": {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1}\n    }\n}\n'''\nhash = NamedValueHash.model_validate_json(json_str)\nprint(hash.get_raw_value('x'))  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>@classmethod\ndef model_validate_json(cls, json_data: str, **kwargs) -&gt; NamedValueHash:\n    \"\"\"\n    Custom JSON deserialization to NamedValueHash instance.\n\n    Reconstructs a NamedValueHash instance from a JSON string representation,\n    including all contained NamedValue objects with their complete state.\n\n    Args:\n        json_data (str): JSON string containing serialized hash data\n        **kwargs: Additional validation options for nested objects\n\n    Returns:\n        NamedValueHash: New instance with all values restored\n\n    Example:\n        ```python\n        json_str = '''\n        {\n            \"objects\": {\n                \"x\": {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1}\n            }\n        }\n        '''\n        hash = NamedValueHash.model_validate_json(json_str)\n        print(hash.get_raw_value('x'))  # Outputs: 1\n        ```\n    \"\"\"\n    data = json.loads(json_data)\n    return cls.model_validate(data, **kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.register_value","title":"register_value","text":"<pre><code>register_value(value: NamedValue) -&gt; Self\n</code></pre> <p>Register a named value in the hash.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NamedValue</code> <p>The value to register</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>Returns self for method chaining</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a value with the same name already exists</p> Example <pre><code>hash = NamedValueHash()\nvalue = NamedValue(\"price\", 10.99)\nhash.register_value(value).register_value(NamedValue(\"qty\", 5))\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def register_value(self, value: NamedValue) -&gt; Self:\n    \"\"\"\n    Register a named value in the hash.\n\n    Args:\n        value (NamedValue): The value to register\n\n    Returns:\n        Self: Returns self for method chaining\n\n    Raises:\n        ValueError: If a value with the same name already exists\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        value = NamedValue(\"price\", 10.99)\n        hash.register_value(value).register_value(NamedValue(\"qty\", 5))\n        ```\n    \"\"\"\n    return self.register_object(value)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueHash.set_raw_value","title":"set_raw_value","text":"<pre><code>set_raw_value(name: str, value: Any) -&gt; None\n</code></pre> <p>Set the underlying value for a named value.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to update</p> required <code>value</code> <code>Any</code> <p>New value to set</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> <code>TypeError</code> <p>If value type doesn't match the expected type</p> Example <pre><code>hash = NamedValueHash()\nhash.register_value(NamedValue(\"price\", 10.99))\nhash.set_raw_value(\"price\", 11.99)\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def set_raw_value(self, name: str, value: Any) -&gt; None:\n    \"\"\"\n    Set the underlying value for a named value.\n\n    Args:\n        name (str): Name of the value to update\n        value (Any): New value to set\n\n    Raises:\n        KeyError: If no value exists with the given name\n        TypeError: If value type doesn't match the expected type\n\n    Example:\n        ```python\n        hash = NamedValueHash()\n        hash.register_value(NamedValue(\"price\", 10.99))\n        hash.set_raw_value(\"price\", 11.99)\n        ```\n    \"\"\"\n    self.get_value(name).value = value\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList","title":"NamedValueList","text":"<p>               Bases: <code>NamedObjectList</code></p> <p>An ordered list container for managing NamedValue objects.</p> <p>NamedValueList maintains an ordered collection of NamedValue objects while providing type safety and convenient access methods. It preserves insertion order while also allowing access by name.</p> <p>Attributes:</p> Name Type Description <code>_registry_category</code> <code>str</code> <p>Category identifier for object registration</p> <code>objects</code> <code>List[SerializeAsAny[InstanceOf[NamedValue]]]</code> <p>The list of stored values</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"first\", 1))\nvalue_list.append(NamedValue(\"second\", 2))\nprint([v.value for v in value_list])  # Outputs: [1, 2]\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; NamedValue\n</code></pre> <p>Get a named value by its index in the list.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the named value to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>The named value at the specified index</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the index is out of range</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(name=\"price\", value=10.5))\nfirst_value = value_list[0] # Get first named value\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; NamedValue:\n    \"\"\"Get a named value by its index in the list.\n\n    Args:\n        idx (int): Index of the named value to retrieve\n\n    Returns:\n        NamedValue: The named value at the specified index\n\n    Raises:\n        IndexError: If the index is out of range\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(name=\"price\", value=10.5))\n        first_value = value_list[0] # Get first named value\n        ```\n    \"\"\"\n    return super().__getitem__(idx)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.append","title":"append","text":"<pre><code>append(value: NamedValue) -&gt; Self\n</code></pre> <p>Append a named value to the end of the list.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NamedValue</code> <p>Named value to append</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The list instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1)).append(NamedValue(\"y\", 2))\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def append(self, value: NamedValue) -&gt; Self:\n    \"\"\"\n    Append a named value to the end of the list.\n\n    Args:\n        value (NamedValue): Named value to append\n\n    Returns:\n        Self: The list instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1)).append(NamedValue(\"y\", 2))\n        ```\n    \"\"\"\n    return super().append(value)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.extend","title":"extend","text":"<pre><code>extend(values: Iterable[NamedValue]) -&gt; Self\n</code></pre> <p>Extend the list with multiple named values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Iterable[NamedValue]</code> <p>Collection of named values to add</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The list instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nnew_values = [NamedValue(\"x\", 1), NamedValue(\"y\", 2)]\nvalue_list.extend(new_values)\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def extend(self, values: Iterable[NamedValue]) -&gt; Self:\n    \"\"\"\n    Extend the list with multiple named values.\n\n    Args:\n        values (Iterable[NamedValue]): Collection of named values to add\n\n    Returns:\n        Self: The list instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        new_values = [NamedValue(\"x\", 1), NamedValue(\"y\", 2)]\n        value_list.extend(new_values)\n        ```\n    \"\"\"\n    return super().extend(values)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.get_value","title":"get_value","text":"<pre><code>get_value(name: str) -&gt; NamedValue\n</code></pre> <p>Get a registered named value by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the value to retrieve</p> required <p>Returns:</p> Name Type Description <code>NamedValue</code> <code>NamedValue</code> <p>The requested named value</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no value exists with the given name</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1))\nx = value_list.get_value(\"x\")\nprint(x.value)  # Outputs: 1\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_value(self, name: str) -&gt; NamedValue:\n    \"\"\"\n    Get a registered named value by name.\n\n    Args:\n        name (str): Name of the value to retrieve\n\n    Returns:\n        NamedValue: The requested named value\n\n    Raises:\n        KeyError: If no value exists with the given name\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1))\n        x = value_list.get_value(\"x\")\n        print(x.value)  # Outputs: 1\n        ```\n    \"\"\"\n    return self.get_object(name)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.get_value_by_type","title":"get_value_by_type","text":"<pre><code>get_value_by_type(value_type: Type) -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all values whose stored value is of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>value_type</code> <code>Type</code> <p>Type to filter values by</p> required <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: Values whose stored value matches the specified type</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1))\nvalue_list.append(NamedValue(\"name\", \"test\"))\nintegers = list(value_list.get_value_by_type(int))\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_value_by_type(self, value_type: Type) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all values whose stored value is of a specific type.\n\n    Args:\n        value_type (Type): Type to filter values by\n\n    Returns:\n        Iterable[NamedValue]: Values whose stored value matches the specified type\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1))\n        value_list.append(NamedValue(\"name\", \"test\"))\n        integers = list(value_list.get_value_by_type(int))\n        ```\n    \"\"\"\n    for value in self.get_values():\n        try:\n            if isinstance(value.value, value_type):\n                yield value\n        except ValueError:\n            # Skip unset values\n            continue\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.get_values","title":"get_values","text":"<pre><code>get_values() -&gt; Iterable[NamedValue]\n</code></pre> <p>Get all registered named values.</p> <p>Returns:</p> Type Description <code>Iterable[NamedValue]</code> <p>Iterable[NamedValue]: Iterator over all stored named values</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.extend([NamedValue(\"x\", 1), NamedValue(\"y\", 2)])\nfor value in value_list.get_values():\n    print(f\"{value.name}: {value.value}\")\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def get_values(self) -&gt; Iterable[NamedValue]:\n    \"\"\"\n    Get all registered named values.\n\n    Returns:\n        Iterable[NamedValue]: Iterator over all stored named values\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.extend([NamedValue(\"x\", 1), NamedValue(\"y\", 2)])\n        for value in value_list.get_values():\n            print(f\"{value.name}: {value.value}\")\n        ```\n    \"\"\"\n    return self.get_objects()\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.model_dump","title":"model_dump","text":"<pre><code>model_dump(**kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Custom serialization to preserve stored values.</p> <p>Extends the parent class serialization to ensure proper serialization of all stored named values and their states.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional serialization options</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing serialized state</p> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Custom serialization to preserve stored values.\n\n    Extends the parent class serialization to ensure proper serialization\n    of all stored named values and their states.\n\n    Args:\n        **kwargs: Additional serialization options\n\n    Returns:\n        dict[str, Any]: Dictionary containing serialized state\n    \"\"\"\n    data = super().model_dump(**kwargs)\n    if 'objects' in data:\n        # Ensure each object's stored value is included\n        data['objects'] = [\n            obj.model_dump(**kwargs) if isinstance(obj, NamedValue) else obj\n            for obj in self.objects\n        ]\n    return data\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(**kwargs) -&gt; str\n</code></pre> <p>Custom JSON serialization of the value list.</p> <p>Serializes the NamedValueList instance and all contained NamedValue objects to a JSON string representation. Preserves the order of values and their complete state.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>JSON serialization options such as: - indent: Number of spaces for pretty printing - ensure_ascii: Escape non-ASCII characters - separators: Tuple of (item_sep, key_sep) for custom formatting</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation of the list</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.append(NamedValue(\"x\", 1))\nvalue_list.append(NamedValue(\"y\", 2))\njson_str = value_list.model_dump_json(indent=2)\nprint(json_str)  # Pretty-printed JSON with ordered values\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def model_dump_json(self, **kwargs) -&gt; str:\n    \"\"\"\n    Custom JSON serialization of the value list.\n\n    Serializes the NamedValueList instance and all contained NamedValue\n    objects to a JSON string representation. Preserves the order of values\n    and their complete state.\n\n    Args:\n        **kwargs: JSON serialization options such as:\n            - indent: Number of spaces for pretty printing\n            - ensure_ascii: Escape non-ASCII characters\n            - separators: Tuple of (item_sep, key_sep) for custom formatting\n\n    Returns:\n        str: JSON string representation of the list\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.append(NamedValue(\"x\", 1))\n        value_list.append(NamedValue(\"y\", 2))\n        json_str = value_list.model_dump_json(indent=2)\n        print(json_str)  # Pretty-printed JSON with ordered values\n        ```\n    \"\"\"\n    # Separate JSON-specific kwargs from model_dump kwargs\n    json_kwargs = {k: v for k, v in kwargs.items() if k in {'indent', 'ensure_ascii', 'separators'}}\n    dump_kwargs = {k: v for k, v in kwargs.items() if k not in json_kwargs}\n\n    # Get model data\n    data = self.model_dump(**dump_kwargs)\n    # Serialize to JSON\n    return json.dumps(data, **json_kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(data: Any) -&gt; NamedValueList\n</code></pre> <p>Custom validation to restore stored values.</p> <p>Reconstructs a NamedValueList instance from serialized data, properly restoring all contained named values and their states.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Serialized data to deserialize</p> required <p>Returns:</p> Name Type Description <code>NamedValueList</code> <code>NamedValueList</code> <p>New instance with restored values</p> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>@classmethod\ndef model_validate(cls, data: Any) -&gt; NamedValueList:\n    \"\"\"\n    Custom validation to restore stored values.\n\n    Reconstructs a NamedValueList instance from serialized data,\n    properly restoring all contained named values and their states.\n\n    Args:\n        data (Any): Serialized data to deserialize\n\n    Returns:\n        NamedValueList: New instance with restored values\n    \"\"\"\n    if not isinstance(data, dict):\n        return super().model_validate(data)\n\n    instance = cls()\n\n    # Process each object in the data\n    for obj_data in data.get('objects', []):\n        if isinstance(obj_data, dict):\n            obj_type = obj_data.get('type')\n            if obj_type:\n                # Get the appropriate class from registry\n                value_class = ObjectRegistry.get(cls._registry_category, obj_type)\n                # Create and validate the object\n                value_obj = value_class.model_validate(obj_data)\n                instance.append(value_obj)\n\n    return instance\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(json_data: str, **kwargs) -&gt; NamedValueList\n</code></pre> <p>Custom JSON deserialization to NamedValueList instance.</p> <p>Reconstructs a NamedValueList instance from a JSON string representation, preserving the order of values and restoring their complete state.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string containing serialized list data</p> required <code>**kwargs</code> <p>Additional validation options for nested objects</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>NamedValueList</code> <code>NamedValueList</code> <p>New instance with all values restored in order</p> Example <pre><code>json_str = '''\n{\n    \"objects\": [\n        {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1},\n        {\"name\": \"y\", \"type\": \"NamedValue\", \"stored_value\": 2}\n    ]\n}\n'''\nvalue_list = NamedValueList.model_validate_json(json_str)\nprint([v.value for v in value_list])  # Outputs: [1, 2]\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>@classmethod\ndef model_validate_json(cls, json_data: str, **kwargs) -&gt; NamedValueList:\n    \"\"\"\n    Custom JSON deserialization to NamedValueList instance.\n\n    Reconstructs a NamedValueList instance from a JSON string representation,\n    preserving the order of values and restoring their complete state.\n\n    Args:\n        json_data (str): JSON string containing serialized list data\n        **kwargs: Additional validation options for nested objects\n\n    Returns:\n        NamedValueList: New instance with all values restored in order\n\n    Example:\n        ```python\n        json_str = '''\n        {\n            \"objects\": [\n                {\"name\": \"x\", \"type\": \"NamedValue\", \"stored_value\": 1},\n                {\"name\": \"y\", \"type\": \"NamedValue\", \"stored_value\": 2}\n            ]\n        }\n        '''\n        value_list = NamedValueList.model_validate_json(json_str)\n        print([v.value for v in value_list])  # Outputs: [1, 2]\n        ```\n    \"\"\"\n    data = json.loads(json_data)\n    return cls.model_validate(data, **kwargs)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueList.register_value","title":"register_value","text":"<pre><code>register_value(value: NamedValue) -&gt; Self\n</code></pre> <p>Register a named value to the list.</p> <p>Similar to append but uses the register_object method internally, which may perform additional validation.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NamedValue</code> <p>Named value to register</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The list instance for method chaining</p> Example <pre><code>value_list = NamedValueList()\nvalue_list.register_value(NamedValue(\"x\", 1))\n</code></pre> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def register_value(self, value: NamedValue) -&gt; Self:\n    \"\"\"\n    Register a named value to the list.\n\n    Similar to append but uses the register_object method internally,\n    which may perform additional validation.\n\n    Args:\n        value (NamedValue): Named value to register\n\n    Returns:\n        Self: The list instance for method chaining\n\n    Example:\n        ```python\n        value_list = NamedValueList()\n        value_list.register_value(NamedValue(\"x\", 1))\n        ```\n    \"\"\"\n    return self.register_object(value)\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueState","title":"NamedValueState","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>State enumeration for NamedValue objects.</p> <p>This enum tracks whether a named value has been set or remains unset. Once set, values are typically frozen unless explicitly forced to change.</p> <p>Attributes:</p> Name Type Description <code>UNSET</code> <p>Indicates no value has been set yet</p> <code>SET</code> <p>Indicates value has been set and is frozen</p>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueState.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Get string representation for debugging.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The state value as a string (\"unset\" or \"set\")</p> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Get string representation for debugging.\n\n    Returns:\n        str: The state value as a string (\"unset\" or \"set\")\n    \"\"\"\n    return self.value  # Returns just \"unset\" or \"set\"\n</code></pre>"},{"location":"reference/data_handlers/values_save/#data_handlers.values_save.NamedValueState.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Convert state to string representation.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The state value as a string (\"unset\" or \"set\")</p> Source code in <code>src/data_handlers/values_save.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Convert state to string representation.\n\n    Returns:\n        str: The state value as a string (\"unset\" or \"set\")\n    \"\"\"\n    return self.value  # Returns just \"unset\" or \"set\"\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/","title":"custom_serde_definitions","text":""},{"location":"reference/data_handlers/custom_serde_definitions/#data_handlers.custom_serde_definitions","title":"custom_serde_definitions","text":"<p>Defines custom serialization and deserialization definitions for the process manager inputs.</p>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/","title":"pandantic","text":""},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic","title":"pandantic","text":"<p>Defines types for Pandas Series and DataFrame serialization and deserialization.</p>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.PandasDataFrame","title":"PandasDataFrame  <code>module-attribute</code>","text":"<pre><code>PandasDataFrame = Annotated[\n    DataFrame, BeforeValidator(to_dataframe), WrapSerializer(from_dataframe)\n]\n</code></pre> <p>Type alias for Pandas DataFrame objects that can be serialized and deserialized. This type alias is used to define the expected data structure when working with Pandas DataFrame objects in a way that allows them to be both serialized and deserialized using the <code>DataFrameSerDe</code> class. The <code>PandasDataFrame</code> type alias is defined as an Annotated type, which means it has two type arguments: <code>pd.DataFrame</code>, which specifies the expected data structure for this type, and a BeforeValidator and PlainSerializer, respectively. This allows you to use Pandas DataFrame objects in your code while ensuring that they can be serialized and deserialized using the <code>DataFrameSerDe</code> class.</p>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.PandasSeries","title":"PandasSeries  <code>module-attribute</code>","text":"<pre><code>PandasSeries = Annotated[Series, BeforeValidator(to_series), WrapSerializer(from_series)]\n</code></pre> <p>Type alias for Pandas Series objects that can be serialized and deserialized. This type alias is used to define the expected data structure when working with Pandas Series objects in a way that allows them to be both serialized and deserialized using the <code>SeriesSerDe</code> class. The <code>PandasSeries</code> type alias is defined as an Annotated type, which means it has two type arguments: <code>pd.Series</code>, which specifies the expected data structure for this type, and a BeforeValidator and PlainSerializer, respectively. This allows you to use Pandas Series objects in your code while ensuring that they can be serialized and deserialized using the <code>SeriesSerDe</code> class.</p>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.DataFrameSerDe","title":"DataFrameSerDe","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class to serialize and deserialize Pandas DataFrame objects.</p> <p>Attributes:</p> Name Type Description <code>columns</code> <code>NDArray[Shape['*'], Any]</code> <p>Column names of the dataframe</p> <code>values</code> <code>NDArray[Shape['*, *'], Any]</code> <p>Values of the dataframe</p> <code>index</code> <code>NDArray[Shape['*'], Any]</code> <p>Index of the dataframe</p> <code>index_name</code> <code>int | str | None</code> <p>Name of the index</p> <code>columns_name</code> <code>list[int | str | None]</code> <p>Names of the columns</p> <p>Methods:     as_dataframe(): Convert to Pandas DataFrame object     from_dict(data: dict) -&gt; DataFrameSerDe: Create a new instance from a dictionary     model_validate_json(json: str | bytes, loc: Any = None, prop: Any = None, cls: Any = None, **kwargs: Any) -&gt; Self: Validate and deserialize JSON data into the model.</p>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.DataFrameSerDe.as_dataframe","title":"as_dataframe","text":"<pre><code>as_dataframe()\n</code></pre> <p>Convert to Pandas DataFrame object.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Pandas DataFrame object from stored data</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>def as_dataframe(self):\n    \"\"\"\n    Convert to Pandas DataFrame object.\n\n    Returns:\n        (pd.DataFrame): Pandas DataFrame object from stored data\n    \"\"\"\n    return pd.DataFrame(\n        self.values, \n        columns=pd.Index(self.columns, name=self.columns_name), \n        index=pd.Index(self.index, name=self.index_name)\n    )\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.DataFrameSerDe.from_dataframe","title":"from_dataframe  <code>classmethod</code>","text":"<pre><code>from_dataframe(df: DataFrame, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)\n</code></pre> <p>Create a new instance from a Pandas DataFrame object.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Pandas DataFrame object to convert.</p> required <p>Returns:</p> Type Description <code>cls</code> <p>New instance created from the Pandas DataFrame object.</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>@classmethod\ndef from_dataframe(cls, df: pd.DataFrame, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo):\n    \"\"\"\n    Create a new instance from a Pandas DataFrame object.\n\n    Args:\n        df (pd.DataFrame): Pandas DataFrame object to convert.\n\n    Returns:\n        (cls): New instance created from the Pandas DataFrame object.\n    \"\"\"\n    return cls(\n        columns=df.columns.values,\n        values=df.values,\n        index=df.index.values,\n        index_name=df.index.name,\n        columns_name=df.columns.name\n    )\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.DataFrameSerDe.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(d: dict)\n</code></pre> <p>Create a new instance from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>Dictionary containing the data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>New DataFrame created from the dictionary.</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>@classmethod\ndef from_dict(cls, d: dict):\n    \"\"\"\n    Create a new instance from a dictionary.\n\n    Args:\n        d (dict): Dictionary containing the data.\n\n    Returns:\n        (pd.DataFrame): New DataFrame created from the dictionary.\n    \"\"\"\n    try:\n        return pd.DataFrame(\n            d['values'],\n            columns=pd.Index(d['columns'], name=d['columns_name']),\n            index=pd.Index(d['index'], name=d['index_name'])\n        )\n    except:\n        raise ValueError(d)\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.DataFrameSerDe.to_dataframe","title":"to_dataframe  <code>classmethod</code>","text":"<pre><code>to_dataframe(input: DataFrame | dict | str)\n</code></pre> <p>Convert input to a Pandas DataFrame object.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>DataFrame | dict | str</code> <p>Input data to convert.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Pandas DataFrame object from input data.</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>@classmethod\ndef to_dataframe(cls, input: pd.DataFrame | dict | str):\n    \"\"\"\n    Convert input to a Pandas DataFrame object.\n\n    Args:\n        input (pd.DataFrame | dict | str): Input data to convert.\n\n    Returns:\n        (pd.DataFrame): Pandas DataFrame object from input data.\n    \"\"\"\n    if isinstance(input, str):\n        return cls.model_validate_json(input).as_dataframe()\n    elif isinstance(input, dict):\n        return cls.from_dict(input)\n    elif isinstance(input, pd.DataFrame):\n        return input\n    else:\n        # breakpoint()\n        raise ValueError(input)\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.SeriesSerDe","title":"SeriesSerDe","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class to serialize and deserialize Pandas Series objects.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>int | str | None</code> <p>Name of the series</p> <code>values</code> <code>NDArray[Shape['*'], Any]</code> <p>Values of the series</p> <code>index</code> <code>NDArray[Shape['*'], Any]</code> <p>Index of the series</p> <code>index_name</code> <code>int | str | None</code> <p>Name of the index</p> <p>Methods:     as_series(): Convert to Pandas Series object     from_dict(data: dict) -&gt; SeriesSerDe: Create a new instance from a dictionary     model_validate_json(json: str | bytes, loc: Any = None, prop: Any = None, cls: Any = None, **kwargs: Any) -&gt; Self: Validate and deserialize JSON data into the model.</p>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.SeriesSerDe.as_series","title":"as_series","text":"<pre><code>as_series()\n</code></pre> <p>Convert to Pandas Series object.</p> <p>Returns:</p> Type Description <code>Series</code> <p>Pandas Series object from stored data</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>def as_series(self):\n    \"\"\"\n    Convert to Pandas Series object.\n\n    Returns:\n        (pd.Series): Pandas Series object from stored data\n    \"\"\"\n    return pd.Series(self.values, name=self.name, index=pd.Index(self.index, name=self.index_name))\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.SeriesSerDe.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(d: dict)\n</code></pre> <p>Create a new instance from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>Dictionary containing the data.</p> required <p>Returns:</p> Type Description <code>cls</code> <p>New instance created from the dictionary.</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>@classmethod\ndef from_dict(cls, d: dict):\n    \"\"\"\n    Create a new instance from a dictionary.\n\n    Args:\n        d (dict): Dictionary containing the data.\n\n    Returns:\n        (cls): New instance created from the dictionary.\n    \"\"\"\n    try:\n        return pd.Series(\n            d['values'], \n            name=d['name'],\n            index=pd.Index(\n                d['index'], \n                name=d['index_name'],\n            ),\n        )\n    except:\n        raise ValueError(d)\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.SeriesSerDe.from_series","title":"from_series  <code>classmethod</code>","text":"<pre><code>from_series(series: Series, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)\n</code></pre> <p>Create a new instance from a Pandas Series object.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Pandas Series object to convert.</p> required <p>Returns:</p> Type Description <code>cls</code> <p>New instance created from the Pandas Series object.</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>@classmethod\ndef from_series(cls, series: pd.Series, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo):\n    \"\"\"\n    Create a new instance from a Pandas Series object.\n\n    Args:\n        series (pd.Series): Pandas Series object to convert.\n\n    Returns:\n        (cls): New instance created from the Pandas Series object.\n    \"\"\"\n    return cls(\n        name=series.name,\n        values=series.values,\n        index=series.index.values,\n        index_name=series.index.name,\n    )\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.SeriesSerDe.to_series","title":"to_series  <code>classmethod</code>","text":"<pre><code>to_series(input: Series | dict | str)\n</code></pre> <p>Convert input to a Pandas Series object.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Series | dict | str</code> <p>Input data to convert.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>Pandas Series object from input data.</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>@classmethod\ndef to_series(cls, input: pd.Series | dict | str):\n    \"\"\"\n    Convert input to a Pandas Series object.\n\n    Args:\n        input (pd.Series | dict | str): Input data to convert.\n\n    Returns:\n        (pd.Series): Pandas Series object from input data.\n    \"\"\"\n    if isinstance(input, str):\n        print('str')\n        return cls.model_validate_json(input).as_series()\n    elif isinstance(input, dict):\n        print('dict')\n        return cls.from_dict(input)\n    elif isinstance(input, pd.Series):\n        print('series')\n        return input\n    else:\n        raise ValueError(input)\n</code></pre>"},{"location":"reference/data_handlers/custom_serde_definitions/pandantic/#data_handlers.custom_serde_definitions.pandantic.np_encoder","title":"np_encoder","text":"<pre><code>np_encoder(object)\n</code></pre> <p>JSON encoder function for numpy types.</p> <p>Parameters:</p> Name Type Description Default <code>object</code> <code>Any</code> <p>Object to encode</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Encoded object</p> Source code in <code>src/data_handlers/custom_serde_definitions/pandantic.py</code> <pre><code>def np_encoder(object):\n    \"\"\"\n    JSON encoder function for numpy types.\n\n    Args:\n        object (Any): Object to encode\n\n    Returns:\n        Any: Encoded object\n    \"\"\"\n    if isinstance(object, np.generic):\n        return object.item()\n    else:\n        return object\n</code></pre>"},{"location":"reference/flow/","title":"flow","text":""},{"location":"reference/flow/#flow","title":"flow","text":"<p>Flow package for managing complex workflows.</p>"},{"location":"reference/flow/#flow.Flow","title":"Flow","text":"<pre><code>Flow(\n    name: str,\n    callable: Callable[[Any], Any],\n    flow_tree: Optional[FlowTree] = None,\n    required_prerequisites: Optional[List[Flow]] = None,\n    optional_prerequisites: Optional[List[Flow]] = None,\n)\n</code></pre> <p>Core flow implementation.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    callable: Callable[[Any], Any],\n    flow_tree: Optional[FlowTree] = None,\n    required_prerequisites: Optional[List[Flow]] = None,\n    optional_prerequisites: Optional[List[Flow]] = None,\n):\n    self.callable = callable\n    self.config = FlowConfig(name=name)\n    self.status = FlowStatus.PENDING\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.config.name})\")\n    self._flow_tree = None\n\n\n    if flow_tree is not None:\n        self.register_to_flow_tree(flow_tree)\n\n    if required_prerequisites is not None:\n        assert flow_tree is not None\n        for prereq in required_prerequisites:\n            flow_tree.add_prerequisite(flow_id=self.id, prerequisite_id=prereq.id)\n\n    if optional_prerequisites is not None:\n        assert flow_tree is not None\n        for prereq in optional_prerequisites:\n            flow_tree.add_prerequisite(flow_id=self.id, prerequisite_id=prereq.id)\n</code></pre>"},{"location":"reference/flow/#flow.Flow.add_prerequisite","title":"add_prerequisite","text":"<pre><code>add_prerequisite(prerequisite_flow: Flow) -&gt; None\n</code></pre> <p>Add a prerequisite flow.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def add_prerequisite(self, prerequisite_flow: Flow) -&gt; None:\n    \"\"\"Add a prerequisite flow.\"\"\"\n    self._flow_tree.add_prerequisite(self.id, prerequisite_flow.id)\n</code></pre>"},{"location":"reference/flow/#flow.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Dict[str, Any]) -&gt; FlowResult\n</code></pre> <p>Execute the flow.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def execute(self, input_data: Dict[str, Any]) -&gt; FlowResult:\n    \"\"\"Execute the flow.\"\"\"\n    logger.debug(f\"Executing flow {self.config.name} with input: {input_data}\")\n    start_time = datetime.now()\n    self.status = FlowStatus.RUNNING\n\n    try:\n        output = self.callable(input_data)\n        logger.debug(f\"Flow {self.config.name} produced output: {output}\")\n\n        result = FlowResult.create_completed(\n            process_id=self.config.name,\n            output=output,\n            start_time=start_time,\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.COMPLETED\n\n    except Exception as e:\n        logger.error(f\"Flow {self.config.name} execution failed: {e}\")\n        result = FlowResult.create_failed(\n            process_id=self.config.name,\n            error=str(e),\n            start_time=start_time,\n            traceback=traceback.format_exc(),\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.FAILED\n        raise\n\n    return result\n</code></pre>"},{"location":"reference/flow/#flow.FlowError","title":"FlowError","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for flow errors.</p>"},{"location":"reference/flow/#flow.FlowExecutionError","title":"FlowExecutionError","text":"<pre><code>FlowExecutionError(message: str, traceback: str)\n</code></pre> <p>               Bases: <code>FlowError</code></p> <p>Error during flow execution.</p> Source code in <code>src/flow/core/errors.py</code> <pre><code>def __init__(self, message: str, traceback: str):\n    super().__init__(message)\n    self.traceback = traceback\n</code></pre>"},{"location":"reference/flow/#flow.FlowResult","title":"FlowResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Immutable result of a completed flow execution.</p>"},{"location":"reference/flow/#flow.FlowResult.create_completed","title":"create_completed  <code>classmethod</code>","text":"<pre><code>create_completed(\n    process_id: str,\n    output: Dict[str, Any],\n    start_time: datetime,\n    metadata: Optional[Dict[str, Any]] = None,\n) -&gt; FlowResult\n</code></pre> <p>Create a result for a completed flow.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>@classmethod\ndef create_completed(\n    cls, \n    process_id: str,\n    output: Dict[str, Any],\n    start_time: datetime,\n    metadata: Optional[Dict[str, Any]] = None\n) -&gt; FlowResult:\n    \"\"\"Create a result for a completed flow.\"\"\"\n    return cls(\n        process_id=process_id,\n        status=FlowStatus.COMPLETED,\n        start_time=start_time,\n        end_time=datetime.now(),\n        output=output,\n        metadata=metadata or {}\n    )\n</code></pre>"},{"location":"reference/flow/#flow.FlowResult.create_failed","title":"create_failed  <code>classmethod</code>","text":"<pre><code>create_failed(\n    process_id: str,\n    error: str,\n    start_time: datetime,\n    traceback: Optional[str] = None,\n    metadata: Optional[Dict[str, Any]] = None,\n) -&gt; \"FlowResult\"\n</code></pre> <p>Create a result for a failed flow.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>@classmethod\ndef create_failed(\n    cls,\n    process_id: str,\n    error: str,\n    start_time: datetime,\n    traceback: Optional[str] = None,\n    metadata: Optional[Dict[str, Any]] = None\n) -&gt; 'FlowResult':\n    \"\"\"Create a result for a failed flow.\"\"\"\n    return cls(\n        process_id=process_id,\n        status=FlowStatus.FAILED,\n        start_time=start_time,\n        end_time=datetime.now(),\n        error=error,\n        traceback=traceback,\n        metadata=metadata or {}\n    )\n</code></pre>"},{"location":"reference/flow/#flow.FlowRetryError","title":"FlowRetryError","text":"<pre><code>FlowRetryError(message: str, original_error: Exception)\n</code></pre> <p>               Bases: <code>FlowError</code></p> <p>Flow retry attempts exhausted.</p> Source code in <code>src/flow/core/errors.py</code> <pre><code>def __init__(self, message: str, original_error: Exception):\n    super().__init__(message)\n    self.original_error = original_error\n</code></pre>"},{"location":"reference/flow/#flow.FlowStatus","title":"FlowStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Status of flow execution.</p>"},{"location":"reference/flow/#flow.FlowTimeoutError","title":"FlowTimeoutError","text":"<p>               Bases: <code>FlowError</code></p> <p>Flow execution timed out.</p>"},{"location":"reference/flow/#flow.FlowType","title":"FlowType","text":"<p>               Bases: <code>Enum</code></p> <p>Type of flow execution.</p>"},{"location":"reference/flow/#flow.MissingDependencyError","title":"MissingDependencyError","text":"<p>               Bases: <code>FlowError</code></p> <p>Required dependency not found.</p>"},{"location":"reference/flow/#flow.StorageType","title":"StorageType","text":"<p>               Bases: <code>Enum</code></p> <p>Type of result storage.</p>"},{"location":"reference/flow/core/","title":"core","text":""},{"location":"reference/flow/core/#flow.core","title":"core","text":"<p>Core components of the flow package.</p>"},{"location":"reference/flow/core/context/","title":"context","text":""},{"location":"reference/flow/core/context/#flow.core.context","title":"context","text":"<p>Flow context management and coordination.</p>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext","title":"FlowContext","text":"<pre><code>FlowContext()\n</code></pre> <p>Central manager for flow coordination and service access.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def __init__(self):\n    if FlowContext._instance is not None:\n        raise RuntimeError(\"FlowContext is a singleton - use get_instance()\")\n\n    self._flow_graph = nx.DiGraph()\n    self._flows: Dict[str, Flow] = {}\n    self._status_locks: Dict[str, asyncio.Lock] = {}\n    self._execution_locks: Dict[str, asyncio.Lock] = {}\n\n    # Initialize managers\n    self.results_manager = ResultsManager(context=self)\n\n    from flow.execution.pool import ProcessPoolManager\n    self.pool_manager = ProcessPoolManager()\n\n    logger.info(\"FlowContext initialized\")\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.cleanup","title":"cleanup","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Cleanup all managers and resources.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup all managers and resources.\"\"\"\n    self.pool_manager.shutdown()\n    self.results_manager.cleanup()\n    self._flows.clear()\n    self._flow_graph.clear()\n    self._status_locks.clear()\n    self._execution_locks.clear()\n    logger.info(\"FlowContext cleaned up\")\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.fail_flow","title":"fail_flow  <code>async</code>","text":"<pre><code>fail_flow(process_id: str, reason: str) -&gt; None\n</code></pre> <p>Mark a flow as failed with the given reason.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>async def fail_flow(self, process_id: str, reason: str) -&gt; None:\n    \"\"\"Mark a flow as failed with the given reason.\"\"\"\n    flow = self._flows.get(process_id)\n    if not flow:\n        return\n    from flow.core.flow import FlowResult\n    async with self._status_locks[process_id]:\n        flow.status = FlowStatus.FAILED\n        await self.results_manager.save_result(\n            process_id,\n            FlowResult(\n                process_id=process_id,\n                status=FlowStatus.FAILED,\n                error=reason,\n                start_time=datetime.now(),\n                end_time=datetime.now()\n            )\n        )\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.get_flow","title":"get_flow","text":"<pre><code>get_flow(process_id: str) -&gt; Optional[Flow]\n</code></pre> <p>Get a flow by its process ID.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def get_flow(self, process_id: str) -&gt; Optional[Flow]:\n    \"\"\"Get a flow by its process ID.\"\"\"\n    return self._flows.get(process_id)\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.get_instance","title":"get_instance  <code>classmethod</code>","text":"<pre><code>get_instance() -&gt; FlowContext\n</code></pre> <p>Get or create the singleton instance.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>@classmethod\ndef get_instance(cls) -&gt; FlowContext:\n    \"\"\"Get or create the singleton instance.\"\"\"\n    if cls._instance is None:\n        cls._instance = cls()\n    return cls._instance\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.handle_flow_failure","title":"handle_flow_failure  <code>async</code>","text":"<pre><code>handle_flow_failure(process_id: str) -&gt; None\n</code></pre> <p>Handle flow failure and notify dependent flows.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>async def handle_flow_failure(self, process_id: str) -&gt; None:\n    \"\"\"Handle flow failure and notify dependent flows.\"\"\"\n    flow = self._flows.get(process_id)\n    if not flow:\n        return\n\n    async with self._status_locks[process_id]:\n        # Get all dependent flows\n        dependent_flows = set(self._flow_graph.successors(process_id))\n\n        for dep_id in dependent_flows:\n            dep_flow = self._flows.get(dep_id)\n            if not dep_flow:\n                continue\n\n            # If this was an optional dependency, mark it as skipped\n            if process_id in dep_flow.get_dependencies(DependencyType.OPTIONAL):\n                logger.warning(f\"Optional dependency {process_id} failed for {dep_id}\")\n                continue\n\n            # For required dependencies, fail the dependent flow\n            logger.error(f\"Required dependency {process_id} failed - failing {dep_id}\")\n            await self.fail_flow(dep_id, f\"Required dependency {process_id} failed\")\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.has_cycle","title":"has_cycle","text":"<pre><code>has_cycle(start_id: str) -&gt; bool\n</code></pre> <p>Check if adding a flow would create a cycle.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def has_cycle(self, start_id: str) -&gt; bool:\n    \"\"\"Check if adding a flow would create a cycle.\"\"\"\n    try:\n        nx.find_cycle(self._flow_graph, source=start_id)\n        return True\n    except nx.NetworkXNoCycle:\n        return False\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.register_dependency","title":"register_dependency","text":"<pre><code>register_dependency(parent_id: str, child_id: str) -&gt; None\n</code></pre> <p>Register a dependency relationship between flows.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def register_dependency(self, parent_id: str, child_id: str) -&gt; None:\n    \"\"\"Register a dependency relationship between flows.\"\"\"\n    if parent_id not in self._flows or child_id not in self._flows:\n        raise FlowError(f\"Cannot register dependency - flows not found\")\n\n    self._flow_graph.add_edge(parent_id, child_id)\n\n    # Validate no cycles were created\n    if not nx.is_directed_acyclic_graph(self._flow_graph):\n        self._flow_graph.remove_edge(parent_id, child_id)\n        raise FlowError(\"Adding dependency would create a cycle\")\n\n    logger.debug(f\"Registered dependency: {parent_id} -&gt; {child_id}\")\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.register_flow","title":"register_flow","text":"<pre><code>register_flow(flow: Flow) -&gt; None\n</code></pre> <p>Register a flow with the context.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def register_flow(self, flow: Flow) -&gt; None:\n    \"\"\"Register a flow with the context.\"\"\"\n    if flow.process_id in self._flows:\n        raise FlowError(f\"Flow with id {flow.process_id} already registered\")\n\n    self._flows[flow.process_id] = flow\n    self._flow_graph.add_node(flow.process_id)\n    self._status_locks[flow.process_id] = asyncio.Lock()\n    self._execution_locks[flow.process_id] = asyncio.Lock()\n\n    logger.debug(f\"Registered flow: {flow.process_id}\")\n</code></pre>"},{"location":"reference/flow/core/context/#flow.core.context.FlowContext.wait_for_flows","title":"wait_for_flows  <code>async</code>","text":"<pre><code>wait_for_flows(flow_ids: Set[str], timeout: Optional[float] = None) -&gt; None\n</code></pre> <p>Wait for multiple flows to complete.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>async def wait_for_flows(self, flow_ids: Set[str], timeout: Optional[float] = None) -&gt; None:\n    \"\"\"Wait for multiple flows to complete.\"\"\"\n    if not flow_ids:\n        return\n\n    async def wait_for_flow(flow_id: str) -&gt; None:\n        flow = self._flows.get(flow_id)\n        if not flow:\n            raise FlowError(f\"Flow {flow_id} not found\")\n\n        async with self._status_locks[flow_id]:\n            while flow.status not in (FlowStatus.COMPLETED, FlowStatus.FAILED):\n                await asyncio.sleep(0.1)\n\n    # Wait for all flows with timeout\n    wait_tasks = [wait_for_flow(fid) for fid in flow_ids]\n    try:\n        await asyncio.wait_for(asyncio.gather(*wait_tasks), timeout=timeout)\n    except asyncio.TimeoutError:\n        raise FlowError(f\"Timeout waiting for flows: {flow_ids}\")\n</code></pre>"},{"location":"reference/flow/core/errors/","title":"errors","text":""},{"location":"reference/flow/core/errors/#flow.core.errors","title":"errors","text":"<p>Custom exceptions for the flow package.</p>"},{"location":"reference/flow/core/errors/#flow.core.errors.FlowError","title":"FlowError","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for flow errors.</p>"},{"location":"reference/flow/core/errors/#flow.core.errors.FlowExecutionError","title":"FlowExecutionError","text":"<pre><code>FlowExecutionError(message: str, traceback: str)\n</code></pre> <p>               Bases: <code>FlowError</code></p> <p>Error during flow execution.</p> Source code in <code>src/flow/core/errors.py</code> <pre><code>def __init__(self, message: str, traceback: str):\n    super().__init__(message)\n    self.traceback = traceback\n</code></pre>"},{"location":"reference/flow/core/errors/#flow.core.errors.FlowRetryError","title":"FlowRetryError","text":"<pre><code>FlowRetryError(message: str, original_error: Exception)\n</code></pre> <p>               Bases: <code>FlowError</code></p> <p>Flow retry attempts exhausted.</p> Source code in <code>src/flow/core/errors.py</code> <pre><code>def __init__(self, message: str, original_error: Exception):\n    super().__init__(message)\n    self.original_error = original_error\n</code></pre>"},{"location":"reference/flow/core/errors/#flow.core.errors.FlowTimeoutError","title":"FlowTimeoutError","text":"<p>               Bases: <code>FlowError</code></p> <p>Flow execution timed out.</p>"},{"location":"reference/flow/core/errors/#flow.core.errors.MissingDependencyError","title":"MissingDependencyError","text":"<p>               Bases: <code>FlowError</code></p> <p>Required dependency not found.</p>"},{"location":"reference/flow/core/f1/","title":"f1","text":""},{"location":"reference/flow/core/f1/#flow.core.f1","title":"f1","text":"<p>Fixed Flow implementation that properly abstracts execution details.</p>"},{"location":"reference/flow/core/f1/#flow.core.f1.Flow","title":"Flow","text":"<pre><code>Flow(processor: Any, config: FlowConfig, process_id: Optional[str] = None)\n</code></pre> <p>Core flow implementation that wraps user-defined processors.</p> Source code in <code>src/flow/core/f1.py</code> <pre><code>def __init__(\n    self,\n    processor: Any,\n    config: FlowConfig,\n    process_id: Optional[str] = None\n):\n    from flow.core.context import FlowContext\n\n    self.processor = processor\n    self.config = config\n    self.process_id = process_id or str(uuid.uuid4())\n    self.context = FlowContext.get_instance()\n\n    # Flow state\n    self.status = FlowStatus.PENDING\n    self._parent_flow = None\n    self._dependencies: Dict[str, DependencyType] = {}\n    self._dependent_flows: Set[str] = set()\n\n    # Initialize logger\n    self.logger = logging.getLogger(f\"flow.{self.config.name}\")\n\n    # Register with context\n    self.context.register_flow(self)\n\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.process_id})\")\n</code></pre>"},{"location":"reference/flow/core/f1/#flow.core.f1.Flow.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancel the flow execution.</p> Source code in <code>src/flow/core/f1.py</code> <pre><code>async def cancel(self) -&gt; None:\n    \"\"\"Cancel the flow execution.\"\"\"\n    if self.status == FlowStatus.RUNNING:\n        await self.context.pool_manager.cancel_task(self.process_id)\n        self.status = FlowStatus.CANCELLED\n</code></pre>"},{"location":"reference/flow/core/f1/#flow.core.f1.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Optional[Dict[str, Any]] = None) -&gt; FlowResult\n</code></pre> <p>Execute the flow and its dependencies.</p> <p>This is the public interface that users should call.</p> Source code in <code>src/flow/core/f1.py</code> <pre><code>async def execute(\n        self,\n        input_data: Optional[Dict[str, Any]] = None\n    ) -&gt; FlowResult:\n    \"\"\"Execute the flow and its dependencies.\n\n    This is the public interface that users should call.\n    \"\"\"\n    monitoring_service = MonitoringService.get_instance()\n\n    async with monitoring_service.monitor_flow(self):\n        try:\n            await monitoring_service.record_flow_event(\n                self,\n                \"execution_started\",\n                f\"Started execution of flow {self.config.name}\",\n                LoggingLevel.INFO\n            )\n\n            result = await self._execute_with_dependencies(input_data or {})\n\n            await monitoring_service.record_flow_event(\n                self,\n                \"execution_completed\",\n                f\"Completed execution of flow {self.config.name}\",\n                LoggingLevel.INFO,\n                {\"status\": result.status}\n            )\n\n            return result\n\n        except Exception as e:\n            await monitoring_service.record_flow_event(\n                self,\n                \"execution_failed\",\n                f\"Flow {self.config.name} failed: {str(e)}\",\n                LoggingLevel.ERROR\n            )\n            raise\n</code></pre>"},{"location":"reference/flow/core/f1/#flow.core.f1.Flow.register_to","title":"register_to","text":"<pre><code>register_to(\n    parent_flow: \"Flow\",\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None,\n) -&gt; None\n</code></pre> <p>Register this flow as a child of another flow.</p> Source code in <code>src/flow/core/f1.py</code> <pre><code>def register_to(\n    self,\n    parent_flow: 'Flow',\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None\n) -&gt; None:\n    \"\"\"Register this flow as a child of another flow.\"\"\"\n    self._parent_flow = parent_flow\n\n    # Register dependencies\n    if required_deps:\n        for dep_id in required_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Required dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.REQUIRED\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n\n    if optional_deps:\n        for dep_id in optional_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Optional dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.OPTIONAL\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n</code></pre>"},{"location":"reference/flow/core/f1/#flow.core.f1.FlowConfig","title":"FlowConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a flow.</p>"},{"location":"reference/flow/core/f1/#flow.core.f1.FlowResult","title":"FlowResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a flow execution.</p>"},{"location":"reference/flow/core/f2/","title":"f2","text":""},{"location":"reference/flow/core/f2/#flow.core.f2","title":"f2","text":"<p>Fixed Flow implementation that properly abstracts execution details.</p>"},{"location":"reference/flow/core/f2/#flow.core.f2.Flow","title":"Flow","text":"<pre><code>Flow(processor: Any, config: FlowConfig, process_id: Optional[str] = None)\n</code></pre> <p>Core flow implementation that wraps user-defined processors.</p> Source code in <code>src/flow/core/f2.py</code> <pre><code>def __init__(\n    self,\n    processor: Any,\n    config: FlowConfig,\n    process_id: Optional[str] = None\n):\n    from flow.core.context import FlowContext\n\n    self.processor = processor\n    self.config = config\n    self.process_id = process_id or str(uuid.uuid4())\n    self.context = FlowContext.get_instance()\n\n    # Flow state\n    self.status = FlowStatus.PENDING\n    self._parent_flow = None\n    self._dependencies: Dict[str, DependencyType] = {}\n    self._dependent_flows: Set[str] = set()\n\n    # Register with context\n    self.context.register_flow(self)\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.process_id})\")\n</code></pre>"},{"location":"reference/flow/core/f2/#flow.core.f2.Flow.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancel the flow execution.</p> Source code in <code>src/flow/core/f2.py</code> <pre><code>async def cancel(self) -&gt; None:\n    \"\"\"Cancel the flow execution.\"\"\"\n    if self.status == FlowStatus.RUNNING:\n        await self.context.pool_manager.cancel_task(self.process_id)\n        self.status = FlowStatus.CANCELLED\n</code></pre>"},{"location":"reference/flow/core/f2/#flow.core.f2.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Optional[Dict[str, Any]] = None) -&gt; FlowResult\n</code></pre> <p>Execute the flow and its dependencies.</p> Source code in <code>src/flow/core/f2.py</code> <pre><code>async def execute(\n    self,\n    input_data: Optional[Dict[str, Any]] = None\n) -&gt; FlowResult:\n    \"\"\"Execute the flow and its dependencies.\"\"\"\n    logger.debug(f\"Starting execution of flow {self.config.name} ({self.process_id})\")\n    input_data = input_data or {}\n\n    # Initialize result first\n    result = FlowResult(\n        process_id=self.process_id,\n        status=FlowStatus.RUNNING,\n        start_time=datetime.now(),\n        metadata={}\n    )\n\n    try:\n        # Set status before dependency execution\n        self.status = FlowStatus.RUNNING\n        logger.debug(f\"Flow {self.config.name} status set to RUNNING\")\n\n        # Execute dependencies\n        logger.debug(f\"Executing dependencies for {self.config.name}\")\n        deps_data = await self._execute_dependencies(input_data)\n        logger.debug(f\"Dependencies completed for {self.config.name}\")\n\n        # Merge input data\n        execution_data = {**deps_data, **input_data}\n        logger.debug(f\"Prepared execution data for {self.config.name}\")\n\n        # Execute processor\n        logger.debug(f\"Executing processor for {self.config.name}\")\n        try:\n            # Direct execution without process pool for debugging\n            if hasattr(self.processor, 'process'):\n                output = self.processor.process(execution_data)\n            else:\n                output = self.processor(execution_data)\n\n            # Ensure output is a dictionary\n            if not isinstance(output, dict):\n                output = {\"result\": output}\n\n            logger.debug(f\"Processor execution completed for {self.config.name}\")\n\n            # Update result\n            result.status = FlowStatus.COMPLETED\n            result.output = output\n            self.status = FlowStatus.COMPLETED\n\n        except Exception as e:\n            logger.error(f\"Processor execution failed for {self.config.name}: {e}\")\n            result.status = FlowStatus.FAILED\n            result.error = str(e)\n            result.traceback = traceback.format_exc()\n            self.status = FlowStatus.FAILED\n            raise\n\n    except Exception as e:\n        logger.error(f\"Flow execution failed for {self.config.name}: {e}\")\n        result.status = FlowStatus.FAILED\n        result.error = str(e)\n        result.traceback = traceback.format_exc()\n        self.status = FlowStatus.FAILED\n        raise\n\n    finally:\n        # Always save result and update timing\n        result.end_time = datetime.now()\n        logger.debug(f\"Saving result for {self.config.name}\")\n        await self.context.results_manager.save_result(\n            self.process_id,\n            result\n        )\n        logger.debug(f\"Result saved for {self.config.name}\")\n\n    logger.debug(f\"Flow {self.config.name} execution completed with status {result.status}\")\n    return result\n</code></pre>"},{"location":"reference/flow/core/f2/#flow.core.f2.Flow.get_dependencies","title":"get_dependencies","text":"<pre><code>get_dependencies(dep_type: Optional[DependencyType] = None) -&gt; Set[str]\n</code></pre> <p>Get set of dependency process IDs, optionally filtered by type.</p> Source code in <code>src/flow/core/f2.py</code> <pre><code>def get_dependencies(self, dep_type: Optional[DependencyType] = None) -&gt; Set[str]:\n    \"\"\"Get set of dependency process IDs, optionally filtered by type.\"\"\"\n    if dep_type is None:\n        return set(self._dependencies.keys())\n    return {\n        dep_id for dep_id, dtype in self._dependencies.items() \n        if dtype == dep_type\n    }\n</code></pre>"},{"location":"reference/flow/core/f2/#flow.core.f2.Flow.register_to","title":"register_to","text":"<pre><code>register_to(\n    parent_flow: \"Flow\",\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None,\n) -&gt; None\n</code></pre> <p>Register this flow as a child of another flow.</p> Source code in <code>src/flow/core/f2.py</code> <pre><code>def register_to(\n    self,\n    parent_flow: 'Flow',\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None\n) -&gt; None:\n    \"\"\"Register this flow as a child of another flow.\"\"\"\n    self._parent_flow = parent_flow\n\n    # Register dependencies\n    if required_deps:\n        for dep_id in required_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Required dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.REQUIRED\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n\n    if optional_deps:\n        for dep_id in optional_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Optional dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.OPTIONAL\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n</code></pre>"},{"location":"reference/flow/core/f2/#flow.core.f2.FlowConfig","title":"FlowConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a flow.</p>"},{"location":"reference/flow/core/f2/#flow.core.f2.FlowResult","title":"FlowResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a flow execution.</p>"},{"location":"reference/flow/core/f3/","title":"f3","text":""},{"location":"reference/flow/core/f3/#flow.core.f3","title":"f3","text":"<p>Fixed Flow implementation that properly abstracts execution details.</p>"},{"location":"reference/flow/core/f3/#flow.core.f3.Flow","title":"Flow","text":"<pre><code>Flow(processor: Any, config: FlowConfig, process_id: Optional[str] = None)\n</code></pre> <p>Core flow implementation that wraps user-defined processors.</p> Source code in <code>src/flow/core/f3.py</code> <pre><code>def __init__(\n    self,\n    processor: Any,\n    config: FlowConfig,\n    process_id: Optional[str] = None\n):\n    from flow.core.context import FlowContext\n\n    self.processor = processor\n    self.config = config\n    self.process_id = process_id or str(uuid.uuid4())\n    self.context = FlowContext.get_instance()\n\n    # Flow state\n    self.status = FlowStatus.PENDING\n    self._parent_flow = None\n    self._dependencies: Dict[str, DependencyType] = {}\n    self._dependent_flows: Set[str] = set()\n\n    # Register with context\n    self.context.register_flow(self)\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.process_id})\")\n</code></pre>"},{"location":"reference/flow/core/f3/#flow.core.f3.Flow.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancel the flow execution.</p> Source code in <code>src/flow/core/f3.py</code> <pre><code>async def cancel(self) -&gt; None:\n    \"\"\"Cancel the flow execution.\"\"\"\n    if self.status == FlowStatus.RUNNING:\n        await self.context.pool_manager.cancel_task(self.process_id)\n        self.status = FlowStatus.CANCELLED\n</code></pre>"},{"location":"reference/flow/core/f3/#flow.core.f3.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Optional[Dict[str, Any]] = None) -&gt; FlowResult\n</code></pre> <p>Execute the flow and its dependencies.</p> Source code in <code>src/flow/core/f3.py</code> <pre><code>async def execute(\n    self,\n    input_data: Optional[Dict[str, Any]] = None\n) -&gt; FlowResult:\n    \"\"\"Execute the flow and its dependencies.\"\"\"\n    logger.debug(f\"Starting execution of flow {self.config.name} ({self.process_id})\")\n    input_data = input_data or {}\n\n    # Initialize result first\n    result = FlowResult(\n        process_id=self.process_id,\n        status=FlowStatus.RUNNING,\n        start_time=datetime.now(),\n        metadata={}\n    )\n\n    try:\n        # Set status before dependency execution\n        self.status = FlowStatus.RUNNING\n        logger.debug(f\"Flow {self.config.name} status set to RUNNING\")\n\n        # Execute dependencies\n        logger.debug(f\"Executing dependencies for {self.config.name}\")\n        deps_data = await self._execute_dependencies(input_data)\n        logger.debug(f\"Dependencies completed for {self.config.name}\")\n\n        # Merge input data\n        execution_data = {**deps_data, **input_data}\n        logger.debug(f\"Prepared execution data for {self.config.name}\")\n\n        # Execute processor\n        logger.debug(f\"Executing processor for {self.config.name}\")\n        try:\n            # Direct execution without process pool for debugging\n            if hasattr(self.processor, 'process'):\n                output = self.processor.process(execution_data)\n            else:\n                output = self.processor(execution_data)\n\n            # Ensure output is a dictionary\n            if not isinstance(output, dict):\n                output = {\"result\": output}\n\n            logger.debug(f\"Processor execution completed for {self.config.name}\")\n\n            # Update result\n            result.status = FlowStatus.COMPLETED\n            result.output = output\n            self.status = FlowStatus.COMPLETED\n\n        except Exception as e:\n            logger.error(f\"Processor execution failed for {self.config.name}: {e}\")\n            result.status = FlowStatus.FAILED\n            result.error = str(e)\n            result.traceback = traceback.format_exc()\n            self.status = FlowStatus.FAILED\n            raise\n\n    except Exception as e:\n        logger.error(f\"Flow execution failed for {self.config.name}: {e}\")\n        result.status = FlowStatus.FAILED\n        result.error = str(e)\n        result.traceback = traceback.format_exc()\n        self.status = FlowStatus.FAILED\n        raise\n\n    finally:\n        # Always save result and update timing\n        result.end_time = datetime.now()\n        logger.debug(f\"Saving result for {self.config.name}\")\n        await self.context.results_manager.save_result(\n            self.process_id,\n            result\n        )\n        logger.debug(f\"Result saved for {self.config.name}\")\n\n    logger.debug(f\"Flow {self.config.name} execution completed with status {result.status}\")\n    return result\n</code></pre>"},{"location":"reference/flow/core/f3/#flow.core.f3.Flow.get_dependencies","title":"get_dependencies","text":"<pre><code>get_dependencies(dep_type: Optional[DependencyType] = None) -&gt; Set[str]\n</code></pre> <p>Get set of dependency process IDs, optionally filtered by type.</p> Source code in <code>src/flow/core/f3.py</code> <pre><code>def get_dependencies(self, dep_type: Optional[DependencyType] = None) -&gt; Set[str]:\n    \"\"\"Get set of dependency process IDs, optionally filtered by type.\"\"\"\n    if dep_type is None:\n        return set(self._dependencies.keys())\n    return {\n        dep_id for dep_id, dtype in self._dependencies.items() \n        if dtype == dep_type\n    }\n</code></pre>"},{"location":"reference/flow/core/f3/#flow.core.f3.Flow.register_to","title":"register_to","text":"<pre><code>register_to(\n    parent_flow: \"Flow\",\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None,\n) -&gt; None\n</code></pre> <p>Register this flow as a child of another flow.</p> Source code in <code>src/flow/core/f3.py</code> <pre><code>def register_to(\n    self,\n    parent_flow: 'Flow',\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None\n) -&gt; None:\n    \"\"\"Register this flow as a child of another flow.\"\"\"\n    self._parent_flow = parent_flow\n\n    # Register dependencies\n    if required_deps:\n        for dep_id in required_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Required dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.REQUIRED\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n\n    if optional_deps:\n        for dep_id in optional_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Optional dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.OPTIONAL\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n</code></pre>"},{"location":"reference/flow/core/f3/#flow.core.f3.FlowConfig","title":"FlowConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a flow.</p>"},{"location":"reference/flow/core/f3/#flow.core.f3.FlowResult","title":"FlowResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a flow execution.</p>"},{"location":"reference/flow/core/f4/","title":"f4","text":""},{"location":"reference/flow/core/f4/#flow.core.f4","title":"f4","text":"<p>Fixed Flow implementation that properly abstracts execution details.</p>"},{"location":"reference/flow/core/f4/#flow.core.f4.Flow","title":"Flow","text":"<pre><code>Flow(function: Optional[Callable], config: FlowConfig, process_id: Optional[str] = None)\n</code></pre> <p>Core flow implementation that wraps user-defined processors.</p> Source code in <code>src/flow/core/f4.py</code> <pre><code>def __init__(\n    self,\n    function: Optional[Callable],\n    config: FlowConfig,\n    process_id: Optional[str] = None\n):\n    from flow.core.context import FlowContext\n\n    self.function = function or (lambda i: None)\n    self.config = config\n    self.process_id = process_id or str(uuid.uuid4())\n    self.context = FlowContext.get_instance()\n\n    # Flow state\n    self.status = FlowStatus.PENDING\n    self._parent_flow = None\n    self._dependencies: Dict[str, DependencyType] = {}\n    self._dependent_flows: Set[str] = set()\n\n    # Register with context\n    self.context.register_flow(self)\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.process_id})\")\n</code></pre>"},{"location":"reference/flow/core/f4/#flow.core.f4.Flow.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancel the flow execution.</p> Source code in <code>src/flow/core/f4.py</code> <pre><code>async def cancel(self) -&gt; None:\n    \"\"\"Cancel the flow execution.\"\"\"\n    if self.status == FlowStatus.RUNNING:\n        await self.context.pool_manager.cancel_task(self.process_id)\n        self.status = FlowStatus.CANCELLED\n</code></pre>"},{"location":"reference/flow/core/f4/#flow.core.f4.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Optional[Dict[str, Any]] = None) -&gt; FlowResult\n</code></pre> <p>Execute the flow and its dependencies.</p> Source code in <code>src/flow/core/f4.py</code> <pre><code>async def execute(\n    self,\n    input_data: Optional[Dict[str, Any]] = None\n) -&gt; FlowResult:\n    \"\"\"Execute the flow and its dependencies.\"\"\"\n    input_data = input_data or {}\n    logger.debug(f\"Starting execution of {self.config.name} with input: {input_data}\")\n\n    start_time = datetime.now()\n    self.status = FlowStatus.RUNNING\n\n    try:\n        # Execute processor\n        output = self.function(input_data)\n        logger.debug(f\"{self.config.name} produced output: {output}\")\n\n        # Create and save completed result\n        result = FlowResult.create_completed(\n            process_id=self.process_id,\n            output=output,\n            start_time=start_time,\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.COMPLETED\n\n        await self.context.results_manager.save_result(\n            self.process_id,\n            result\n        )\n\n        # Execute dependent flows\n        for dep_id in self._dependent_flows:\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                logger.debug(f\"Executing dependent flow {dep_flow.config.name}\")\n                dep_input = {**input_data, **output}\n                await dep_flow.execute(dep_input)\n\n    except Exception as e:\n        # Create and save failed result\n        result = FlowResult.create_failed(\n            process_id=self.process_id,\n            error=str(e),\n            start_time=start_time,\n            traceback=traceback.format_exc(),\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.FAILED\n\n        await self.context.results_manager.save_result(\n            self.process_id,\n            result\n        )\n        raise\n\n    return result\n</code></pre>"},{"location":"reference/flow/core/f4/#flow.core.f4.Flow.get_dependencies","title":"get_dependencies","text":"<pre><code>get_dependencies(dep_type: Optional[DependencyType] = None) -&gt; Set[str]\n</code></pre> <p>Get set of dependency process IDs, optionally filtered by type.</p> Source code in <code>src/flow/core/f4.py</code> <pre><code>def get_dependencies(self, dep_type: Optional[DependencyType] = None) -&gt; Set[str]:\n    \"\"\"Get set of dependency process IDs, optionally filtered by type.\"\"\"\n    if dep_type is None:\n        return set(self._dependencies.keys())\n    return {\n        dep_id for dep_id, dtype in self._dependencies.items() \n        if dtype == dep_type\n    }\n</code></pre>"},{"location":"reference/flow/core/f4/#flow.core.f4.Flow.register_to","title":"register_to","text":"<pre><code>register_to(\n    parent_flow: Flow,\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None,\n) -&gt; Self\n</code></pre> <p>Register this flow as a child of another flow.</p> Source code in <code>src/flow/core/f4.py</code> <pre><code>def register_to(\n    self,\n    parent_flow: Flow,\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None\n) -&gt; Self:\n    \"\"\"Register this flow as a child of another flow.\"\"\"\n    self._parent_flow = parent_flow\n\n    # Register dependencies\n    if required_deps:\n        for dep_id in required_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Required dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.REQUIRED\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n\n    if optional_deps:\n        for dep_id in optional_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Optional dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.OPTIONAL\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n    return self\n</code></pre>"},{"location":"reference/flow/core/f4/#flow.core.f4.FlowConfig","title":"FlowConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a flow.</p>"},{"location":"reference/flow/core/f5/","title":"f5","text":""},{"location":"reference/flow/core/f5/#flow.core.f5","title":"f5","text":"<p>Fixed Flow implementation that properly abstracts execution details.</p>"},{"location":"reference/flow/core/f5/#flow.core.f5.Flow","title":"Flow","text":"<pre><code>Flow(function: Optional[Callable], config: FlowConfig, process_id: Optional[str] = None)\n</code></pre> <p>Core flow implementation that wraps user-defined processors.</p> Source code in <code>src/flow/core/f5.py</code> <pre><code>def __init__(\n    self,\n    function: Optional[Callable],\n    config: FlowConfig,\n    process_id: Optional[str] = None\n):\n    from flow.core.context import FlowContext\n\n    self.function = function or (lambda i: None)\n    self.config = config\n    self.process_id = process_id or str(uuid.uuid4())\n    self.context = FlowContext.get_instance()\n\n    # Flow state\n    self.status = FlowStatus.PENDING\n    self._parent_flow = None\n    self._dependencies: Dict[str, DependencyType] = {}\n    self._dependent_flows: Set[str] = set()\n\n    # Register with context\n    self.context.register_flow(self)\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.process_id})\")\n</code></pre>"},{"location":"reference/flow/core/f5/#flow.core.f5.Flow.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancel the flow execution.</p> Source code in <code>src/flow/core/f5.py</code> <pre><code>async def cancel(self) -&gt; None:\n    \"\"\"Cancel the flow execution.\"\"\"\n    if self.status == FlowStatus.RUNNING:\n        await self.context.pool_manager.cancel_task(self.process_id)\n        self.status = FlowStatus.CANCELLED\n</code></pre>"},{"location":"reference/flow/core/f5/#flow.core.f5.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Optional[Dict[str, Any]] = None) -&gt; FlowResult\n</code></pre> <p>Execute the flow and its dependencies.</p> Source code in <code>src/flow/core/f5.py</code> <pre><code>async def execute(\n    self,\n    input_data: Optional[Dict[str, Any]] = None\n) -&gt; FlowResult:\n    \"\"\"Execute the flow and its dependencies.\"\"\"\n    input_data = input_data or {}\n    logger.debug(f\"Starting execution of {self.config.name} with input: {input_data}\")\n\n    start_time = datetime.now()\n    self.status = FlowStatus.RUNNING\n\n    try:\n        # Execute processor\n        output = self.function(input_data)\n        logger.debug(f\"{self.config.name} produced output: {output}\")\n\n        # Create and save completed result\n        result = FlowResult.create_completed(\n            process_id=self.process_id,\n            output=output,\n            start_time=start_time,\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.COMPLETED\n\n        await self.context.results_manager.save_result(\n            self.process_id,\n            result\n        )\n\n        # Execute dependent flows\n        for dep_id in self._dependent_flows:\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                logger.debug(f\"Executing dependent flow {dep_flow.config.name}\")\n                dep_input = {**input_data, **output}\n                await dep_flow.execute(dep_input)\n\n    except Exception as e:\n        # Create and save failed result\n        result = FlowResult.create_failed(\n            process_id=self.process_id,\n            error=str(e),\n            start_time=start_time,\n            traceback=traceback.format_exc(),\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.FAILED\n\n        await self.context.results_manager.save_result(\n            self.process_id,\n            result\n        )\n        raise\n\n    return result\n</code></pre>"},{"location":"reference/flow/core/f5/#flow.core.f5.Flow.get_dependencies","title":"get_dependencies","text":"<pre><code>get_dependencies(dep_type: Optional[DependencyType] = None) -&gt; Set[str]\n</code></pre> <p>Get set of dependency process IDs, optionally filtered by type.</p> Source code in <code>src/flow/core/f5.py</code> <pre><code>def get_dependencies(self, dep_type: Optional[DependencyType] = None) -&gt; Set[str]:\n    \"\"\"Get set of dependency process IDs, optionally filtered by type.\"\"\"\n    if dep_type is None:\n        return set(self._dependencies.keys())\n    return {\n        dep_id for dep_id, dtype in self._dependencies.items() \n        if dtype == dep_type\n    }\n</code></pre>"},{"location":"reference/flow/core/f5/#flow.core.f5.Flow.register_to","title":"register_to","text":"<pre><code>register_to(\n    parent_flow: Flow,\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None,\n) -&gt; Self\n</code></pre> <p>Register this flow as a child of another flow.</p> Source code in <code>src/flow/core/f5.py</code> <pre><code>def register_to(\n    self,\n    parent_flow: Flow,\n    required_deps: Optional[List[str]] = None,\n    optional_deps: Optional[List[str]] = None\n) -&gt; Self:\n    \"\"\"Register this flow as a child of another flow.\"\"\"\n    self._parent_flow = parent_flow\n\n    # Register dependencies\n    if required_deps:\n        for dep_id in required_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Required dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.REQUIRED\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n\n    if optional_deps:\n        for dep_id in optional_deps:\n            dep_flow = self.context.get_flow(dep_id)\n            if not dep_flow:\n                raise FlowError(f\"Optional dependency {dep_id} not found\")\n            self._dependencies[dep_id] = DependencyType.OPTIONAL\n            dep_flow._dependent_flows.add(self.process_id)\n            self.context.register_dependency(dep_id, self.process_id)\n    return self\n</code></pre>"},{"location":"reference/flow/core/f5/#flow.core.f5.FlowConfig","title":"FlowConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a flow.</p>"},{"location":"reference/flow/core/flow/","title":"flow","text":""},{"location":"reference/flow/core/flow/#flow.core.flow","title":"flow","text":""},{"location":"reference/flow/core/flow/#flow.core.flow.Flow","title":"Flow","text":"<pre><code>Flow(\n    name: str,\n    callable: Callable[[Any], Any],\n    flow_tree: Optional[FlowTree] = None,\n    required_prerequisites: Optional[List[Flow]] = None,\n    optional_prerequisites: Optional[List[Flow]] = None,\n)\n</code></pre> <p>Core flow implementation.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    callable: Callable[[Any], Any],\n    flow_tree: Optional[FlowTree] = None,\n    required_prerequisites: Optional[List[Flow]] = None,\n    optional_prerequisites: Optional[List[Flow]] = None,\n):\n    self.callable = callable\n    self.config = FlowConfig(name=name)\n    self.status = FlowStatus.PENDING\n    logger.debug(f\"Initialized flow: {self.config.name} ({self.config.name})\")\n    self._flow_tree = None\n\n\n    if flow_tree is not None:\n        self.register_to_flow_tree(flow_tree)\n\n    if required_prerequisites is not None:\n        assert flow_tree is not None\n        for prereq in required_prerequisites:\n            flow_tree.add_prerequisite(flow_id=self.id, prerequisite_id=prereq.id)\n\n    if optional_prerequisites is not None:\n        assert flow_tree is not None\n        for prereq in optional_prerequisites:\n            flow_tree.add_prerequisite(flow_id=self.id, prerequisite_id=prereq.id)\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.Flow.add_prerequisite","title":"add_prerequisite","text":"<pre><code>add_prerequisite(prerequisite_flow: Flow) -&gt; None\n</code></pre> <p>Add a prerequisite flow.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def add_prerequisite(self, prerequisite_flow: Flow) -&gt; None:\n    \"\"\"Add a prerequisite flow.\"\"\"\n    self._flow_tree.add_prerequisite(self.id, prerequisite_flow.id)\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.Flow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Dict[str, Any]) -&gt; FlowResult\n</code></pre> <p>Execute the flow.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def execute(self, input_data: Dict[str, Any]) -&gt; FlowResult:\n    \"\"\"Execute the flow.\"\"\"\n    logger.debug(f\"Executing flow {self.config.name} with input: {input_data}\")\n    start_time = datetime.now()\n    self.status = FlowStatus.RUNNING\n\n    try:\n        output = self.callable(input_data)\n        logger.debug(f\"Flow {self.config.name} produced output: {output}\")\n\n        result = FlowResult.create_completed(\n            process_id=self.config.name,\n            output=output,\n            start_time=start_time,\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.COMPLETED\n\n    except Exception as e:\n        logger.error(f\"Flow {self.config.name} execution failed: {e}\")\n        result = FlowResult.create_failed(\n            process_id=self.config.name,\n            error=str(e),\n            start_time=start_time,\n            traceback=traceback.format_exc(),\n            metadata={\"flow_name\": self.config.name}\n        )\n        self.status = FlowStatus.FAILED\n        raise\n\n    return result\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowConfig","title":"FlowConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a flow.</p>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree","title":"FlowTree","text":"<pre><code>FlowTree(max_workers: int = 4)\n</code></pre> Source code in <code>src/flow/core/flow.py</code> <pre><code>def __init__(self, max_workers: int = 4):\n    self._flows: Dict[str, Flow] = {}\n    self._prerequisites: Dict[str, Set[str]] = defaultdict(set)\n    self._dependent_flows: Dict[str, Set[str]] = defaultdict(set)\n    self._max_workers = max_workers\n    self._running_flows: Set[str] = set()\n    self._completed_flows: Set[str] = set()\n    self._results: Dict[str, FlowResult] = {}  # Store results\n    self._lock = asyncio.Lock()\n    logger.debug(f\"{type(self).__name__} initialized\")\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.add_prerequisite","title":"add_prerequisite","text":"<pre><code>add_prerequisite(flow_id: str, prerequisite_id: str) -&gt; None\n</code></pre> <p>Add a prerequisite relationship between flows.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def add_prerequisite(self, flow_id: str, prerequisite_id: str) -&gt; None:\n    \"\"\"Add a prerequisite relationship between flows.\"\"\"\n    if flow_id not in self._flows or prerequisite_id not in self._flows:\n        raise FlowError(\"Both flows must be registered first\")\n\n    self._prerequisites[flow_id].add(prerequisite_id)\n    self._dependent_flows[prerequisite_id].add(flow_id)\n    logger.debug(f\"Added prerequisite: {prerequisite_id} -&gt; {flow_id}\")\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.execute_all","title":"execute_all  <code>async</code>","text":"<pre><code>execute_all(input_data: Optional[Dict[str, Any]] = None) -&gt; Dict[str, FlowResult]\n</code></pre> <p>Execute all flows in the correct order based on prerequisites.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def execute_all(self, input_data: Optional[Dict[str, Any]] = None) -&gt; Dict[str, FlowResult]:\n    \"\"\"Execute all flows in the correct order based on prerequisites.\"\"\"\n    input_data = input_data or {}\n\n    async with self._lock:\n        self._running_flows.clear()\n        self._completed_flows.clear()\n        self._results.clear()  # Clear previous results\n\n    while True:\n        # Get flows that are ready to execute\n        ready_flows = await self.get_ready_flows()\n        if not ready_flows:\n            # If no flows are ready and none are running, we're done\n            if not self._running_flows:\n                break\n            # Otherwise wait a bit and check again\n            await asyncio.sleep(0.1)\n            continue\n\n        # Execute ready flows up to max_workers\n        available_workers = self._max_workers - len(self._running_flows)\n        if available_workers &gt; 0:\n            flows_to_execute = list(ready_flows)[:available_workers]\n            execution_tasks = []\n\n            for flow_id in flows_to_execute:\n                flow = self._flows[flow_id]\n                async with self._lock:\n                    self._running_flows.add(flow_id)\n\n                execution_tasks.append(self._execute_flow(flow, input_data))\n\n            # Execute flows in parallel\n            await asyncio.gather(*execution_tasks)\n\n    # Return all results\n    return await self.get_all_results()\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_all_results","title":"get_all_results  <code>async</code>","text":"<pre><code>get_all_results() -&gt; Dict[str, FlowResult]\n</code></pre> <p>Get all flow results.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def get_all_results(self) -&gt; Dict[str, FlowResult]:\n    \"\"\"Get all flow results.\"\"\"\n    async with self._lock:\n        return self._results.copy()\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_execution_summary","title":"get_execution_summary  <code>async</code>","text":"<pre><code>get_execution_summary() -&gt; Dict[str, Any]\n</code></pre> <p>Get summary of flow execution.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def get_execution_summary(self) -&gt; Dict[str, Any]:\n    \"\"\"Get summary of flow execution.\"\"\"\n    async with self._lock:\n        total_flows = len(self._flows)\n        completed = len(self._completed_flows)\n        failed = sum(\n            1 for r in self._results.values()\n            if r.status == FlowStatus.FAILED\n        )\n\n        return {\n            \"total_flows\": total_flows,\n            \"completed_flows\": completed,\n            \"failed_flows\": failed,\n            \"success_rate\": completed / total_flows if total_flows &gt; 0 else 0,\n            \"flow_names\": [flow.config.name for flow in self._flows.values()]\n        }\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_flow_by_name","title":"get_flow_by_name","text":"<pre><code>get_flow_by_name(name: str) -&gt; Optional[Flow]\n</code></pre> <p>Get a flow by its name.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def get_flow_by_name(self, name: str) -&gt; Optional[Flow]:\n    \"\"\"Get a flow by its name.\"\"\"\n    for flow in self._flows.values():\n        if flow.config.name == name:\n            return flow\n    return None\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_flow_names","title":"get_flow_names","text":"<pre><code>get_flow_names() -&gt; List[str]\n</code></pre> <p>Get names of all registered flows.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def get_flow_names(self) -&gt; List[str]:\n    \"\"\"Get names of all registered flows.\"\"\"\n    return list(set(flow.config.name for flow in self._flows.values()))\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_ready_flows","title":"get_ready_flows  <code>async</code>","text":"<pre><code>get_ready_flows() -&gt; Set[str]\n</code></pre> <p>Get flows whose prerequisites are all completed.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def get_ready_flows(self) -&gt; Set[str]:\n    \"\"\"Get flows whose prerequisites are all completed.\"\"\"\n    async with self._lock:\n        ready_flows = set()\n        for flow_id, prerequisites in self._prerequisites.items():\n            if (\n                flow_id not in self._running_flows and\n                flow_id not in self._completed_flows and\n                all(p in self._completed_flows for p in prerequisites)\n            ):\n                ready_flows.add(flow_id)\n        return ready_flows\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(flow_id: str) -&gt; Optional[FlowResult]\n</code></pre> <p>Get result for a specific flow.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def get_result(self, flow_id: str) -&gt; Optional[FlowResult]:\n    \"\"\"Get result for a specific flow.\"\"\"\n    async with self._lock:\n        return self._results.get(flow_id)\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_results_by_name","title":"get_results_by_name  <code>async</code>","text":"<pre><code>get_results_by_name(flow_name: str) -&gt; List[FlowResult]\n</code></pre> <p>Get results for all flows with a given name.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>async def get_results_by_name(self, flow_name: str) -&gt; List[FlowResult]:\n    \"\"\"Get results for all flows with a given name.\"\"\"\n    async with self._lock:\n        return [\n            result for flow_id, result in self._results.items()\n            if self._flows[flow_id].config.name == flow_name\n        ]\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.get_root_flows","title":"get_root_flows","text":"<pre><code>get_root_flows() -&gt; Set[str]\n</code></pre> <p>Get all flows with no prerequisites.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def get_root_flows(self) -&gt; Set[str]:\n    \"\"\"Get all flows with no prerequisites.\"\"\"\n    return {\n        flow_id for flow_id in self._flows.keys()\n        if not self._prerequisites[flow_id]\n    }\n</code></pre>"},{"location":"reference/flow/core/flow/#flow.core.flow.FlowTree.register_flow","title":"register_flow","text":"<pre><code>register_flow(flow: Flow) -&gt; None\n</code></pre> <p>Register a flow with the registry.</p> Source code in <code>src/flow/core/flow.py</code> <pre><code>def register_flow(self, flow: Flow) -&gt; None:\n    \"\"\"Register a flow with the registry.\"\"\"\n    assert flow.id not in self._flows.keys()\n    self._flows[flow.id] = flow\n    logger.debug(f\"Registered flow: {flow.config.name} ({flow.id})\")\n</code></pre>"},{"location":"reference/flow/core/logging/","title":"logging","text":""},{"location":"reference/flow/core/logging/#flow.core.logging","title":"logging","text":"<p>Logging configuration for the flow system.</p>"},{"location":"reference/flow/core/logging/#flow.core.logging.FlowFormatter","title":"FlowFormatter","text":"<pre><code>FlowFormatter(include_process_thread: bool = False)\n</code></pre> <p>               Bases: <code>Formatter</code></p> <p>Custom formatter for flow system logs.</p> <p>Format example: 2024-01-24 15:30:45.123 INFO Started execution - {\"context\": \"additional data\"} 2024-01-24 15:30:46.234 ERROR Execution failed - {\"error\": \"details\", \"traceback\": \"...\"}</p> Source code in <code>src/flow/core/logging.py</code> <pre><code>def __init__(self, include_process_thread: bool = False):\n    super().__init__()\n    self.include_process_thread = include_process_thread\n</code></pre>"},{"location":"reference/flow/core/logging/#flow.core.logging.FlowFormatter.format","title":"format","text":"<pre><code>format(record: LogRecord) -&gt; str\n</code></pre> <p>Format the log record.</p> Source code in <code>src/flow/core/logging.py</code> <pre><code>def format(self, record: logging.LogRecord) -&gt; str:\n    \"\"\"Format the log record.\"\"\"\n    # Extract flow information if available\n    flow_info = f\"[{getattr(record, 'flow_name', 'System')}:{getattr(record, 'process_id', 'N/A')}]\"\n\n    # Format timestamp\n    timestamp = datetime.fromtimestamp(record.created).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n\n    # Format level\n    level = record.levelname.ljust(8)\n\n    # Process and thread info if requested\n    proc_thread = \"\"\n    if self.include_process_thread:\n        proc_thread = f\"[P:{record.process}|T:{record.thread}] \"\n\n    # Format the message\n    msg = record.getMessage()\n\n    # Format any extra contextual data\n    extra = \"\"\n    if hasattr(record, 'flow_context'):\n        try:\n            extra = f\" - {json.dumps(record.flow_context, default=str)}\"\n        except Exception:\n            extra = f\" - {str(record.flow_context)}\"\n\n    # Combine all parts\n    log_message = f\"{timestamp} [{level}] {proc_thread}{flow_info} {msg}{extra}\"\n\n    # Add exception information if present\n    if record.exc_info:\n        exc_text = self.formatException(record.exc_info)\n        log_message = f\"{log_message}\\nException:\\n{exc_text}\"\n\n    return log_message\n</code></pre>"},{"location":"reference/flow/core/logging/#flow.core.logging.FlowLogger","title":"FlowLogger","text":"<pre><code>FlowLogger(name: str)\n</code></pre> <p>Enhanced logger for flow system with context management.</p> Source code in <code>src/flow/core/logging.py</code> <pre><code>def __init__(self, name: str):\n    self.logger = logging.getLogger(name)\n    self.context: Dict[str, Any] = {}\n    self._context_lock = threading.Lock()\n</code></pre>"},{"location":"reference/flow/core/logging/#flow.core.logging.FlowLogger.flow_context","title":"flow_context","text":"<pre><code>flow_context(**kwargs)\n</code></pre> <p>Context manager for adding flow-specific context to logs.</p> Source code in <code>src/flow/core/logging.py</code> <pre><code>@contextlib.contextmanager\ndef flow_context(self, **kwargs):\n    \"\"\"Context manager for adding flow-specific context to logs.\"\"\"\n    with self._context_lock:\n        old_context = self.context.copy()\n        self.context.update(kwargs)\n        try:\n            yield\n        finally:\n            self.context = old_context\n</code></pre>"},{"location":"reference/flow/core/logging/#flow.core.logging.setup_logging","title":"setup_logging","text":"<pre><code>setup_logging(\n    log_file: Optional[str] = None,\n    level: int = INFO,\n    max_bytes: int = 10485760,\n    backup_count: int = 5,\n    include_process_thread: bool = False,\n) -&gt; None\n</code></pre> <p>Set up logging configuration for the flow system.</p> <p>Parameters:</p> Name Type Description Default <code>log_file</code> <code>Optional[str]</code> <p>Optional path to log file. If None, logs to console only</p> <code>None</code> <code>level</code> <code>int</code> <p>Minimum logging level</p> <code>INFO</code> <code>max_bytes</code> <code>int</code> <p>Maximum size of each log file</p> <code>10485760</code> <code>backup_count</code> <code>int</code> <p>Number of backup log files to keep</p> <code>5</code> <code>include_process_thread</code> <code>bool</code> <p>Whether to include process and thread IDs in logs</p> <code>False</code> Source code in <code>src/flow/core/logging.py</code> <pre><code>def setup_logging(\n    log_file: Optional[str] = None,\n    level: int = LoggingLevel.INFO,\n    max_bytes: int = 10_485_760,  # 10MB\n    backup_count: int = 5,\n    include_process_thread: bool = False\n) -&gt; None:\n    \"\"\"Set up logging configuration for the flow system.\n\n    Args:\n        log_file: Optional path to log file. If None, logs to console only\n        level: Minimum logging level\n        max_bytes: Maximum size of each log file\n        backup_count: Number of backup log files to keep\n        include_process_thread: Whether to include process and thread IDs in logs\n    \"\"\"\n    root_logger = logging.getLogger('flow')\n    root_logger.setLevel(level)\n\n    # Create formatter\n    formatter = FlowFormatter(include_process_thread=include_process_thread)\n\n    # Console handler\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setFormatter(formatter)\n    root_logger.addHandler(console_handler)\n\n    # File handler if requested\n    if log_file:\n        log_path = Path(log_file)\n        log_path.parent.mkdir(parents=True, exist_ok=True)\n\n        file_handler = logging.handlers.RotatingFileHandler(\n            log_file,\n            maxBytes=max_bytes,\n            backupCount=backup_count\n        )\n        file_handler.setFormatter(formatter)\n        root_logger.addHandler(file_handler)\n</code></pre>"},{"location":"reference/flow/core/results/","title":"results","text":""},{"location":"reference/flow/core/results/#flow.core.results","title":"results","text":""},{"location":"reference/flow/core/results/#flow.core.results.FlowResult","title":"FlowResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Immutable result of a completed flow execution.</p>"},{"location":"reference/flow/core/results/#flow.core.results.FlowResult.create_completed","title":"create_completed  <code>classmethod</code>","text":"<pre><code>create_completed(\n    process_id: str,\n    output: Dict[str, Any],\n    start_time: datetime,\n    metadata: Optional[Dict[str, Any]] = None,\n) -&gt; FlowResult\n</code></pre> <p>Create a result for a completed flow.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>@classmethod\ndef create_completed(\n    cls, \n    process_id: str,\n    output: Dict[str, Any],\n    start_time: datetime,\n    metadata: Optional[Dict[str, Any]] = None\n) -&gt; FlowResult:\n    \"\"\"Create a result for a completed flow.\"\"\"\n    return cls(\n        process_id=process_id,\n        status=FlowStatus.COMPLETED,\n        start_time=start_time,\n        end_time=datetime.now(),\n        output=output,\n        metadata=metadata or {}\n    )\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.FlowResult.create_failed","title":"create_failed  <code>classmethod</code>","text":"<pre><code>create_failed(\n    process_id: str,\n    error: str,\n    start_time: datetime,\n    traceback: Optional[str] = None,\n    metadata: Optional[Dict[str, Any]] = None,\n) -&gt; \"FlowResult\"\n</code></pre> <p>Create a result for a failed flow.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>@classmethod\ndef create_failed(\n    cls,\n    process_id: str,\n    error: str,\n    start_time: datetime,\n    traceback: Optional[str] = None,\n    metadata: Optional[Dict[str, Any]] = None\n) -&gt; 'FlowResult':\n    \"\"\"Create a result for a failed flow.\"\"\"\n    return cls(\n        process_id=process_id,\n        status=FlowStatus.FAILED,\n        start_time=start_time,\n        end_time=datetime.now(),\n        error=error,\n        traceback=traceback,\n        metadata=metadata or {}\n    )\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.ResultsManager","title":"ResultsManager","text":"<pre><code>ResultsManager(context: 'FlowContext')\n</code></pre> <p>Manages immutable flow results.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>def __init__(self, context: 'FlowContext'):\n    self.context = context\n    self._results: Dict[str, FlowResult] = {}\n    self._lock = asyncio.Lock()\n    logger.debug(\"ResultsManager initialized\")\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.ResultsManager.cleanup","title":"cleanup","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Clear all stored results.\"\"\"\n    self._results.clear()\n    logger.debug(\"ResultsManager cleaned up\")\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.ResultsManager.get_dependency_output","title":"get_dependency_output  <code>async</code>","text":"<pre><code>get_dependency_output(process_id: str, dep_id: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get output from a specific dependency.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>async def get_dependency_output(self, process_id: str, dep_id: str) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Get output from a specific dependency.\"\"\"\n    async with self._lock:\n        result = self._results.get(dep_id)\n        if result and result.output:\n            logger.debug(f\"Retrieved dependency {dep_id} output for {process_id}: {result.output}\")\n            return result.output\n        return None\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.ResultsManager.get_dependency_outputs","title":"get_dependency_outputs  <code>async</code>","text":"<pre><code>get_dependency_outputs(process_id: str, dep_ids: set[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Get combined outputs from multiple dependencies.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>async def get_dependency_outputs(self, process_id: str, dep_ids: set[str]) -&gt; Dict[str, Any]:\n    \"\"\"Get combined outputs from multiple dependencies.\"\"\"\n    async with self._lock:\n        outputs = {}\n        for dep_id in dep_ids:\n            result = self._results.get(dep_id)\n            if result and result.output:\n                # Store outputs with process ID as prefix to avoid collisions\n                prefixed_outputs = {\n                    f\"{dep_id}.{k}\": v \n                    for k, v in result.output.items()\n                }\n                outputs.update(prefixed_outputs)\n        logger.debug(f\"Retrieved dependency outputs for {process_id}: {outputs}\")\n        return outputs\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.ResultsManager.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(process_id: str) -&gt; Optional[FlowResult]\n</code></pre> <p>Get an immutable flow result.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>async def get_result(self, process_id: str) -&gt; Optional[FlowResult]:\n    \"\"\"Get an immutable flow result.\"\"\"\n    async with self._lock:\n        result = self._results.get(process_id)\n        logger.debug(f\"Retrieved result for process {process_id}: {result}\")\n        return result\n</code></pre>"},{"location":"reference/flow/core/results/#flow.core.results.ResultsManager.save_result","title":"save_result  <code>async</code>","text":"<pre><code>save_result(process_id: str, result: FlowResult) -&gt; None\n</code></pre> <p>Save an immutable flow result.</p> Source code in <code>src/flow/core/results.py</code> <pre><code>async def save_result(self, process_id: str, result: FlowResult) -&gt; None:\n    \"\"\"Save an immutable flow result.\"\"\"\n    async with self._lock:\n        self._results[process_id] = result\n        logger.debug(f\"Saved result for process {process_id}: {result}\")\n</code></pre>"},{"location":"reference/flow/core/types/","title":"types","text":""},{"location":"reference/flow/core/types/#flow.core.types","title":"types","text":"<p>Core type definitions for the flow package.</p>"},{"location":"reference/flow/core/types/#flow.core.types.DependencyType","title":"DependencyType","text":"<p>               Bases: <code>Enum</code></p> <p>Type of dependency relationship.</p>"},{"location":"reference/flow/core/types/#flow.core.types.FlowStatus","title":"FlowStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Status of flow execution.</p>"},{"location":"reference/flow/core/types/#flow.core.types.FlowType","title":"FlowType","text":"<p>               Bases: <code>Enum</code></p> <p>Type of flow execution.</p>"},{"location":"reference/flow/core/types/#flow.core.types.StorageType","title":"StorageType","text":"<p>               Bases: <code>Enum</code></p> <p>Type of result storage.</p>"},{"location":"reference/flow/core/types/#flow.core.types.VisFormat","title":"VisFormat","text":"<p>               Bases: <code>Enum</code></p> <p>Visualization format options.</p>"},{"location":"reference/flow/examples/","title":"examples","text":""},{"location":"reference/flow/examples/#flow.examples","title":"examples","text":""},{"location":"reference/flow/examples/data_processing/","title":"data_processing","text":""},{"location":"reference/flow/examples/data_processing/#flow.examples.data_processing","title":"data_processing","text":"<p>Example usage of the Flow system.</p>"},{"location":"reference/flow/examples/data_processing/#flow.examples.data_processing.DataLoader","title":"DataLoader","text":"<p>               Bases: <code>BaseModel</code></p> <p>Example data loader processor.</p>"},{"location":"reference/flow/examples/data_processing/#flow.examples.data_processing.DataProcessor","title":"DataProcessor","text":"<p>               Bases: <code>BaseModel</code></p> <p>Example data processor.</p>"},{"location":"reference/flow/examples/data_processing/#flow.examples.data_processing.DataValidator","title":"DataValidator","text":"<p>               Bases: <code>BaseModel</code></p> <p>Example data validator processor.</p>"},{"location":"reference/flow/execution/","title":"execution","text":""},{"location":"reference/flow/execution/#flow.execution","title":"execution","text":"<p>Execution components of the flow package.</p>"},{"location":"reference/flow/execution/#flow.execution.FlowContext","title":"FlowContext","text":"<pre><code>FlowContext()\n</code></pre> <p>Central manager for flow coordination and service access.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def __init__(self):\n    if FlowContext._instance is not None:\n        raise RuntimeError(\"FlowContext is a singleton - use get_instance()\")\n\n    self._flow_graph = nx.DiGraph()\n    self._flows: Dict[str, Flow] = {}\n    self._status_locks: Dict[str, asyncio.Lock] = {}\n    self._execution_locks: Dict[str, asyncio.Lock] = {}\n\n    # Initialize managers\n    self.results_manager = ResultsManager(context=self)\n\n    from flow.execution.pool import ProcessPoolManager\n    self.pool_manager = ProcessPoolManager()\n\n    logger.info(\"FlowContext initialized\")\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.cleanup","title":"cleanup","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Cleanup all managers and resources.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup all managers and resources.\"\"\"\n    self.pool_manager.shutdown()\n    self.results_manager.cleanup()\n    self._flows.clear()\n    self._flow_graph.clear()\n    self._status_locks.clear()\n    self._execution_locks.clear()\n    logger.info(\"FlowContext cleaned up\")\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.fail_flow","title":"fail_flow  <code>async</code>","text":"<pre><code>fail_flow(process_id: str, reason: str) -&gt; None\n</code></pre> <p>Mark a flow as failed with the given reason.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>async def fail_flow(self, process_id: str, reason: str) -&gt; None:\n    \"\"\"Mark a flow as failed with the given reason.\"\"\"\n    flow = self._flows.get(process_id)\n    if not flow:\n        return\n    from flow.core.flow import FlowResult\n    async with self._status_locks[process_id]:\n        flow.status = FlowStatus.FAILED\n        await self.results_manager.save_result(\n            process_id,\n            FlowResult(\n                process_id=process_id,\n                status=FlowStatus.FAILED,\n                error=reason,\n                start_time=datetime.now(),\n                end_time=datetime.now()\n            )\n        )\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.get_flow","title":"get_flow","text":"<pre><code>get_flow(process_id: str) -&gt; Optional[Flow]\n</code></pre> <p>Get a flow by its process ID.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def get_flow(self, process_id: str) -&gt; Optional[Flow]:\n    \"\"\"Get a flow by its process ID.\"\"\"\n    return self._flows.get(process_id)\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.get_instance","title":"get_instance  <code>classmethod</code>","text":"<pre><code>get_instance() -&gt; FlowContext\n</code></pre> <p>Get or create the singleton instance.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>@classmethod\ndef get_instance(cls) -&gt; FlowContext:\n    \"\"\"Get or create the singleton instance.\"\"\"\n    if cls._instance is None:\n        cls._instance = cls()\n    return cls._instance\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.handle_flow_failure","title":"handle_flow_failure  <code>async</code>","text":"<pre><code>handle_flow_failure(process_id: str) -&gt; None\n</code></pre> <p>Handle flow failure and notify dependent flows.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>async def handle_flow_failure(self, process_id: str) -&gt; None:\n    \"\"\"Handle flow failure and notify dependent flows.\"\"\"\n    flow = self._flows.get(process_id)\n    if not flow:\n        return\n\n    async with self._status_locks[process_id]:\n        # Get all dependent flows\n        dependent_flows = set(self._flow_graph.successors(process_id))\n\n        for dep_id in dependent_flows:\n            dep_flow = self._flows.get(dep_id)\n            if not dep_flow:\n                continue\n\n            # If this was an optional dependency, mark it as skipped\n            if process_id in dep_flow.get_dependencies(DependencyType.OPTIONAL):\n                logger.warning(f\"Optional dependency {process_id} failed for {dep_id}\")\n                continue\n\n            # For required dependencies, fail the dependent flow\n            logger.error(f\"Required dependency {process_id} failed - failing {dep_id}\")\n            await self.fail_flow(dep_id, f\"Required dependency {process_id} failed\")\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.has_cycle","title":"has_cycle","text":"<pre><code>has_cycle(start_id: str) -&gt; bool\n</code></pre> <p>Check if adding a flow would create a cycle.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def has_cycle(self, start_id: str) -&gt; bool:\n    \"\"\"Check if adding a flow would create a cycle.\"\"\"\n    try:\n        nx.find_cycle(self._flow_graph, source=start_id)\n        return True\n    except nx.NetworkXNoCycle:\n        return False\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.register_dependency","title":"register_dependency","text":"<pre><code>register_dependency(parent_id: str, child_id: str) -&gt; None\n</code></pre> <p>Register a dependency relationship between flows.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def register_dependency(self, parent_id: str, child_id: str) -&gt; None:\n    \"\"\"Register a dependency relationship between flows.\"\"\"\n    if parent_id not in self._flows or child_id not in self._flows:\n        raise FlowError(f\"Cannot register dependency - flows not found\")\n\n    self._flow_graph.add_edge(parent_id, child_id)\n\n    # Validate no cycles were created\n    if not nx.is_directed_acyclic_graph(self._flow_graph):\n        self._flow_graph.remove_edge(parent_id, child_id)\n        raise FlowError(\"Adding dependency would create a cycle\")\n\n    logger.debug(f\"Registered dependency: {parent_id} -&gt; {child_id}\")\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.register_flow","title":"register_flow","text":"<pre><code>register_flow(flow: Flow) -&gt; None\n</code></pre> <p>Register a flow with the context.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>def register_flow(self, flow: Flow) -&gt; None:\n    \"\"\"Register a flow with the context.\"\"\"\n    if flow.process_id in self._flows:\n        raise FlowError(f\"Flow with id {flow.process_id} already registered\")\n\n    self._flows[flow.process_id] = flow\n    self._flow_graph.add_node(flow.process_id)\n    self._status_locks[flow.process_id] = asyncio.Lock()\n    self._execution_locks[flow.process_id] = asyncio.Lock()\n\n    logger.debug(f\"Registered flow: {flow.process_id}\")\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.FlowContext.wait_for_flows","title":"wait_for_flows  <code>async</code>","text":"<pre><code>wait_for_flows(flow_ids: Set[str], timeout: Optional[float] = None) -&gt; None\n</code></pre> <p>Wait for multiple flows to complete.</p> Source code in <code>src/flow/core/context.py</code> <pre><code>async def wait_for_flows(self, flow_ids: Set[str], timeout: Optional[float] = None) -&gt; None:\n    \"\"\"Wait for multiple flows to complete.\"\"\"\n    if not flow_ids:\n        return\n\n    async def wait_for_flow(flow_id: str) -&gt; None:\n        flow = self._flows.get(flow_id)\n        if not flow:\n            raise FlowError(f\"Flow {flow_id} not found\")\n\n        async with self._status_locks[flow_id]:\n            while flow.status not in (FlowStatus.COMPLETED, FlowStatus.FAILED):\n                await asyncio.sleep(0.1)\n\n    # Wait for all flows with timeout\n    wait_tasks = [wait_for_flow(fid) for fid in flow_ids]\n    try:\n        await asyncio.wait_for(asyncio.gather(*wait_tasks), timeout=timeout)\n    except asyncio.TimeoutError:\n        raise FlowError(f\"Timeout waiting for flows: {flow_ids}\")\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.ProcessPoolManager","title":"ProcessPoolManager","text":"<pre><code>ProcessPoolManager(max_threads: Optional[int] = None, max_processes: Optional[int] = None)\n</code></pre> <p>Manages process and thread pools for flow execution.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>def __init__(\n    self,\n    max_threads: Optional[int] = None,\n    max_processes: Optional[int] = None\n):\n    self.max_threads = max_threads or mp.cpu_count()\n    self.max_processes = max_processes or mp.cpu_count()\n\n    # Initialize pools\n    self._thread_pool = ThreadPoolExecutor(max_workers=self.max_threads)\n    self._process_pool = ProcessPoolExecutor(max_workers=self.max_processes)\n\n    # Track active tasks\n    self._futures: Dict[str, Future] = {}\n    self._locks: Dict[str, asyncio.Lock] = {}\n    self._loop = asyncio.get_event_loop()\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.ProcessPoolManager.active_tasks","title":"active_tasks  <code>property</code>","text":"<pre><code>active_tasks: Set[str]\n</code></pre> <p>Get set of currently active task IDs.</p>"},{"location":"reference/flow/execution/#flow.execution.ProcessPoolManager.cancel_task","title":"cancel_task  <code>async</code>","text":"<pre><code>cancel_task(process_id: str) -&gt; None\n</code></pre> <p>Cancel a running task.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>async def cancel_task(self, process_id: str) -&gt; None:\n    \"\"\"Cancel a running task.\"\"\"\n    future = self._futures.get(process_id)\n    if future and not future.done():\n        future.cancel()\n        self._cleanup_task(process_id)\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.ProcessPoolManager.shutdown","title":"shutdown","text":"<pre><code>shutdown(wait: bool = True) -&gt; None\n</code></pre> <p>Shutdown the pool manager.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>def shutdown(self, wait: bool = True) -&gt; None:\n    \"\"\"Shutdown the pool manager.\"\"\"\n    # Cancel all running tasks\n    for process_id in list(self._futures.keys()):\n        asyncio.create_task(self.cancel_task(process_id))\n\n    # Shutdown pools\n    self._thread_pool.shutdown(wait=wait)\n    self._process_pool.shutdown(wait=wait)\n\n    # Clear tracking\n    self._futures.clear()\n    self._locks.clear()\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.ProcessPoolManager.submit_task","title":"submit_task  <code>async</code>","text":"<pre><code>submit_task(\n    process_id: str,\n    flow_type: FlowType,\n    func: Callable,\n    input_data: Dict[str, Any],\n    timeout: Optional[float] = None,\n) -&gt; Any\n</code></pre> <p>Submit a task for execution.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>async def submit_task(\n    self,\n    process_id: str,\n    flow_type: FlowType,\n    func: Callable,\n    input_data: Dict[str, Any],\n    timeout: Optional[float] = None,\n) -&gt; Any:\n    \"\"\"Submit a task for execution.\"\"\"\n    if process_id in self._futures:\n        raise FlowError(f\"Task {process_id} already running\")\n\n    self._locks[process_id] = asyncio.Lock()\n\n    try:\n        # Create the executor based on flow type\n        executor = self._thread_pool if flow_type == FlowType.THREAD else self._process_pool\n\n        # Submit the task\n        future = executor.submit(func, input_data)\n        self._futures[process_id] = future\n\n        # Wait for completion\n        try:\n            if timeout:\n                result = await asyncio.wait_for(\n                    asyncio.wrap_future(future),\n                    timeout=timeout\n                )\n            else:\n                result = await asyncio.wrap_future(future)\n\n            return result\n\n        except asyncio.TimeoutError:\n            future.cancel()\n            raise FlowTimeoutError(f\"Task {process_id} timed out after {timeout} seconds\")\n\n    finally:\n        self._cleanup_task(process_id)\n</code></pre>"},{"location":"reference/flow/execution/#flow.execution.ProcessPoolManager.wait_for_task","title":"wait_for_task  <code>async</code>","text":"<pre><code>wait_for_task(process_id: str, timeout: Optional[float] = None) -&gt; None\n</code></pre> <p>Wait for a specific task to complete.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>async def wait_for_task(self, process_id: str, timeout: Optional[float] = None) -&gt; None:\n    \"\"\"Wait for a specific task to complete.\"\"\"\n    future = self._futures.get(process_id)\n    if not future:\n        return\n\n    try:\n        await asyncio.wait_for(\n            self._loop.run_in_executor(None, future.result),\n            timeout=timeout\n        )\n    except asyncio.TimeoutError:\n        raise FlowTimeoutError(f\"Timeout waiting for task {process_id}\")\n</code></pre>"},{"location":"reference/flow/execution/pool/","title":"pool","text":""},{"location":"reference/flow/execution/pool/#flow.execution.pool","title":"pool","text":"<p>Process pool management for flow execution.</p>"},{"location":"reference/flow/execution/pool/#flow.execution.pool.ProcessPoolManager","title":"ProcessPoolManager","text":"<pre><code>ProcessPoolManager(max_threads: Optional[int] = None, max_processes: Optional[int] = None)\n</code></pre> <p>Manages process and thread pools for flow execution.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>def __init__(\n    self,\n    max_threads: Optional[int] = None,\n    max_processes: Optional[int] = None\n):\n    self.max_threads = max_threads or mp.cpu_count()\n    self.max_processes = max_processes or mp.cpu_count()\n\n    # Initialize pools\n    self._thread_pool = ThreadPoolExecutor(max_workers=self.max_threads)\n    self._process_pool = ProcessPoolExecutor(max_workers=self.max_processes)\n\n    # Track active tasks\n    self._futures: Dict[str, Future] = {}\n    self._locks: Dict[str, asyncio.Lock] = {}\n    self._loop = asyncio.get_event_loop()\n</code></pre>"},{"location":"reference/flow/execution/pool/#flow.execution.pool.ProcessPoolManager.active_tasks","title":"active_tasks  <code>property</code>","text":"<pre><code>active_tasks: Set[str]\n</code></pre> <p>Get set of currently active task IDs.</p>"},{"location":"reference/flow/execution/pool/#flow.execution.pool.ProcessPoolManager.cancel_task","title":"cancel_task  <code>async</code>","text":"<pre><code>cancel_task(process_id: str) -&gt; None\n</code></pre> <p>Cancel a running task.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>async def cancel_task(self, process_id: str) -&gt; None:\n    \"\"\"Cancel a running task.\"\"\"\n    future = self._futures.get(process_id)\n    if future and not future.done():\n        future.cancel()\n        self._cleanup_task(process_id)\n</code></pre>"},{"location":"reference/flow/execution/pool/#flow.execution.pool.ProcessPoolManager.shutdown","title":"shutdown","text":"<pre><code>shutdown(wait: bool = True) -&gt; None\n</code></pre> <p>Shutdown the pool manager.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>def shutdown(self, wait: bool = True) -&gt; None:\n    \"\"\"Shutdown the pool manager.\"\"\"\n    # Cancel all running tasks\n    for process_id in list(self._futures.keys()):\n        asyncio.create_task(self.cancel_task(process_id))\n\n    # Shutdown pools\n    self._thread_pool.shutdown(wait=wait)\n    self._process_pool.shutdown(wait=wait)\n\n    # Clear tracking\n    self._futures.clear()\n    self._locks.clear()\n</code></pre>"},{"location":"reference/flow/execution/pool/#flow.execution.pool.ProcessPoolManager.submit_task","title":"submit_task  <code>async</code>","text":"<pre><code>submit_task(\n    process_id: str,\n    flow_type: FlowType,\n    func: Callable,\n    input_data: Dict[str, Any],\n    timeout: Optional[float] = None,\n) -&gt; Any\n</code></pre> <p>Submit a task for execution.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>async def submit_task(\n    self,\n    process_id: str,\n    flow_type: FlowType,\n    func: Callable,\n    input_data: Dict[str, Any],\n    timeout: Optional[float] = None,\n) -&gt; Any:\n    \"\"\"Submit a task for execution.\"\"\"\n    if process_id in self._futures:\n        raise FlowError(f\"Task {process_id} already running\")\n\n    self._locks[process_id] = asyncio.Lock()\n\n    try:\n        # Create the executor based on flow type\n        executor = self._thread_pool if flow_type == FlowType.THREAD else self._process_pool\n\n        # Submit the task\n        future = executor.submit(func, input_data)\n        self._futures[process_id] = future\n\n        # Wait for completion\n        try:\n            if timeout:\n                result = await asyncio.wait_for(\n                    asyncio.wrap_future(future),\n                    timeout=timeout\n                )\n            else:\n                result = await asyncio.wrap_future(future)\n\n            return result\n\n        except asyncio.TimeoutError:\n            future.cancel()\n            raise FlowTimeoutError(f\"Task {process_id} timed out after {timeout} seconds\")\n\n    finally:\n        self._cleanup_task(process_id)\n</code></pre>"},{"location":"reference/flow/execution/pool/#flow.execution.pool.ProcessPoolManager.wait_for_task","title":"wait_for_task  <code>async</code>","text":"<pre><code>wait_for_task(process_id: str, timeout: Optional[float] = None) -&gt; None\n</code></pre> <p>Wait for a specific task to complete.</p> Source code in <code>src/flow/execution/pool.py</code> <pre><code>async def wait_for_task(self, process_id: str, timeout: Optional[float] = None) -&gt; None:\n    \"\"\"Wait for a specific task to complete.\"\"\"\n    future = self._futures.get(process_id)\n    if not future:\n        return\n\n    try:\n        await asyncio.wait_for(\n            self._loop.run_in_executor(None, future.result),\n            timeout=timeout\n        )\n    except asyncio.TimeoutError:\n        raise FlowTimeoutError(f\"Timeout waiting for task {process_id}\")\n</code></pre>"},{"location":"reference/flow/monitoring/","title":"monitoring","text":""},{"location":"reference/flow/monitoring/#flow.monitoring","title":"monitoring","text":""},{"location":"reference/flow/monitoring/metrics/","title":"metrics","text":""},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics","title":"metrics","text":"<p>Metric collection and management for flows.</p>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor","title":"FlowMonitor","text":"<pre><code>FlowMonitor()\n</code></pre> <p>Monitors and tracks flow execution and health.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>def __init__(self):\n    self.collectors: Dict[str, MetricsCollector] = {}\n    self.events: List[FlowEvent] = []\n    self.statistics: Dict[str, FlowStatistics] = defaultdict(FlowStatistics)\n    self._lock = asyncio.Lock()\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor.get_health_status","title":"get_health_status  <code>async</code>","text":"<pre><code>get_health_status(process_id: str) -&gt; HealthStatus\n</code></pre> <p>Get current health status of a flow.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>async def get_health_status(self, process_id: str) -&gt; HealthStatus:\n    \"\"\"Get current health status of a flow.\"\"\"\n    stats = self.statistics.get(process_id)\n    if not stats:\n        return HealthStatus(\n            healthy=True,\n            message=\"No execution history\",\n            last_check=datetime.now()\n        )\n\n    # Calculate health based on error rate and performance\n    error_rate = stats.failed_executions / stats.total_executions if stats.total_executions &gt; 0 else 0\n    avg_exec_time = stats.avg_execution_time\n\n    healthy = error_rate &lt; 0.1 and (stats.max_execution_time or 0) &lt; 300  # example thresholds\n\n    return HealthStatus(\n        healthy=healthy,\n        message=\"Flow operating normally\" if healthy else \"Flow showing issues\",\n        last_check=datetime.now(),\n        details={\n            \"error_rate\": error_rate,\n            \"avg_execution_time\": avg_exec_time,\n            \"total_executions\": stats.total_executions\n        }\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor.get_resource_metrics","title":"get_resource_metrics  <code>async</code>","text":"<pre><code>get_resource_metrics() -&gt; ResourceMetrics\n</code></pre> <p>Get current system resource metrics.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>async def get_resource_metrics(self) -&gt; ResourceMetrics:\n    \"\"\"Get current system resource metrics.\"\"\"\n    return ResourceMetrics(\n        cpu_percent=psutil.cpu_percent(),\n        memory_percent=psutil.virtual_memory().percent,\n        disk_usage_percent=psutil.disk_usage('/').percent,\n        network_bytes_sent=psutil.net_io_counters().bytes_sent,\n        network_bytes_received=psutil.net_io_counters().bytes_recv,\n        thread_count=psutil.Process().num_threads(),\n        process_count=len(psutil.Process().children())\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor.record_event","title":"record_event  <code>async</code>","text":"<pre><code>record_event(\n    process_id: str, event_type: str, description: str, level: str, details: Dict[str, Any] = None\n) -&gt; None\n</code></pre> <p>Record a flow event.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>async def record_event(\n    self,\n    process_id: str,\n    event_type: str,\n    description: str,\n    level: str,\n    details: Dict[str, Any] = None\n) -&gt; None:\n    \"\"\"Record a flow event.\"\"\"\n    event = FlowEvent(\n        timestamp=datetime.now(),\n        process_id=process_id,\n        event_type=event_type,\n        description=description,\n        level=level,\n        details=details or {}\n    )\n\n    async with self._lock:\n        self.events.append(event)\n\n    if level in (LoggingLevel.ERROR, LoggingLevel.CRITICAL):\n        logger.error(f\"Flow {process_id} - {description}\")\n    elif level == LoggingLevel.WARNING:\n        logger.warning(f\"Flow {process_id} - {description}\")\n    else:\n        logger.info(f\"Flow {process_id} - {description}\")\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor.start_monitoring","title":"start_monitoring  <code>async</code>","text":"<pre><code>start_monitoring(process_id: str) -&gt; None\n</code></pre> <p>Start monitoring a flow.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>async def start_monitoring(self, process_id: str) -&gt; None:\n    \"\"\"Start monitoring a flow.\"\"\"\n    async with self._lock:\n        collector = MetricsCollector(process_id)\n        collector.start_collection()\n        self.collectors[process_id] = collector\n\n    await self.record_event(\n        process_id,\n        \"monitoring_started\",\n        \"Started monitoring flow\",\n        LoggingLevel.INFO\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor.stop_monitoring","title":"stop_monitoring  <code>async</code>","text":"<pre><code>stop_monitoring(process_id: str) -&gt; None\n</code></pre> <p>Stop monitoring a flow and collect final metrics.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>async def stop_monitoring(self, process_id: str) -&gt; None:\n    \"\"\"Stop monitoring a flow and collect final metrics.\"\"\"\n    async with self._lock:\n        if process_id in self.collectors:\n            metrics = self.collectors[process_id].collect_metrics()\n            await self.update_statistics(process_id, metrics)\n            del self.collectors[process_id]\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.FlowMonitor.update_statistics","title":"update_statistics  <code>async</code>","text":"<pre><code>update_statistics(process_id: str, metrics: FlowMetrics) -&gt; None\n</code></pre> <p>Update flow statistics with new metrics.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>async def update_statistics(self, process_id: str, metrics: FlowMetrics) -&gt; None:\n    \"\"\"Update flow statistics with new metrics.\"\"\"\n    async with self._lock:\n        stats = self.statistics[process_id]\n        stats.total_executions += 1\n        stats.total_execution_time += metrics.execution_time\n        stats.avg_execution_time = stats.total_execution_time / stats.total_executions\n\n        if stats.min_execution_time is None or metrics.execution_time &lt; stats.min_execution_time:\n            stats.min_execution_time = metrics.execution_time\n\n        if stats.max_execution_time is None or metrics.execution_time &gt; stats.max_execution_time:\n            stats.max_execution_time = metrics.execution_time\n\n        stats.last_execution_time = datetime.now()\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.MetricsCollector","title":"MetricsCollector","text":"<pre><code>MetricsCollector(process_id: str)\n</code></pre> <p>Collects and manages metrics for a flow.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>def __init__(self, process_id: str):\n    self.process_id = process_id\n    self.start_time: Optional[datetime] = None\n    self.metrics: Dict[str, List[MetricValue]] = defaultdict(list)\n    self._process = psutil.Process()\n    self._prev_cpu_time = 0\n    self._prev_time = time.time()\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.MetricsCollector.add_metric","title":"add_metric","text":"<pre><code>add_metric(name: str, value: float, metric_type: MetricType, labels: Dict[str, str] = None) -&gt; None\n</code></pre> <p>Add a metric measurement.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>def add_metric(self, name: str, value: float, metric_type: MetricType, labels: Dict[str, str] = None) -&gt; None:\n    \"\"\"Add a metric measurement.\"\"\"\n    self.metrics[name].append(\n        MetricValue(\n            timestamp=datetime.now(),\n            value=value,\n            labels=labels or {}\n        )\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.MetricsCollector.collect_metrics","title":"collect_metrics","text":"<pre><code>collect_metrics() -&gt; FlowMetrics\n</code></pre> <p>Collect current metrics.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>def collect_metrics(self) -&gt; FlowMetrics:\n    \"\"\"Collect current metrics.\"\"\"\n    current_time = time.time()\n    cpu_times = self._process.cpu_times()\n    current_cpu_time = cpu_times.user + cpu_times.system\n\n    # Calculate CPU usage\n    cpu_usage = (current_cpu_time - self._prev_cpu_time) / (current_time - self._prev_time) * 100\n\n    # Update previous values\n    self._prev_cpu_time = current_cpu_time\n    self._prev_time = current_time\n\n    return FlowMetrics(\n        process_id=self.process_id,\n        execution_time=time.time() - self.start_time.timestamp(),\n        memory_usage=self._process.memory_percent(),\n        cpu_usage=cpu_usage,\n        start_time=self.start_time,\n        end_time=datetime.now()\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/metrics/#flow.monitoring.metrics.MetricsCollector.start_collection","title":"start_collection","text":"<pre><code>start_collection() -&gt; None\n</code></pre> <p>Start collecting metrics.</p> Source code in <code>src/flow/monitoring/metrics.py</code> <pre><code>def start_collection(self) -&gt; None:\n    \"\"\"Start collecting metrics.\"\"\"\n    self.start_time = datetime.now()\n    self._prev_cpu_time = self._process.cpu_times().user + self._process.cpu_times().system\n    self._prev_time = time.time()\n</code></pre>"},{"location":"reference/flow/monitoring/service/","title":"service","text":""},{"location":"reference/flow/monitoring/service/#flow.monitoring.service","title":"service","text":"<p>Monitoring service for flow execution.</p>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService","title":"MonitoringService","text":"<pre><code>MonitoringService()\n</code></pre> <p>Service for monitoring and managing flow metrics.</p> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>def __init__(self):\n    if MonitoringService._instance is not None:\n        raise RuntimeError(\"MonitoringService is a singleton - use get_instance()\")\n\n    self.monitor = FlowMonitor()\n    self._background_task: Optional[asyncio.Task] = None\n    self._stopping = False\n\n    # Initialize background monitoring\n    self._init_background_monitoring()\n</code></pre>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService.get_flow_health","title":"get_flow_health  <code>async</code>","text":"<pre><code>get_flow_health(flow: 'Flow') -&gt; HealthStatus\n</code></pre> <p>Get health status for a flow.</p> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>async def get_flow_health(self, flow: 'Flow') -&gt; HealthStatus:\n    \"\"\"Get health status for a flow.\"\"\"\n    # Get current statistics\n    stats = await self.get_flow_statistics(flow)\n\n    # Check basic health metrics\n    is_healthy = True\n    issues = []\n\n    if stats.error_rate &gt; 0.1:  # More than 10% error rate\n        is_healthy = False\n        issues.append(f\"High error rate: {stats.error_rate:.2%}\")\n\n    if stats.avg_execution_time &gt; 300:  # More than 5 minutes average\n        is_healthy = False\n        issues.append(f\"High average execution time: {stats.avg_execution_time:.1f}s\")\n\n    # Check dependency health\n    deps_health: Dict[str, HealthStatus] = {}\n    for dep_id in flow.get_dependencies():\n        dep_flow = flow.context.get_flow(dep_id)\n        if dep_flow:\n            deps_health[dep_id] = await self.get_flow_health(dep_flow)\n\n    # If any required dependency is unhealthy, mark as unhealthy\n    unhealthy_deps = [\n        dep_id for dep_id, health in deps_health.items()\n        if not health.healthy and dep_id in flow.get_dependencies(DependencyType.REQUIRED)\n    ]\n    if unhealthy_deps:\n        is_healthy = False\n        issues.append(f\"Unhealthy required dependencies: {', '.join(unhealthy_deps)}\")\n\n    message = \"Flow is healthy\" if is_healthy else f\"Flow has issues: {', '.join(issues)}\"\n\n    return HealthStatus(\n        healthy=is_healthy,\n        message=message,\n        last_check=datetime.now(),\n        details={\n            \"error_rate\": stats.error_rate,\n            \"avg_execution_time\": stats.avg_execution_time,\n            \"total_executions\": stats.total_executions,\n            \"last_execution\": stats.last_execution_time\n        },\n        dependencies_health=deps_health\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService.get_flow_statistics","title":"get_flow_statistics  <code>async</code>","text":"<pre><code>get_flow_statistics(flow: Flow) -&gt; FlowStatistics\n</code></pre> <p>Get execution statistics for a flow.</p> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>async def get_flow_statistics(self, flow: Flow) -&gt; FlowStatistics:\n    \"\"\"Get execution statistics for a flow.\"\"\"\n    # Get metrics from the collector\n    collector = self.monitor.collectors.get(flow.process_id)\n    if not collector:\n        return FlowStatistics()  # Return empty stats if no collector\n\n    # Get all metrics\n    metrics = collector.metrics\n\n    # Calculate statistics\n    executions = [m for m in metrics.get('executions', [])]\n    total = len(executions)\n    if total == 0:\n        return FlowStatistics()\n\n    successful = sum(1 for m in executions if m.status == FlowStatus.COMPLETED)\n    failed = sum(1 for m in executions if m.status == FlowStatus.FAILED)\n\n    execution_times = [m.execution_time for m in executions]\n    total_time = sum(execution_times)\n\n    return FlowStatistics(\n        total_executions=total,\n        successful_executions=successful,\n        failed_executions=failed,\n        total_execution_time=total_time,\n        avg_execution_time=total_time / total if total &gt; 0 else 0.0,\n        min_execution_time=min(execution_times) if execution_times else None,\n        max_execution_time=max(execution_times) if execution_times else None,\n        last_execution_time=max(m.timestamp for m in executions) if executions else None,\n        error_rate=failed / total if total &gt; 0 else 0.0,\n        avg_retry_count=sum(m.retry_count for m in executions) / total if total &gt; 0 else 0.0\n    )\n</code></pre>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService.get_instance","title":"get_instance  <code>classmethod</code>","text":"<pre><code>get_instance() -&gt; 'MonitoringService'\n</code></pre> <p>Get or create the singleton instance.</p> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>@classmethod\ndef get_instance(cls) -&gt; 'MonitoringService':\n    \"\"\"Get or create the singleton instance.\"\"\"\n    if cls._instance is None:\n        cls._instance = cls()\n    return cls._instance\n</code></pre>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService.get_recent_events","title":"get_recent_events  <code>async</code>","text":"<pre><code>get_recent_events(\n    flow: Optional[\"Flow\"] = None, limit: int = 100, min_level: int = INFO\n) -&gt; List[FlowEvent]\n</code></pre> <p>Get recent events, optionally filtered.</p> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>async def get_recent_events(\n    self,\n    flow: Optional['Flow'] = None,\n    limit: int = 100,\n    min_level: int = LoggingLevel.INFO  # Filter by minimum logging level\n) -&gt; List[FlowEvent]:\n    \"\"\"Get recent events, optionally filtered.\"\"\"\n    events = self.monitor.events\n\n    if flow:\n        events = [e for e in events if e.process_id == flow.process_id]\n\n    # Filter by minimum logging level\n    events = [e for e in events if e.level &gt;= min_level]\n\n    return sorted(events, key=lambda e: e.timestamp, reverse=True)[:limit]\n</code></pre>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService.monitor_flow","title":"monitor_flow  <code>async</code>","text":"<pre><code>monitor_flow(flow: Flow) -&gt; AsyncGenerator[None, None]\n</code></pre> <p>Context manager for monitoring a flow execution.</p> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>@asynccontextmanager\nasync def monitor_flow(self, flow: Flow) -&gt; AsyncGenerator[None, None]:\n    \"\"\"Context manager for monitoring a flow execution.\"\"\"\n    try:\n        # Start monitoring\n        await self.monitor.start_monitoring(flow.process_id)\n        yield\n    finally:\n        # Stop monitoring and collect final metrics\n        await self.monitor.stop_monitoring(flow.process_id)\n</code></pre>"},{"location":"reference/flow/monitoring/service/#flow.monitoring.service.MonitoringService.record_flow_event","title":"record_flow_event  <code>async</code>","text":"<pre><code>record_flow_event(\n    flow: Flow, event_type: str, description: str, level: int, details: Dict[str, Any] = None\n) -&gt; None\n</code></pre> <p>Record a flow-related event.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <code>Flow</code> <p>Flow instance</p> required <code>event_type</code> <code>str</code> <p>Type of event</p> required <code>description</code> <code>str</code> <p>Event description</p> required <code>level</code> <code>int</code> <p>Logging level (e.g., LoggingLevel.INFO, LoggingLevel.ERROR)</p> required <code>details</code> <code>Dict[str, Any]</code> <p>Additional event details</p> <code>None</code> Source code in <code>src/flow/monitoring/service.py</code> <pre><code>async def record_flow_event(\n    self,\n    flow: Flow,\n    event_type: str,\n    description: str,\n    level: int,  # Using logging levels\n    details: Dict[str, Any] = None\n) -&gt; None:\n    \"\"\"Record a flow-related event.\n\n    Args:\n        flow: Flow instance\n        event_type: Type of event\n        description: Event description\n        level: Logging level (e.g., LoggingLevel.INFO, LoggingLevel.ERROR)\n        details: Additional event details\n    \"\"\"\n    await self.monitor.record_event(\n        flow.process_id,\n        event_type,\n        description,\n        level,\n        details\n    )\n\n    # Also log using Python's logging system\n    logger.log(level, f\"Flow {flow.process_id} - {description}\")\n</code></pre>"},{"location":"reference/flow/monitoring/types/","title":"types","text":""},{"location":"reference/flow/monitoring/types/#flow.monitoring.types","title":"types","text":"<p>Type definitions for flow monitoring system.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.FlowEvent","title":"FlowEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event record for flow monitoring.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.FlowMetrics","title":"FlowMetrics","text":"<p>               Bases: <code>BaseModel</code></p> <p>Collection of metrics for a flow.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.FlowStatistics","title":"FlowStatistics","text":"<p>               Bases: <code>BaseModel</code></p> <p>Statistical information about flow execution.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.HealthStatus","title":"HealthStatus","text":"<p>               Bases: <code>BaseModel</code></p> <p>Health check status for a flow or component.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.HistogramBucket","title":"HistogramBucket","text":"<p>               Bases: <code>BaseModel</code></p> <p>Histogram bucket for distribution metrics.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.HistogramValue","title":"HistogramValue","text":"<p>               Bases: <code>BaseModel</code></p> <p>Histogram metric with distribution information.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.MetricType","title":"MetricType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of metrics that can be collected.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.MetricValue","title":"MetricValue","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single metric measurement.</p>"},{"location":"reference/flow/monitoring/types/#flow.monitoring.types.ResourceMetrics","title":"ResourceMetrics","text":"<p>               Bases: <code>BaseModel</code></p> <p>System resource metrics.</p>"},{"location":"reference/flow/storage/","title":"storage","text":""},{"location":"reference/flow/storage/#flow.storage","title":"storage","text":"<p>Storage components of the flow package.</p>"},{"location":"reference/flow/visualization/","title":"visualization","text":""},{"location":"reference/flow/visualization/#flow.visualization","title":"visualization","text":""},{"location":"reference/flow/visualization/graph/","title":"graph","text":""},{"location":"reference/flow/visualization/graph/#flow.visualization.graph","title":"graph","text":"<p>Flow graph visualization utilities.</p>"},{"location":"reference/flow/visualization/graph/#flow.visualization.graph.FlowVisualizer","title":"FlowVisualizer","text":"<pre><code>FlowVisualizer(flow: Flow)\n</code></pre> <p>Visualizes flow dependencies and execution status.</p> Source code in <code>src/flow/visualization/graph.py</code> <pre><code>def __init__(self, flow: Flow):\n    self.flow = flow\n    self.context = flow.context\n    self._node_name_map = {}  # Maps process_ids to readable names\n    logger.info(f\"Initializing FlowVisualizer for flow {flow.config.name}\")\n</code></pre>"},{"location":"reference/flow/visualization/graph/#flow.visualization.graph.FlowVisualizer.to_graphviz","title":"to_graphviz","text":"<pre><code>to_graphviz(output_path: Optional[str] = None) -&gt; Optional[str]\n</code></pre> <p>Generate Graphviz visualization.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Optional[str]</code> <p>Optional path to save the rendered image.         If None, returns the DOT representation.</p> <code>None</code> Source code in <code>src/flow/visualization/graph.py</code> <pre><code>def to_graphviz(self, output_path: Optional[str] = None) -&gt; Optional[str]:\n    \"\"\"Generate Graphviz visualization.\n\n    Args:\n        output_path: Optional path to save the rendered image.\n                    If None, returns the DOT representation.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Add nodes with attributes\n    def add_flow_node(flow: Flow):\n        status_colors = {\n            FlowStatus.PENDING: \"white\",\n            FlowStatus.RUNNING: \"lightblue\",\n            FlowStatus.COMPLETED: \"lightgreen\",\n            FlowStatus.FAILED: \"lightcoral\",\n            FlowStatus.CANCELLED: \"lightgray\"\n        }\n\n        G.add_node(\n            self._get_node_name(flow),\n            label=f\"{flow.config.name}\\n({flow.status.value})\",\n            style=\"filled\",\n            fillcolor=status_colors[flow.status],\n            shape=\"box\",\n            fontname=\"Arial\"\n        )\n\n    # Add edges with attributes\n    def add_flow_edges(flow: Flow):\n        flow_name = self._get_node_name(flow)\n        for dep_id, dep_type in flow._dependencies.items():\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                dep_name = self._get_node_name(dep_flow)\n                G.add_edge(\n                    dep_name,\n                    flow_name,\n                    style=\"dashed\" if dep_type == \"optional\" else \"solid\",\n                    color=\"gray\" if dep_type == \"optional\" else \"black\"\n                )\n\n    # Build graph\n    visited = set()\n    def build_graph(flow: Flow):\n        if flow.process_id in visited:\n            return\n        visited.add(flow.process_id)\n\n        add_flow_node(flow)\n        add_flow_edges(flow)\n\n        for dep_id in flow._dependencies:\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                build_graph(dep_flow)\n\n    build_graph(self.flow)\n\n    if output_path:\n        # Use graphviz to render\n        dot_path = Path(output_path).with_suffix('.dot')\n        nx.drawing.nx_pydot.write_dot(G, dot_path)\n\n        # Convert to desired format\n        output_path = Path(output_path)\n        format = output_path.suffix.lstrip('.')\n        subprocess.run(['dot', '-T' + format, dot_path, '-o', output_path])\n        dot_path.unlink()  # Clean up dot file\n        return output_path.absolute().as_posix()\n    else:\n        return nx.drawing.nx_pydot.to_pydot(G).to_string()\n</code></pre>"},{"location":"reference/flow/visualization/graph/#flow.visualization.graph.FlowVisualizer.to_mermaid","title":"to_mermaid","text":"<pre><code>to_mermaid() -&gt; str\n</code></pre> <p>Generate Mermaid graph definition.</p> Source code in <code>src/flow/visualization/graph.py</code> <pre><code>def to_mermaid(self) -&gt; str:\n    \"\"\"Generate Mermaid graph definition.\"\"\"\n    logger.info(\"Generating Mermaid graph\")\n    nodes = []\n    edges = []\n\n    # Helper to get node style based on status\n    def get_node_style(flow: Flow) -&gt; str:\n        status_styles = {\n            FlowStatus.PENDING: \"\",\n            FlowStatus.RUNNING: \"style %s fill:#aff,stroke:#0aa\",\n            FlowStatus.COMPLETED: \"style %s fill:#afa,stroke:#0a0\",\n            FlowStatus.FAILED: \"style %s fill:#faa,stroke:#a00\",\n            FlowStatus.CANCELLED: \"style %s fill:#eee,stroke:#999\"\n        }\n        node_name = self._get_node_name(flow)\n        return status_styles[flow.status] % node_name if status_styles[flow.status] else \"\"\n\n    # Build nodes and edges\n    visited = set()\n    def visit_flow(flow: Flow):\n        if flow.process_id in visited:\n            return\n        visited.add(flow.process_id)\n\n        # Add node with readable name\n        node_name = self._get_node_name(flow)\n        node_def = f\"    {node_name}[\\\"{flow.config.name}\\\"]\"\n        nodes.append(node_def)\n        logger.info(f\"Added node: {node_def}\")\n\n        style = get_node_style(flow)\n        if style:\n            nodes.append(f\"    {style}\")\n\n        # Add edges with readable names\n        for dep_id, dep_type in flow._dependencies.items():\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                dep_name = self._get_node_name(dep_flow)\n                style = \" style=dashed\" if dep_type == \"optional\" else \"\"\n                edge_def = f\"    {dep_name} --&gt; {node_name}{style}\"\n                edges.append(edge_def)\n                logger.info(f\"Added edge: {edge_def}\")\n                visit_flow(dep_flow)\n\n    visit_flow(self.flow)\n\n    # Build mermaid diagram\n    mermaid = [\"graph TD;\"]\n    mermaid.extend(nodes)\n    mermaid.extend(edges)\n\n    result = \"\\n\".join(mermaid)\n    logger.info(f\"Generated Mermaid graph:\\n{result}\")\n    return result\n</code></pre>"},{"location":"reference/flow/visualization/graph/#flow.visualization.graph.FlowVisualizer.to_plotly","title":"to_plotly","text":"<pre><code>to_plotly(output_path: Optional[str | Path] = None) -&gt; Figure\n</code></pre> <p>Generate interactive Plotly visualization.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Optional[str | Path]</code> <p>Optional path to save as HTML.         If None, returns the Figure object.</p> <code>None</code> Source code in <code>src/flow/visualization/graph.py</code> <pre><code>def to_plotly(self, output_path: Optional[str|Path] = None) -&gt; go.Figure:#|Path:\n    \"\"\"Generate interactive Plotly visualization.\n\n    Args:\n        output_path: Optional path to save as HTML.\n                    If None, returns the Figure object.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Add nodes and edges\n    pos = {}  # For node positions\n    node_colors = []\n    node_labels = {}\n    edge_colors = []\n    edge_styles = []\n\n    status_colors = {\n        FlowStatus.PENDING: \"#ffffff\",\n        FlowStatus.RUNNING: \"#aaffff\",\n        FlowStatus.COMPLETED: \"#aaffaa\",\n        FlowStatus.FAILED: \"#ffaaaa\",\n        FlowStatus.CANCELLED: \"#eeeeee\"\n    }\n\n    def add_flow_data(flow: Flow):\n        node_name = self._get_node_name(flow)\n        G.add_node(node_name)\n        node_colors.append(status_colors[flow.status])\n        node_labels[node_name] = f\"{flow.config.name}\\n({flow.status.value})\"\n\n        for dep_id, dep_type in flow._dependencies.items():\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                dep_name = self._get_node_name(dep_flow)\n                G.add_edge(dep_name, node_name)\n                edge_colors.append(\"gray\" if dep_type == \"optional\" else \"black\")\n                edge_styles.append(\"dash\" if dep_type == \"optional\" else \"solid\")\n\n    # Build graph data\n    visited = set()\n    def build_graph_data(flow: Flow):\n        if flow.process_id in visited:\n            return\n        visited.add(flow.process_id)\n\n        add_flow_data(flow)\n\n        for dep_id in flow._dependencies:\n            dep_flow = self.context.get_flow(dep_id)\n            if dep_flow:\n                build_graph_data(dep_flow)\n\n    build_graph_data(self.flow)\n\n    # Calculate layout\n    pos = nx.spring_layout(G)\n\n    # Create edge traces\n    edge_traces = []\n    for edge, color, style in zip(G.edges(), edge_colors, edge_styles):\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n\n        edge_trace = go.Scatter(\n            x=[x0, x1], y=[y0, y1],\n            line=dict(width=1, color=color, dash='dash' if style == 'dash' else 'solid'),\n            hoverinfo='none',\n            mode='lines'\n        )\n        edge_traces.append(edge_trace)\n\n    # Create node trace\n    node_x = [pos[node][0] for node in G.nodes()]\n    node_y = [pos[node][1] for node in G.nodes()]\n\n    node_trace = go.Scatter(\n        x=node_x, y=node_y,\n        mode='markers+text',\n        hoverinfo='text',\n        marker=dict(\n            size=30,\n            color=node_colors,\n            line=dict(width=2)\n        ),\n        text=[node_labels[node] for node in G.nodes()],\n        textposition=\"bottom center\"\n    )\n\n    # Create figure\n    fig = go.Figure(\n        data=[*edge_traces, node_trace],\n        layout=go.Layout(\n            title=f\"Flow Graph: {self.flow.config.name}\",\n            showlegend=False,\n            hovermode='closest',\n            margin=dict(b=20,l=5,r=5,t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n        )\n    )\n\n    if output_path:\n        fig.write_html(output_path)\n        # return Path(output_path)\n    # else:\n    return fig\n</code></pre>"},{"location":"reference/process_manager/","title":"process_manager","text":""},{"location":"reference/process_manager/#process_manager","title":"process_manager","text":"<p>Tools for managing processes and doing them in parallel</p>"},{"location":"reference/process_manager/data_handling/","title":"data_handling","text":""},{"location":"reference/process_manager/data_handling/#process_manager.data_handling","title":"data_handling","text":""},{"location":"reference/process_manager/data_handling/data_validator/","title":"data_validator","text":""},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator","title":"data_validator","text":""},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.DataValidator","title":"DataValidator","text":"<pre><code>DataValidator(rules: List[ValidationRule])\n</code></pre> <p>Validates data against a set of rules.</p> <p>Features: - Multiple validation rules - Custom error messages - Validation reporting</p> <p>Initialize validator with rules.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>List[ValidationRule]</code> <p>List of validation rules to apply</p> required Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>def __init__(self, rules: List[ValidationRule]):\n    \"\"\"\n    Initialize validator with rules.\n\n    Args:\n        rules: List of validation rules to apply\n    \"\"\"\n    self.rules = rules\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.DataValidator.validate","title":"validate","text":"<pre><code>validate(data: Any) -&gt; List[str]\n</code></pre> <p>Validate data against all rules.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to validate</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of validation error messages (empty if valid)</p> Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>def validate(self, data: Any) -&gt; List[str]:\n    \"\"\"\n    Validate data against all rules.\n\n    Args:\n        data: Data to validate\n\n    Returns:\n        List of validation error messages (empty if valid)\n    \"\"\"\n    errors = []\n\n    for rule in self.rules:\n        try:\n            if not rule.validator(data):\n                error_msg = (rule.error_message or \n                           f\"Validation failed: {rule.name}\")\n                errors.append(error_msg)\n                logger.warning(f\"Validation error: {error_msg}\")\n        except Exception as e:\n            error_msg = f\"Validation error in {rule.name}: {str(e)}\"\n            errors.append(error_msg)\n            logger.error(error_msg)\n\n    return errors\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.DictionaryValidator","title":"DictionaryValidator","text":"<pre><code>DictionaryValidator(rules: List[ValidationRule])\n</code></pre> <p>               Bases: <code>DataValidator</code></p> <p>Specialized validator for dictionary data</p> <p>Initialize validator with rules.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>List[ValidationRule]</code> <p>List of validation rules to apply</p> required Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>def __init__(self, rules: List[ValidationRule]):\n    \"\"\"\n    Initialize validator with rules.\n\n    Args:\n        rules: List of validation rules to apply\n    \"\"\"\n    self.rules = rules\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.DictionaryValidator.create_required_keys_validator","title":"create_required_keys_validator  <code>staticmethod</code>","text":"<pre><code>create_required_keys_validator(required_keys: List[str]) -&gt; DataValidator\n</code></pre> <p>Create validator for required dictionary keys</p> Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>@staticmethod\ndef create_required_keys_validator(\n    required_keys: List[str]\n) -&gt; DataValidator:\n    \"\"\"Create validator for required dictionary keys\"\"\"\n    return DataValidator([\n        ValidationRule(\n            name=\"required_keys\",\n            validator=lambda d: all(key in d for key in required_keys),\n            error_message=f\"Missing required keys: {required_keys}\"\n        )\n    ])\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.DictionaryValidator.create_type_validator","title":"create_type_validator  <code>staticmethod</code>","text":"<pre><code>create_type_validator(key_types: Dict[str, type]) -&gt; DataValidator\n</code></pre> <p>Create validator for dictionary value types</p> Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>@staticmethod\ndef create_type_validator(\n    key_types: Dict[str, type]\n) -&gt; DataValidator:\n    \"\"\"Create validator for dictionary value types\"\"\"\n    return DataValidator([\n        ValidationRule(\n            name=f\"type_{key}\",\n            validator=lambda d: isinstance(d.get(key), type_),\n            error_message=f\"{key} must be of type {type_.__name__}\"\n        )\n        for key, type_ in key_types.items()\n    ])\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.NumericValidator","title":"NumericValidator","text":"<pre><code>NumericValidator(rules: List[ValidationRule])\n</code></pre> <p>               Bases: <code>DataValidator</code></p> <p>Specialized validator for numeric data</p> <p>Initialize validator with rules.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>List[ValidationRule]</code> <p>List of validation rules to apply</p> required Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>def __init__(self, rules: List[ValidationRule]):\n    \"\"\"\n    Initialize validator with rules.\n\n    Args:\n        rules: List of validation rules to apply\n    \"\"\"\n    self.rules = rules\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.NumericValidator.create_range_validator","title":"create_range_validator  <code>staticmethod</code>","text":"<pre><code>create_range_validator(\n    min_val: Optional[float] = None, max_val: Optional[float] = None\n) -&gt; DataValidator\n</code></pre> <p>Create validator for numeric range</p> Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>@staticmethod\ndef create_range_validator(\n    min_val: Optional[float] = None,\n    max_val: Optional[float] = None\n) -&gt; DataValidator:\n    \"\"\"Create validator for numeric range\"\"\"\n    rules = []\n\n    if min_val is not None:\n        rules.append(ValidationRule(\n            name=\"minimum_value\",\n            validator=lambda x: x &gt;= min_val,\n            error_message=f\"Value must be &gt;= {min_val}\"\n        ))\n\n    if max_val is not None:\n        rules.append(ValidationRule(\n            name=\"maximum_value\",\n            validator=lambda x: x &lt;= max_val,\n            error_message=f\"Value must be &lt;= {max_val}\"\n        ))\n\n    return DataValidator(rules)\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.NumericValidator.create_statistical_validator","title":"create_statistical_validator  <code>staticmethod</code>","text":"<pre><code>create_statistical_validator(\n    mean: Optional[float] = None, std_dev: Optional[float] = None, n_sigmas: float = 3.0\n) -&gt; DataValidator\n</code></pre> <p>Create validator for statistical bounds</p> Source code in <code>src/process_manager/data_handling/data_validator.py</code> <pre><code>@staticmethod\ndef create_statistical_validator(\n    mean: Optional[float] = None,\n    std_dev: Optional[float] = None,\n    n_sigmas: float = 3.0\n) -&gt; DataValidator:\n    \"\"\"Create validator for statistical bounds\"\"\"\n    rules = []\n\n    if mean is not None and std_dev is not None:\n        rules.append(ValidationRule(\n            name=\"statistical_bounds\",\n            validator=lambda x: (\n                abs(x - mean) &lt;= n_sigmas * std_dev\n            ),\n            error_message=f\"Value outside {n_sigmas} sigma range\"\n        ))\n\n    return DataValidator(rules)\n</code></pre>"},{"location":"reference/process_manager/data_handling/data_validator/#process_manager.data_handling.data_validator.ValidationRule","title":"ValidationRule  <code>dataclass</code>","text":"<pre><code>ValidationRule(name: str, validator: Callable[[Any], bool], error_message: Optional[str] = None)\n</code></pre> <p>Defines a validation rule for data.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the validation rule</p> <code>validator</code> <code>Callable[[Any], bool]</code> <p>Function that performs validation</p> <code>error_message</code> <code>Optional[str]</code> <p>Optional custom error message</p>"},{"location":"reference/process_manager/data_handling/file_handler/","title":"file_handler","text":""},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler","title":"file_handler","text":""},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler","title":"FileHandler","text":"<pre><code>FileHandler(base_dir: Path)\n</code></pre> <p>Handles file operations with support for multiple formats and validation.</p> <p>Features: - Multiple format support (text, JSON, YAML, CSV, pickle) - Automatic backup - File locking for concurrent access - Error handling and logging</p> <p>Initialize file handler.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Path</code> <p>Base directory for file operations</p> required Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def __init__(self, base_dir: Path):\n    \"\"\"\n    Initialize file handler.\n\n    Args:\n        base_dir: Base directory for file operations\n    \"\"\"\n    self.base_dir = Path(base_dir)\n    self.base_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create backup directory\n    self.backup_dir = self.base_dir / \"backups\"\n    self.backup_dir.mkdir(exist_ok=True)\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.read_csv","title":"read_csv","text":"<pre><code>read_csv(filepath: Path, has_headers: bool = True) -&gt; list\n</code></pre> <p>Read CSV data</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def read_csv(self, filepath: Path, has_headers: bool = True) -&gt; list:\n    \"\"\"Read CSV data\"\"\"\n    try:\n        with open(filepath, 'r', newline='') as f:\n            reader = csv.reader(f)\n            if has_headers:\n                headers = next(reader)\n            return list(reader)\n    except Exception as e:\n        logger.error(f\"Error reading CSV file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.read_json","title":"read_json","text":"<pre><code>read_json(filepath: Path) -&gt; Any\n</code></pre> <p>Read JSON data</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def read_json(self, filepath: Path) -&gt; Any:\n    \"\"\"Read JSON data\"\"\"\n    try:\n        with open(filepath, 'r') as f:\n            return json.load(f)\n    except Exception as e:\n        logger.error(f\"Error reading JSON file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.read_pickle","title":"read_pickle","text":"<pre><code>read_pickle(filepath: Path) -&gt; Any\n</code></pre> <p>Read pickle data</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def read_pickle(self, filepath: Path) -&gt; Any:\n    \"\"\"Read pickle data\"\"\"\n    try:\n        with open(filepath, 'rb') as f:\n            return pickle.load(f)\n    except Exception as e:\n        logger.error(f\"Error reading pickle file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.read_text","title":"read_text","text":"<pre><code>read_text(filepath: Path) -&gt; str\n</code></pre> <p>Read text content from file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to input file</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text content of file</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def read_text(self, filepath: Path) -&gt; str:\n    \"\"\"\n    Read text content from file.\n\n    Args:\n        filepath: Path to input file\n\n    Returns:\n        Text content of file\n    \"\"\"\n    try:\n        return Path(filepath).read_text()\n    except Exception as e:\n        logger.error(f\"Error reading text file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.read_yaml","title":"read_yaml","text":"<pre><code>read_yaml(filepath: Path) -&gt; Any\n</code></pre> <p>Read YAML data</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def read_yaml(self, filepath: Path) -&gt; Any:\n    \"\"\"Read YAML data\"\"\"\n    try:\n        with open(filepath, 'r') as f:\n            return yaml.safe_load(f)\n    except Exception as e:\n        logger.error(f\"Error reading YAML file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.write_csv","title":"write_csv","text":"<pre><code>write_csv(filepath: Path, data: list, headers: list = None, backup: bool = True) -&gt; None\n</code></pre> <p>Write data as CSV</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def write_csv(self, filepath: Path, data: list,\n             headers: list = None, backup: bool = True) -&gt; None:\n    \"\"\"Write data as CSV\"\"\"\n    if backup:\n        self._backup_file(filepath)\n\n    try:\n        with open(filepath, 'w', newline='') as f:\n            writer = csv.writer(f)\n            if headers:\n                writer.writerow(headers)\n            writer.writerows(data)\n        logger.debug(f\"Wrote CSV file: {filepath}\")\n    except Exception as e:\n        logger.error(f\"Error writing CSV file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.write_json","title":"write_json","text":"<pre><code>write_json(filepath: Path, data: Any, backup: bool = True) -&gt; None\n</code></pre> <p>Write data as JSON</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def write_json(self, filepath: Path, data: Any,\n              backup: bool = True) -&gt; None:\n    \"\"\"Write data as JSON\"\"\"\n    if backup:\n        self._backup_file(filepath)\n\n    try:\n        with open(filepath, 'w') as f:\n            json.dump(data, f, indent=2)\n        logger.debug(f\"Wrote JSON file: {filepath}\")\n    except Exception as e:\n        logger.error(f\"Error writing JSON file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.write_pickle","title":"write_pickle","text":"<pre><code>write_pickle(filepath: Path, data: Any, backup: bool = True) -&gt; None\n</code></pre> <p>Write data as pickle</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def write_pickle(self, filepath: Path, data: Any,\n                backup: bool = True) -&gt; None:\n    \"\"\"Write data as pickle\"\"\"\n    if backup:\n        self._backup_file(filepath)\n\n    try:\n        with open(filepath, 'wb') as f:\n            pickle.dump(data, f)\n        logger.debug(f\"Wrote pickle file: {filepath}\")\n    except Exception as e:\n        logger.error(f\"Error writing pickle file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.write_text","title":"write_text","text":"<pre><code>write_text(filepath: Path, content: str, backup: bool = True) -&gt; None\n</code></pre> <p>Write text content to file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to output file</p> required <code>content</code> <code>str</code> <p>Text content to write</p> required <code>backup</code> <code>bool</code> <p>Whether to backup existing file</p> <code>True</code> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def write_text(self, filepath: Path, content: str,\n              backup: bool = True) -&gt; None:\n    \"\"\"\n    Write text content to file.\n\n    Args:\n        filepath: Path to output file\n        content: Text content to write\n        backup: Whether to backup existing file\n    \"\"\"\n    filepath = Path(filepath)\n    if backup:\n        self._backup_file(filepath)\n\n    try:\n        filepath.write_text(content)\n        logger.debug(f\"Wrote text file: {filepath}\")\n    except Exception as e:\n        logger.error(f\"Error writing text file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/data_handling/file_handler/#process_manager.data_handling.file_handler.FileHandler.write_yaml","title":"write_yaml","text":"<pre><code>write_yaml(filepath: Path, data: Any, backup: bool = True) -&gt; None\n</code></pre> <p>Write data as YAML</p> Source code in <code>src/process_manager/data_handling/file_handler.py</code> <pre><code>def write_yaml(self, filepath: Path, data: Any,\n              backup: bool = True) -&gt; None:\n    \"\"\"Write data as YAML\"\"\"\n    if backup:\n        self._backup_file(filepath)\n\n    try:\n        with open(filepath, 'w') as f:\n            yaml.dump(data, f)\n        logger.debug(f\"Wrote YAML file: {filepath}\")\n    except Exception as e:\n        logger.error(f\"Error writing YAML file {filepath}: {e}\")\n        raise\n</code></pre>"},{"location":"reference/process_manager/examples/","title":"examples","text":""},{"location":"reference/process_manager/examples/#process_manager.examples","title":"examples","text":""},{"location":"reference/process_manager/examples/monte_carlo/","title":"monte_carlo","text":""},{"location":"reference/process_manager/examples/monte_carlo/#process_manager.examples.monte_carlo","title":"monte_carlo","text":""},{"location":"reference/process_manager/examples/monte_carlo/caching/","title":"caching","text":""},{"location":"reference/process_manager/examples/monte_carlo/caching/#process_manager.examples.monte_carlo.caching","title":"caching","text":""},{"location":"reference/process_manager/examples/monte_carlo/caching/#process_manager.examples.monte_carlo.caching.SimulationCache","title":"SimulationCache","text":"<pre><code>SimulationCache(\n    cache_dir: Path, max_cache_size: int = 1024**3, cache_ttl: timedelta = timedelta(days=7)\n)\n</code></pre> <p>Manages caching of simulation results to avoid redundant calculations.</p> <p>This cache system provides: - Content-based caching using parameter hashing - Cache expiration - Cache statistics - Disk space management</p> <p>Attributes:</p> Name Type Description <code>cache_dir</code> <p>Directory for cached results</p> <code>max_cache_size</code> <p>Maximum cache size in bytes</p> <code>cache_ttl</code> <p>Time-to-live for cached results</p> Source code in <code>src/process_manager/examples/monte_carlo/caching.py</code> <pre><code>def __init__(self,\n             cache_dir: Path,\n             max_cache_size: int = 1024**3,  # 1GB default\n             cache_ttl: timedelta = timedelta(days=7)):\n    self.cache_dir = cache_dir\n    self.max_cache_size = max_cache_size\n    self.cache_ttl = cache_ttl\n    self.cache_dir.mkdir(parents=True, exist_ok=True)\n\n    # Cache statistics\n    self.hits = 0\n    self.misses = 0\n\n    # Initialize cache\n    self._init_cache()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/caching/#process_manager.examples.monte_carlo.caching.SimulationCache.get","title":"get","text":"<pre><code>get(params: Dict[str, Any]) -&gt; Optional[Path]\n</code></pre> <p>Retrieve cached result for parameter set.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Dict[str, Any]</code> <p>Simulation parameters</p> required <p>Returns:</p> Type Description <code>Optional[Path]</code> <p>Path to cached result file or None if not found</p> Source code in <code>src/process_manager/examples/monte_carlo/caching.py</code> <pre><code>def get(self, params: Dict[str, Any]) -&gt; Optional[Path]:\n    \"\"\"\n    Retrieve cached result for parameter set.\n\n    Args:\n        params: Simulation parameters\n\n    Returns:\n        Path to cached result file or None if not found\n    \"\"\"\n    param_hash = self._compute_hash(params)\n    cache_path = self._get_cache_path(param_hash)\n\n    if cache_path.exists() and not self._is_expired(param_hash):\n        self.hits += 1\n        return cache_path\n\n    self.misses += 1\n    return None\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/caching/#process_manager.examples.monte_carlo.caching.SimulationCache.get_stats","title":"get_stats","text":"<pre><code>get_stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get cache statistics</p> Source code in <code>src/process_manager/examples/monte_carlo/caching.py</code> <pre><code>def get_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Get cache statistics\"\"\"\n    return {\n        \"hits\": self.hits,\n        \"misses\": self.misses,\n        \"hit_ratio\": self.hits / (self.hits + self.misses) if (self.hits + self.misses) &gt; 0 else 0,\n        \"size_bytes\": self._get_cache_size(),\n        \"size_limit_bytes\": self.max_cache_size,\n        \"entry_count\": len(list(self.cache_dir.glob(\"*.cache\")))\n    }\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/caching/#process_manager.examples.monte_carlo.caching.SimulationCache.put","title":"put","text":"<pre><code>put(params: Dict[str, Any], result_file: Path)\n</code></pre> <p>Cache result file for parameter set.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Dict[str, Any]</code> <p>Simulation parameters</p> required <code>result_file</code> <code>Path</code> <p>Path to result file to cache</p> required Source code in <code>src/process_manager/examples/monte_carlo/caching.py</code> <pre><code>def put(self, params: Dict[str, Any], result_file: Path):\n    \"\"\"\n    Cache result file for parameter set.\n\n    Args:\n        params: Simulation parameters\n        result_file: Path to result file to cache\n    \"\"\"\n    param_hash = self._compute_hash(params)\n    cache_path = self._get_cache_path(param_hash)\n\n    # Copy result to cache\n    shutil.copy2(result_file, cache_path)\n    self._save_metadata(param_hash, params)\n\n    # Maintain cache size limit\n    self._ensure_size_limit()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/","title":"monte_carlo_workflow","text":""},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow","title":"monte_carlo_workflow","text":"<p>Monte Carlo workflow implementation using data_handlers framework.</p>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow.InputGenerator","title":"InputGenerator","text":"<pre><code>InputGenerator(\n    output_dir: Path,\n    num_simulations: int,\n    progress_tracker: AsyncProgressTracker,\n    seed: Optional[int] = None,\n)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Generates input files for Monte Carlo simulation cases.</p> Source code in <code>src/process_manager/examples/monte_carlo/monte_carlo_workflow.py</code> <pre><code>def __init__(self,\n             output_dir: Path,\n             num_simulations: int,\n             progress_tracker: AsyncProgressTracker,\n             seed: Optional[int] = None):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.THREAD,\n        process_id=\"input_generator\"\n    ))\n    self.output_dir = output_dir\n    self.num_simulations = num_simulations\n    self.progress_tracker = progress_tracker\n    self.params_generator = SimulationParams(seed=seed)\n\n    # Create output directory\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow.InputGenerator.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Any) -&gt; Dict[str, SimulationCase]\n</code></pre> <p>Generate all input files for Monte Carlo simulation.</p> Source code in <code>src/process_manager/examples/monte_carlo/monte_carlo_workflow.py</code> <pre><code>async def execute(self, input_data: Any) -&gt; Dict[str, SimulationCase]:\n    \"\"\"Generate all input files for Monte Carlo simulation.\"\"\"\n    await self.progress_tracker.update_state(ProgressState.GENERATING_INPUTS)\n\n    cases = {}\n    id_gen = ProcessIdGenerator(prefix=\"case\")\n\n    for i in range(self.num_simulations):\n        case_id = id_gen.next_id()\n\n        # Generate parameters using data_handlers framework\n        params = self.params_generator.generate()\n\n        case = SimulationCase(\n            case_id=case_id,\n            params=params,\n            input_file=self.output_dir / f\"{case_id}.mid\"\n        )\n\n        self._create_mid_input_file(case)\n        cases[case_id] = case\n\n        # Update progress\n        await self.progress_tracker.complete_case(case_id)\n\n        # Update process metadata\n        self.metadata.progress = (i + 1) / self.num_simulations * 100\n\n    return cases\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow.MIDSolver","title":"MIDSolver","text":"<pre><code>MIDSolver(\n    mid_executable: Path,\n    progress_tracker: AsyncProgressTracker,\n    cache: Optional[SimulationCache] = None,\n)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Runs the MID solver on simulation cases.</p> Source code in <code>src/process_manager/examples/monte_carlo/monte_carlo_workflow.py</code> <pre><code>def __init__(self,\n             mid_executable: Path,\n             progress_tracker: AsyncProgressTracker,\n             cache: Optional[SimulationCache] = None):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.PROCESS,\n        process_id=\"mid_solver\"\n    ))\n    self.mid_executable = mid_executable\n    self.progress_tracker = progress_tracker\n    self.cache = cache\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow.MIDSolver.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Dict[str, SimulationCase]) -&gt; Dict[str, SimulationCase]\n</code></pre> <p>Run solver on all cases.</p> Source code in <code>src/process_manager/examples/monte_carlo/monte_carlo_workflow.py</code> <pre><code>async def execute(self, input_data: Dict[str, SimulationCase]) -&gt; Dict[str, SimulationCase]:\n    \"\"\"Run solver on all cases.\"\"\"\n    await self.progress_tracker.update_state(ProgressState.RUNNING_SIMULATIONS)\n\n    updated_cases = {}\n    total_cases = len(input_data)\n    completed = 0\n\n    for case_id, case in input_data.items():\n        try:\n            case.state = SimulationState.RUNNING\n            case.output_file = self._run_mid_solver(case)\n            case.state = SimulationState.COMPLETED\n            await self.progress_tracker.complete_case(\n                case_id,\n                cached=case.cache_hit\n            )\n\n        except Exception as e:\n            logger.error(f\"Error processing case {case_id}: {e}\")\n            case.state = SimulationState.FAILED\n            case.error = str(e)\n            await self.progress_tracker.fail_case(case_id)\n\n        updated_cases[case_id] = case\n        completed += 1\n        self.metadata.progress = completed / total_cases * 100\n\n    return updated_cases\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow.ResultsAnalyzer","title":"ResultsAnalyzer","text":"<pre><code>ResultsAnalyzer(output_dir: Path, progress_tracker: AsyncProgressTracker)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Analyzes results from Monte Carlo simulations.</p> Source code in <code>src/process_manager/examples/monte_carlo/monte_carlo_workflow.py</code> <pre><code>def __init__(self,\n             output_dir: Path,\n             progress_tracker: AsyncProgressTracker):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.THREAD,\n        process_id=\"results_analyzer\"\n    ))\n    self.output_dir = output_dir\n    self.progress_tracker = progress_tracker\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/monte_carlo_workflow/#process_manager.examples.monte_carlo.monte_carlo_workflow.ResultsAnalyzer.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Dict[str, SimulationCase]) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Analyze all simulation results.</p> Source code in <code>src/process_manager/examples/monte_carlo/monte_carlo_workflow.py</code> <pre><code>async def execute(self, \n                 input_data: Dict[str, SimulationCase]\n                 ) -&gt; Dict[str, Dict[str, float]]:\n    \"\"\"Analyze all simulation results.\"\"\"\n    await self.progress_tracker.update_state(ProgressState.ANALYZING_RESULTS)\n\n    results = {}\n    total_cases = len(input_data)\n    completed = 0\n\n    for case_id, case in input_data.items():\n        if case.state == SimulationState.COMPLETED:\n            try:\n                results[case_id] = self._parse_results_file(case)\n                await self.progress_tracker.complete_case(case_id)\n            except Exception as e:\n                logger.error(f\"Error analyzing case {case_id}: {e}\")\n                await self.progress_tracker.fail_case(case_id)\n\n        completed += 1\n        self.metadata.progress = completed / total_cases * 100\n\n    # Generate visualizations\n    if results:\n        self._generate_visualization(results, self.output_dir)\n\n    return results\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/","title":"progress","text":""},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress","title":"progress","text":""},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.AsyncProgressTracker","title":"AsyncProgressTracker","text":"<pre><code>AsyncProgressTracker(*args, **kwargs)\n</code></pre> <p>               Bases: <code>ProgressTracker</code></p> <p>Asynchronous version of progress tracker</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self._lock = asyncio.Lock()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.AsyncProgressTracker.complete","title":"complete  <code>async</code>","text":"<pre><code>complete(success: bool = True)\n</code></pre> <p>Complete progress tracking (async)</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>async def complete(self, success: bool = True):\n    \"\"\"Complete progress tracking (async)\"\"\"\n    async with self._lock:\n        super().complete(success)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.AsyncProgressTracker.complete_case","title":"complete_case  <code>async</code>","text":"<pre><code>complete_case(case_id: str, cached: bool = False)\n</code></pre> <p>Mark a case as completed (async)</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>async def complete_case(self, case_id: str, cached: bool = False):\n    \"\"\"Mark a case as completed (async)\"\"\"\n    async with self._lock:\n        super().complete_case(case_id, cached)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.AsyncProgressTracker.fail_case","title":"fail_case  <code>async</code>","text":"<pre><code>fail_case(case_id: str)\n</code></pre> <p>Mark a case as failed (async)</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>async def fail_case(self, case_id: str):\n    \"\"\"Mark a case as failed (async)\"\"\"\n    async with self._lock:\n        super().fail_case(case_id)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.AsyncProgressTracker.start","title":"start  <code>async</code>","text":"<pre><code>start(total_cases: int)\n</code></pre> <p>Start progress tracking (async)</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>async def start(self, total_cases: int):\n    \"\"\"Start progress tracking (async)\"\"\"\n    async with self._lock:\n        super().start(total_cases)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.AsyncProgressTracker.update_state","title":"update_state  <code>async</code>","text":"<pre><code>update_state(state: ProgressState)\n</code></pre> <p>Update progress state (async)</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>async def update_state(self, state: ProgressState):\n    \"\"\"Update progress state (async)\"\"\"\n    async with self._lock:\n        super().update_state(state)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressState","title":"ProgressState","text":"<p>               Bases: <code>Enum</code></p> <p>Detailed progress states for tracking</p>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressStats","title":"ProgressStats  <code>dataclass</code>","text":"<pre><code>ProgressStats(\n    total_cases: int = 0,\n    completed_cases: int = 0,\n    failed_cases: int = 0,\n    cached_cases: int = 0,\n    current_case: Optional[str] = None,\n    start_time: Optional[datetime] = None,\n    end_time: Optional[datetime] = None,\n)\n</code></pre> <p>Statistics for progress tracking</p>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressStats.elapsed_time","title":"elapsed_time  <code>property</code>","text":"<pre><code>elapsed_time: Optional[float]\n</code></pre> <p>Get elapsed time in seconds</p>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressStats.progress_percentage","title":"progress_percentage  <code>property</code>","text":"<pre><code>progress_percentage: float\n</code></pre> <p>Get overall progress percentage</p>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressStats.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert stats to dictionary format</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert stats to dictionary format\"\"\"\n    return {\n        \"total_cases\": self.total_cases,\n        \"completed_cases\": self.completed_cases,\n        \"failed_cases\": self.failed_cases,\n        \"cached_cases\": self.cached_cases,\n        \"current_case\": self.current_case,\n        \"start_time\": self.start_time.isoformat() if self.start_time else None,\n        \"end_time\": self.end_time.isoformat() if self.end_time else None,\n        \"elapsed_time\": self.elapsed_time,\n        \"progress_percentage\": self.progress_percentage\n    }\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressTracker","title":"ProgressTracker","text":"<pre><code>ProgressTracker(\n    output_dir: Path,\n    progress_callback: Optional[Callable[[ProgressState, ProgressStats], None]] = None,\n)\n</code></pre> <p>Tracks and reports progress of Monte Carlo simulation.</p> <p>Features: - Detailed progress states - Progress statistics - Progress file output - Progress callback support - ETA calculation</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def __init__(self,\n             output_dir: Path,\n             progress_callback: Optional[Callable[[ProgressState, ProgressStats], None]] = None):\n    self.output_dir = output_dir\n    self.progress_callback = progress_callback\n    self.stats = ProgressStats()\n    self.state = ProgressState.NOT_STARTED\n    self.progress_file = output_dir / \"progress.json\"\n\n    # Ensure output directory exists\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressTracker.complete","title":"complete","text":"<pre><code>complete(success: bool = True)\n</code></pre> <p>Complete progress tracking</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def complete(self, success: bool = True):\n    \"\"\"Complete progress tracking\"\"\"\n    self.stats.end_time = datetime.now()\n    self.state = ProgressState.COMPLETED if success else ProgressState.FAILED\n    self._update()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressTracker.complete_case","title":"complete_case","text":"<pre><code>complete_case(case_id: str, cached: bool = False)\n</code></pre> <p>Mark a case as completed</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def complete_case(self, case_id: str, cached: bool = False):\n    \"\"\"Mark a case as completed\"\"\"\n    self.stats.completed_cases += 1\n    if cached:\n        self.stats.cached_cases += 1\n    self.stats.current_case = case_id\n    self._update()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressTracker.fail_case","title":"fail_case","text":"<pre><code>fail_case(case_id: str)\n</code></pre> <p>Mark a case as failed</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def fail_case(self, case_id: str):\n    \"\"\"Mark a case as failed\"\"\"\n    self.stats.failed_cases += 1\n    self.stats.current_case = case_id\n    self._update()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressTracker.start","title":"start","text":"<pre><code>start(total_cases: int)\n</code></pre> <p>Start progress tracking</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def start(self, total_cases: int):\n    \"\"\"Start progress tracking\"\"\"\n    self.stats.total_cases = total_cases\n    self.stats.start_time = datetime.now()\n    self.state = ProgressState.INITIALIZING\n    self._update()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/progress/#process_manager.examples.monte_carlo.progress.ProgressTracker.update_state","title":"update_state","text":"<pre><code>update_state(state: ProgressState)\n</code></pre> <p>Update progress state</p> Source code in <code>src/process_manager/examples/monte_carlo/progress.py</code> <pre><code>def update_state(self, state: ProgressState):\n    \"\"\"Update progress state\"\"\"\n    self.state = state\n    self._update()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/","title":"simulation_parameters","text":""},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters","title":"simulation_parameters","text":"<p>Parameter definitions for Monte Carlo simulations using data_handlers framework.</p>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters.SimulationCase","title":"SimulationCase  <code>dataclass</code>","text":"<pre><code>SimulationCase(\n    case_id: str,\n    params: Dict[str, float],\n    input_file: Path,\n    output_file: Optional[Path] = None,\n    state: SimulationState = PENDING,\n    error: Optional[str] = None,\n    cache_hit: bool = False,\n)\n</code></pre> <p>               Bases: <code>SerializableValue</code></p> <p>Represents a single simulation case.</p> <p>This class uses the SerializableValue base class from data_handlers to enable automatic serialization/deserialization.</p>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters.SimulationCase.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: Dict[str, Any]) -&gt; SimulationCase\n</code></pre> <p>Create case from dictionary format.</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_parameters.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, Any]) -&gt; 'SimulationCase':\n    \"\"\"Create case from dictionary format.\"\"\"\n    return cls(\n        case_id=data[\"case_id\"],\n        params=data[\"params\"],\n        input_file=Path(data[\"input_file\"]),\n        output_file=Path(data[\"output_file\"]) if data[\"output_file\"] else None,\n        state=SimulationState(data[\"state\"]),\n        error=data[\"error\"],\n        cache_hit=data[\"cache_hit\"]\n    )\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters.SimulationCase.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert case to dictionary format.</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_parameters.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert case to dictionary format.\"\"\"\n    return {\n        \"case_id\": self.case_id,\n        \"params\": self.params,\n        \"input_file\": str(self.input_file),\n        \"output_file\": str(self.output_file) if self.output_file else None,\n        \"state\": self.state.value,\n        \"error\": self.error,\n        \"cache_hit\": self.cache_hit\n    }\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters.SimulationParams","title":"SimulationParams","text":"<pre><code>SimulationParams(seed: Optional[int] = None, validate: bool = True)\n</code></pre> <p>Generator for simulation parameters using the data_handlers framework.</p> <p>Initialize parameter distributions.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducibility</p> <code>None</code> <code>validate</code> <code>bool</code> <p>Whether to validate parameters</p> <code>True</code> Source code in <code>src/process_manager/examples/monte_carlo/simulation_parameters.py</code> <pre><code>def __init__(self, \n             seed: Optional[int] = None,\n             validate: bool = True):\n    \"\"\"Initialize parameter distributions.\n\n    Args:\n        seed (Optional[int]): Random seed for reproducibility\n        validate (bool): Whether to validate parameters\n    \"\"\"\n    self.seed = seed\n    self.validate = validate\n    self._initialize_distributions()\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters.SimulationParams.generate","title":"generate","text":"<pre><code>generate(size: int = 1) -&gt; Dict[str, float]\n</code></pre> <p>Generate a set of simulation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of parameter sets to generate</p> <code>1</code> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dict[str, float]: Generated parameter values</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_parameters.py</code> <pre><code>def generate(self, size: int = 1) -&gt; Dict[str, float]:\n    \"\"\"Generate a set of simulation parameters.\n\n    Args:\n        size (int): Number of parameter sets to generate\n\n    Returns:\n        Dict[str, float]: Generated parameter values\n    \"\"\"\n    samples = self.variables.sample_all(size=size)\n\n    if self.validate:\n        self._validate_samples(samples)\n\n    return samples\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_parameters/#process_manager.examples.monte_carlo.simulation_parameters.SimulationState","title":"SimulationState","text":"<p>               Bases: <code>Enum</code></p> <p>Tracks the state of individual simulation cases</p>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/","title":"simulation_types","text":""},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types","title":"simulation_types","text":""},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationCase","title":"SimulationCase  <code>dataclass</code>","text":"<pre><code>SimulationCase(\n    case_id: str,\n    params: SimulationParams,\n    input_file: Path,\n    output_file: Optional[Path] = None,\n    state: SimulationState = PENDING,\n    error: Optional[str] = None,\n    cache_hit: bool = False,\n)\n</code></pre> <p>Represents a single simulation case in the Monte Carlo study.</p> <p>Attributes:</p> Name Type Description <code>case_id</code> <code>str</code> <p>Unique identifier for the case</p> <code>params</code> <code>SimulationParams</code> <p>Simulation parameters</p> <code>input_file</code> <code>Path</code> <p>Path to input file</p> <code>output_file</code> <code>Optional[Path]</code> <p>Path to output file (if completed)</p> <code>state</code> <code>SimulationState</code> <p>Current simulation state</p> <code>error</code> <code>Optional[str]</code> <p>Error message if failed</p> <code>cache_hit</code> <code>bool</code> <p>Whether result was retrieved from cache</p> Note <p>This class maintains the complete state of a simulation case throughout its lifecycle from creation to completion.</p>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationCase.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str: str) -&gt; SimulationCase\n</code></pre> <p>Create case from JSON format</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_types.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; 'SimulationCase':\n    \"\"\"Create case from JSON format\"\"\"\n    data = json.loads(json_str)\n    return cls(\n        case_id=data[\"case_id\"],\n        params=SimulationParams.from_dict(data[\"params\"]),\n        input_file=Path(data[\"input_file\"]),\n        output_file=Path(data[\"output_file\"]) if data[\"output_file\"] else None,\n        state=SimulationState(data[\"state\"]),\n        error=data[\"error\"],\n        cache_hit=data[\"cache_hit\"]\n    )\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationCase.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize case to JSON format</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_types.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Serialize case to JSON format\"\"\"\n    data = {\n        \"case_id\": self.case_id,\n        \"params\": self.params.to_dict(),\n        \"input_file\": str(self.input_file),\n        \"output_file\": str(self.output_file) if self.output_file else None,\n        \"state\": self.state.value,\n        \"error\": self.error,\n        \"cache_hit\": self.cache_hit\n    }\n    return json.dumps(data, indent=2)\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationParams","title":"SimulationParams  <code>dataclass</code>","text":"<pre><code>SimulationParams(temperature: float, pressure: float, flow_rate: float, sim_time: float)\n</code></pre> <p>Parameters for a single Monte Carlo simulation case.</p> <p>Attributes:</p> Name Type Description <code>temperature</code> <code>float</code> <p>System temperature in Kelvin (273-373K)</p> <code>pressure</code> <code>float</code> <p>System pressure in Pascal (1e5-5e5 Pa)</p> <code>flow_rate</code> <code>float</code> <p>Flow rate in m\u00b3/s (0.1-1.0 m\u00b3/s)</p> <code>sim_time</code> <code>float</code> <p>Simulation duration in seconds (10-100s)</p> Note <p>All parameters have physical bounds enforced by validation.</p>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationParams.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: Dict[str, Any]) -&gt; SimulationParams\n</code></pre> <p>Create parameters from dictionary format</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_types.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, Any]) -&gt; 'SimulationParams':\n    \"\"\"Create parameters from dictionary format\"\"\"\n    return cls(\n        temperature=float(data[\"temperature\"]),\n        pressure=float(data[\"pressure\"]),\n        flow_rate=float(data[\"flow_rate\"]),\n        sim_time=float(data[\"sim_time\"])\n    )\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationParams.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert parameters to dictionary format</p> Source code in <code>src/process_manager/examples/monte_carlo/simulation_types.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert parameters to dictionary format\"\"\"\n    return {\n        \"temperature\": self.temperature,\n        \"pressure\": self.pressure,\n        \"flow_rate\": self.flow_rate,\n        \"sim_time\": self.sim_time\n    }\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/simulation_types/#process_manager.examples.monte_carlo.simulation_types.SimulationState","title":"SimulationState","text":"<p>               Bases: <code>Enum</code></p> <p>Tracks the state of individual simulation cases</p>"},{"location":"reference/process_manager/examples/monte_carlo/validation/","title":"validation","text":""},{"location":"reference/process_manager/examples/monte_carlo/validation/#process_manager.examples.monte_carlo.validation","title":"validation","text":""},{"location":"reference/process_manager/examples/monte_carlo/validation/#process_manager.examples.monte_carlo.validation.PhysicalBounds","title":"PhysicalBounds  <code>dataclass</code>","text":"<pre><code>PhysicalBounds(min_value: float, max_value: float, units: str, description: str)\n</code></pre> <p>Defines physical bounds for simulation parameters.</p> <p>Attributes:</p> Name Type Description <code>min_value</code> <code>float</code> <p>Minimum allowed value</p> <code>max_value</code> <code>float</code> <p>Maximum allowed value</p> <code>units</code> <code>str</code> <p>Physical units for the parameter</p> <code>description</code> <code>str</code> <p>Description of the parameter</p>"},{"location":"reference/process_manager/examples/monte_carlo/validation/#process_manager.examples.monte_carlo.validation.SimulationValidator","title":"SimulationValidator","text":"<pre><code>SimulationValidator()\n</code></pre> <p>Validates simulation parameters against physical and numerical constraints.</p> <p>This class provides comprehensive validation for simulation parameters, including: - Physical bounds checking - Consistency validation - Numerical stability checks</p> <p>Initialize validator with all validation rules</p> Source code in <code>src/process_manager/examples/monte_carlo/validation.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize validator with all validation rules\"\"\"\n    self.validators = {\n        param: self._create_validator(bounds)\n        for param, bounds in self.PARAMETER_BOUNDS.items()\n    }\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/validation/#process_manager.examples.monte_carlo.validation.SimulationValidator.validate_parameter","title":"validate_parameter","text":"<pre><code>validate_parameter(param_name: str, value: float) -&gt; List[str]\n</code></pre> <p>Validate a single parameter value.</p> <p>Parameters:</p> Name Type Description Default <code>param_name</code> <code>str</code> <p>Name of the parameter to validate</p> required <code>value</code> <code>float</code> <p>Value to validate</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of validation error messages (empty if valid)</p> Source code in <code>src/process_manager/examples/monte_carlo/validation.py</code> <pre><code>def validate_parameter(self, param_name: str, value: float) -&gt; List[str]:\n    \"\"\"\n    Validate a single parameter value.\n\n    Args:\n        param_name: Name of the parameter to validate\n        value: Value to validate\n\n    Returns:\n        List of validation error messages (empty if valid)\n    \"\"\"\n    if param_name not in self.validators:\n        return [f\"Unknown parameter: {param_name}\"]\n\n    return self.validators[param_name].validate({\"value\": value})\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/validation/#process_manager.examples.monte_carlo.validation.SimulationValidator.validate_params","title":"validate_params","text":"<pre><code>validate_params(params: Dict[str, float]) -&gt; Dict[str, List[str]]\n</code></pre> <p>Validate all parameters in a parameter set.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Dict[str, float]</code> <p>Dictionary of parameter names and values</p> required <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dictionary mapping parameter names to lists of validation errors</p> Source code in <code>src/process_manager/examples/monte_carlo/validation.py</code> <pre><code>def validate_params(self, params: Dict[str, float]) -&gt; Dict[str, List[str]]:\n    \"\"\"\n    Validate all parameters in a parameter set.\n\n    Args:\n        params: Dictionary of parameter names and values\n\n    Returns:\n        Dictionary mapping parameter names to lists of validation errors\n    \"\"\"\n    errors = {}\n    for param_name, value in params.items():\n        param_errors = self.validate_parameter(param_name, value)\n        if param_errors:\n            errors[param_name] = param_errors\n    return errors\n</code></pre>"},{"location":"reference/process_manager/examples/monte_carlo/validation/#process_manager.examples.monte_carlo.validation.SimulationValidator.validate_simulation_case","title":"validate_simulation_case","text":"<pre><code>validate_simulation_case(case: SimulationCase) -&gt; List[str]\n</code></pre> <p>Validate a complete simulation case including consistency checks.</p> <p>Parameters:</p> Name Type Description Default <code>case</code> <code>SimulationCase</code> <p>SimulationCase to validate</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of validation error messages</p> Source code in <code>src/process_manager/examples/monte_carlo/validation.py</code> <pre><code>def validate_simulation_case(self, case: 'SimulationCase') -&gt; List[str]:\n    \"\"\"\n    Validate a complete simulation case including consistency checks.\n\n    Args:\n        case: SimulationCase to validate\n\n    Returns:\n        List of validation error messages\n    \"\"\"\n    errors = []\n\n    # Validate individual parameters\n    param_errors = self.validate_params(case.params.to_dict())\n    for param, param_errors in param_errors.items():\n        errors.extend(f\"{param}: {error}\" for error in param_errors)\n\n    # Consistency checks\n    if case.params.temperature &gt; 373 and case.params.pressure &gt; 4e5:\n        errors.append(\n            \"Invalid combination: High temperature and pressure may cause instability\"\n        )\n\n    # Numerical stability checks\n    reynolds_number = self._calculate_reynolds_number(case.params)\n    if reynolds_number &gt; 1e5:\n        errors.append(\n            f\"Warning: High Reynolds number ({reynolds_number:.2e}) may cause instability\"\n        )\n\n    return errors\n</code></pre>"},{"location":"reference/process_manager/examples/simple/","title":"simple","text":""},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple","title":"simple","text":"<p>Example of nested workflows for parallel random number generation.</p>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.FileWriter","title":"FileWriter","text":"<pre><code>FileWriter(output_dir: Path)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process that writes a value to a file.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>def __init__(self, output_dir: Path):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.THREAD,\n        process_id=\"file_writer\"\n    ))\n    self.output_dir = output_dir\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.FileWriter.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Dict[str, Any]) -&gt; Path\n</code></pre> <p>Async interface for the process.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>async def execute(self, input_data: Dict[str, Any]) -&gt; Path:\n    \"\"\"Async interface for the process.\"\"\"\n    return await self._run_threaded(input_data)\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.ParallelRandomWorkflow","title":"ParallelRandomWorkflow","text":"<pre><code>ParallelRandomWorkflow(\n    num_samples: int, output_dir: Path, max_parallel: int = 4, seed: Optional[int] = None\n)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process that runs multiple generate-and-save workflows in parallel.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>def __init__(self, \n             num_samples: int,\n             output_dir: Path,\n             max_parallel: int = 4,\n             seed: Optional[int] = None):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.ASYNC,\n        process_id=\"parallel_random_workflow\"\n    ))\n    self.num_samples = num_samples\n    self.output_dir = output_dir\n    self.max_parallel = max_parallel\n    self.base_seed = seed\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.ParallelRandomWorkflow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Any) -&gt; Dict[int, Path]\n</code></pre> <p>Execute multiple workflows in parallel.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>async def execute(self, input_data: Any) -&gt; Dict[int, Path]:\n    \"\"\"Execute multiple workflows in parallel.\"\"\"\n    results = {}\n    sem = asyncio.Semaphore(self.max_parallel)\n\n    async def run_workflow(index: int):\n        async with sem:\n            workflow = self._create_single_workflow(index)\n            print(f\"Starting workflow {index}\")\n            workflow_results = await workflow.execute()\n            print(f\"Workflow {index} results: {workflow_results}\")\n\n            # Get the writer's result\n            writer_id = f\"writer_{index}\"\n            if writer_id in workflow_results and workflow_results[writer_id].success:\n                results[index] = workflow_results[writer_id].data\n            else:\n                print(f\"Failed to get results for workflow {index}\")\n\n    tasks = [run_workflow(i) for i in range(self.num_samples)]\n    await asyncio.gather(*tasks)\n\n    return results\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.ParallelRandomWorkflowCPUBound","title":"ParallelRandomWorkflowCPUBound","text":"<pre><code>ParallelRandomWorkflowCPUBound(\n    num_samples: int,\n    output_dir: Path,\n    max_parallel: Optional[int] = None,\n    seed: Optional[int] = None,\n)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process that runs multiple CPU-bound generate-and-save workflows in parallel using multiprocessing.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>def __init__(self, \n             num_samples: int,\n             output_dir: Path,\n             max_parallel: Optional[int] = None,\n             seed: Optional[int] = None):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.PROCESS,\n        process_id=\"parallel_random_workflow_cpu\"\n    ))\n    self.num_samples = num_samples\n    self.output_dir = output_dir\n    self.max_parallel = max_parallel or max(1, cpu_count() - 1)\n    self.base_seed = seed\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.ParallelRandomWorkflowCPUBound.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Any) -&gt; Dict[int, Path]\n</code></pre> <p>Async interface that runs the sync implementation.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>async def execute(self, input_data: Any) -&gt; Dict[int, Path]:\n    \"\"\"Async interface that runs the sync implementation.\"\"\"\n    return await self._run_process(input_data)\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.RandomNumberGenerator","title":"RandomNumberGenerator","text":"<pre><code>RandomNumberGenerator(seed: Optional[int] = None)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process that generates a random number using data_handlers.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>def __init__(self, seed: Optional[int] = None):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.THREAD,\n        process_id=\"random_generator\"\n    ))\n    self.distribution = NormalDistribution(\n        name=\"random_value\",\n        mu=0.0,\n        sigma=1.0,\n        seed=seed\n    )\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.RandomNumberGenerator.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Any) -&gt; float\n</code></pre> <p>Async interface for the process.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>async def execute(self, input_data: Any) -&gt; float:\n    \"\"\"Async interface for the process.\"\"\"\n    return await self._run_threaded(input_data)\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.main","title":"main  <code>async</code>","text":"<pre><code>main()\n</code></pre> <p>Example usage of parallel random workflow.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>async def main():\n    \"\"\"Example usage of parallel random workflow.\"\"\"\n    # Create and configure the main workflow\n    main_workflow = create_workflow()\n\n    # Create the parallel process\n    parallel_process = ParallelRandomWorkflow(\n        num_samples=10,\n        output_dir=Path(\"random_outputs\"),\n        max_parallel=3,\n        seed=42\n    )\n\n    # Create and add workflow node\n    node = WorkflowNode(\n        process=parallel_process,\n        dependencies=[],\n        required=True\n    )\n    main_workflow.add_node(node)\n\n    # Execute workflow\n    results = await main_workflow.execute()\n\n    # Print results\n    if parallel_process.config.process_id in results and results[parallel_process.config.process_id].success:\n        output_files = results[parallel_process.config.process_id].data\n        print(f\"Generated files: {output_files}\")\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.main_cpu_bound","title":"main_cpu_bound  <code>async</code>","text":"<pre><code>main_cpu_bound()\n</code></pre> <p>Example usage of parallel random workflow with CPU-bound processes.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>async def main_cpu_bound():\n    \"\"\"Example usage of parallel random workflow with CPU-bound processes.\"\"\"\n    # Create and configure the main workflow\n    main_workflow = create_workflow()\n\n    # Create the parallel process\n    parallel_process = ParallelRandomWorkflowCPUBound(\n        num_samples=10,\n        output_dir=Path(\"random_outputs_cpu\"),\n        max_parallel=3,\n        seed=42\n    )\n\n    # Create and add workflow node\n    node = WorkflowNode(\n        process=parallel_process,\n        dependencies=[],\n        required=True\n    )\n    main_workflow.add_node(node)\n\n    # Execute workflow\n    results = await main_workflow.execute()\n\n    # Print results\n    if parallel_process.config.process_id in results and results[parallel_process.config.process_id].success:\n        output_files = results[parallel_process.config.process_id].data\n        print(f\"Generated files: {output_files}\")\n</code></pre>"},{"location":"reference/process_manager/examples/simple/#process_manager.examples.simple.run_single_workflow_wrapper","title":"run_single_workflow_wrapper","text":"<pre><code>run_single_workflow_wrapper(workflow_creator, index: int) -&gt; Dict[str, Any]\n</code></pre> <p>Standalone function to run a single workflow.</p> Source code in <code>src/process_manager/examples/simple/__init__.py</code> <pre><code>def run_single_workflow_wrapper(workflow_creator, index: int) -&gt; Dict[str, Any]:\n    \"\"\"Standalone function to run a single workflow.\"\"\"\n    try:\n        # Create a new workflow for this process\n        workflow = workflow_creator(index)\n\n        # Create and run event loop\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        try:\n            results = loop.run_until_complete(workflow.execute())\n            loop.close()\n\n            return {\n                'index': index,\n                'success': True,\n                'results': results\n            }\n        finally:\n            loop.close()\n    except Exception as e:\n        return {\n            'index': index,\n            'success': False,\n            'error': str(e)\n        }\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v2/","title":"v2","text":""},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2","title":"v2","text":"<p>Example of nested workflows for parallel random number generation.</p>"},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2.FileWriter","title":"FileWriter","text":"<pre><code>FileWriter(index: int, output_dir: Path)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> Source code in <code>src/process_manager/examples/simple/v2.py</code> <pre><code>def __init__(self, index: int, output_dir: Path):\n    super().__init__(\n        process_type=ProcessType.THREAD,\n        base_name=\"writer\",\n        index=index\n    )\n    self.output_dir = output_dir\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2.FileWriter.process","title":"process","text":"<pre><code>process(input_data: Dict[str, Any]) -&gt; Path\n</code></pre> <p>Just the core logic without error handling.</p> Source code in <code>src/process_manager/examples/simple/v2.py</code> <pre><code>def process(self, input_data: Dict[str, Any]) -&gt; Path:\n    \"\"\"Just the core logic without error handling.\"\"\"\n    generator_id = ProcessId(\"generator\", self.config.process_id.split('_')[-1])\n    value = self.get_process_result(input_data, generator_id)\n\n    output_file = self.output_dir / f\"value_{self.config.process_id}.txt\"\n    with open(output_file, 'w') as f:\n        f.write(f\"{value}\\n\")\n\n    return output_file\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2.RandomNumberGenerator","title":"RandomNumberGenerator","text":"<pre><code>RandomNumberGenerator(index: int, seed: Optional[int] = None)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> Source code in <code>src/process_manager/examples/simple/v2.py</code> <pre><code>def __init__(self, index: int, seed: Optional[int] = None):\n    super().__init__(\n        process_type=ProcessType.THREAD,\n        base_name=\"generator\",\n        index=index\n    )\n    self.distribution = NormalDistribution(\n        name=\"random_value\",\n        mu=0.0,\n        sigma=1.0,\n        seed=seed\n    )\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2.RandomNumberGenerator.process","title":"process","text":"<pre><code>process(input_data: Any) -&gt; float\n</code></pre> <p>Just the core logic without error handling.</p> Source code in <code>src/process_manager/examples/simple/v2.py</code> <pre><code>def process(self, input_data: Any) -&gt; float:\n    \"\"\"Just the core logic without error handling.\"\"\"\n    return self.distribution.sample(size=1).item()\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2.execute_workflow_process","title":"execute_workflow_process","text":"<pre><code>execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]\n</code></pre> <p>Create and execute a single workflow process.</p> Source code in <code>src/process_manager/examples/simple/v2.py</code> <pre><code>def execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]:\n    \"\"\"Create and execute a single workflow process.\"\"\"\n    index, seed, output_dir = args\n\n    # Create workflow\n    workflow = create_workflow(\n        max_threads=1,\n        process_id=f\"workflow_process_{index}\"\n    )\n\n    # Create and add nodes\n    generator = RandomNumberGenerator(index=index, seed=seed)\n    writer = FileWriter(index=index, output_dir=output_dir)\n\n    workflow.add_node(WorkflowNode(\n        process=generator,\n        dependencies=[],\n        required=True\n    ))\n\n    workflow.add_node(WorkflowNode(\n        process=writer,\n        dependencies=[generator.config.process_id],\n        required=True\n    ))\n\n    # The framework handles event loop and execution\n    workflow_results = workflow.execute()\n    return {\n        'index': index,\n        'success': True,\n        'results': workflow_results\n    }\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v2/#process_manager.examples.simple.v2.main_cpu_bound","title":"main_cpu_bound  <code>async</code>","text":"<pre><code>main_cpu_bound()\n</code></pre> <p>Example usage of parallel random workflow with CPU-bound processes.</p> Source code in <code>src/process_manager/examples/simple/v2.py</code> <pre><code>async def main_cpu_bound():\n    \"\"\"Example usage of parallel random workflow with CPU-bound processes.\"\"\"\n    try:\n        # Create and configure the main workflow\n        main_workflow = create_workflow(\n            process_id=\"main_workflow\"\n        )\n\n        # Create the parallel process\n        parallel_process = ParallelRandomWorkflowCPUBound(\n            num_samples=3,  # Reduced for testing\n            output_dir=Path(\"random_outputs_cpu\"),\n            max_parallel=2,\n            seed=42\n        )\n\n        # Create and add workflow node\n        node = WorkflowNode(\n            process=parallel_process,\n            dependencies=[],\n            required=True\n        )\n        main_workflow.add_node(node)\n\n        try:\n            # Execute workflow\n            print(\"Starting main workflow execution...\")\n            results = await main_workflow.execute()\n\n            # Print results\n            if parallel_process.config.process_id in results and results[parallel_process.config.process_id].success:\n                output_files = results[parallel_process.config.process_id].data\n                print(f\"Generated files: {output_files}\")\n            else:\n                print(\"Workflow execution failed\")\n\n        finally:\n            main_workflow.shutdown()  # Clean up main workflow pools\n\n    except Exception as e:\n        print(\"Error in main_cpu_bound:\")\n        print(\"\".join(traceback.format_exception(*sys.exc_info())))\n        raise\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v3/","title":"v3","text":""},{"location":"reference/process_manager/examples/simple/v3/#process_manager.examples.simple.v3","title":"v3","text":"<p>Example of nested workflows for parallel random number generation.</p>"},{"location":"reference/process_manager/examples/simple/v3/#process_manager.examples.simple.v3.execute_workflow_process","title":"execute_workflow_process","text":"<pre><code>execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]\n</code></pre> <p>Create and execute a single workflow process.</p> Source code in <code>src/process_manager/examples/simple/v3.py</code> <pre><code>def execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]:\n    \"\"\"Create and execute a single workflow process.\"\"\"\n    index, seed, output_dir = args\n\n    workflow = create_workflow(\n        max_threads=1,\n        process_id=f\"workflow_process_{index}\"\n    )\n\n    generator = RandomNumberGenerator(index=index, seed=seed)\n    writer = FileWriter(index=index, output_dir=output_dir)\n\n    workflow.add_node(WorkflowNode(\n        process=generator,\n        dependencies=[],\n        required=True\n    ))\n\n    workflow.add_node(WorkflowNode(\n        process=writer,\n        dependencies=[generator.config.process_id],\n        required=True\n    ))\n\n    # Framework handles execution and result wrapping\n    return workflow.execute()\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v4/","title":"v4","text":""},{"location":"reference/process_manager/examples/simple/v4/#process_manager.examples.simple.v4","title":"v4","text":"<p>Example of nested workflows for parallel random number generation.</p>"},{"location":"reference/process_manager/examples/simple/v4/#process_manager.examples.simple.v4.execute_workflow_process","title":"execute_workflow_process","text":"<pre><code>execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]\n</code></pre> <p>Create and execute a single workflow process.</p> Source code in <code>src/process_manager/examples/simple/v4.py</code> <pre><code>def execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]:\n    \"\"\"Create and execute a single workflow process.\"\"\"\n    index, seed, output_dir = args\n\n    workflow = create_workflow(\n        max_threads=1,\n        process_id=f\"workflow_process_{index}\"\n    )\n\n    generator = RandomNumberGenerator(index=index, seed=seed)\n    writer = FileWriter(index=index, output_dir=output_dir)\n\n    workflow.add_node(WorkflowNode(\n        process=generator,\n        dependencies=[],\n        required=True\n    ))\n\n    workflow.add_node(WorkflowNode(\n        process=writer,\n        dependencies=[generator.config.process_id],\n        required=True\n    ))\n\n    # Run the coroutine in a new event loop\n    loop = asyncio.new_event_loop()\n    try:\n        asyncio.set_event_loop(loop)\n        return loop.run_until_complete(workflow.execute())\n    finally:\n        loop.close()\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v5/","title":"v5","text":""},{"location":"reference/process_manager/examples/simple/v5/#process_manager.examples.simple.v5","title":"v5","text":"<p>Example of nested workflows for parallel random number generation.</p>"},{"location":"reference/process_manager/examples/simple/v5/#process_manager.examples.simple.v5.execute_workflow_process","title":"execute_workflow_process","text":"<pre><code>execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]\n</code></pre> <p>Create and execute a single workflow process.</p> Source code in <code>src/process_manager/examples/simple/v5.py</code> <pre><code>def execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]:\n    \"\"\"Create and execute a single workflow process.\"\"\"\n    index, seed, output_dir = args\n\n    workflow = create_workflow(\n        max_threads=1,\n        process_id=f\"workflow_process_{index}\"\n    )\n\n    generator = RandomNumberGenerator(index=index, seed=seed)\n    writer = FileWriter(index=index, output_dir=output_dir)\n\n    workflow.add_node(WorkflowNode(\n        process=generator,\n        dependencies=[],\n        required=True\n    ))\n\n    workflow.add_node(WorkflowNode(\n        process=writer,\n        dependencies=[generator.config.process_id],  # Use the full process_id\n        required=True\n    ))\n\n    # Run the coroutine in a new event loop\n    loop = asyncio.new_event_loop()\n    try:\n        asyncio.set_event_loop(loop)\n        return loop.run_until_complete(workflow.execute())\n    finally:\n        loop.close()\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v6/","title":"v6","text":""},{"location":"reference/process_manager/examples/simple/v6/#process_manager.examples.simple.v6","title":"v6","text":"<p>Example of nested workflows for parallel random number generation.</p>"},{"location":"reference/process_manager/examples/simple/v6/#process_manager.examples.simple.v6.execute_workflow_process","title":"execute_workflow_process","text":"<pre><code>execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]\n</code></pre> <p>Create and execute a single workflow process.</p> Source code in <code>src/process_manager/examples/simple/v6.py</code> <pre><code>def execute_workflow_process(args: Tuple[int, Optional[int], Path]) -&gt; Dict[str, Any]:\n    \"\"\"Create and execute a single workflow process.\"\"\"\n    index, seed, output_dir = args\n\n    workflow = create_workflow(\n        max_threads=1,\n        process_id=f\"workflow_process_{index}\"\n    )\n\n    generator = RandomNumberGenerator(index=index, seed=seed)\n    writer = FileWriter(index=index, output_dir=output_dir)\n\n    workflow.add_node(WorkflowNode(\n        process=generator,\n        dependencies=[],\n        required=True\n    ))\n\n    workflow.add_node(WorkflowNode(\n        process=writer,\n        dependencies=[generator.config.process_id],  # Use the full process_id\n        required=True\n    ))\n\n    # Run the coroutine in a new event loop\n    loop = asyncio.new_event_loop()\n    try:\n        asyncio.set_event_loop(loop)\n        return loop.run_until_complete(workflow.execute())\n    finally:\n        loop.close()\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v7/","title":"v7","text":""},{"location":"reference/process_manager/examples/simple/v7/#process_manager.examples.simple.v7","title":"v7","text":"<p>Example of a simple CPU-bound process that generates a random wait time and returns a Pydantic model.</p>"},{"location":"reference/process_manager/examples/simple/v7/#process_manager.examples.simple.v7.WaitResult","title":"WaitResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model to represent the result of a random wait process.</p>"},{"location":"reference/process_manager/examples/simple/v8/","title":"v8","text":""},{"location":"reference/process_manager/examples/simple/v8/#process_manager.examples.simple.v8","title":"v8","text":"<p>Example of a process that uses ProcessResult with NamedValueHash for data handling.</p>"},{"location":"reference/process_manager/examples/simple/v8/#process_manager.examples.simple.v8.ProcessResult","title":"ProcessResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Generic process result that includes a NamedValueHash for data storage.</p>"},{"location":"reference/process_manager/examples/simple/v9/","title":"v9","text":""},{"location":"reference/process_manager/examples/simple/v9/#process_manager.examples.simple.v9","title":"v9","text":"<p>Example of a process using composition rather than inheritance.</p>"},{"location":"reference/process_manager/examples/simple/v9/#process_manager.examples.simple.v9.ProcessResult","title":"ProcessResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Generic process result that includes a NamedValueHash for data storage.</p>"},{"location":"reference/process_manager/examples/simple/v9/#process_manager.examples.simple.v9.RandomWaitConfig","title":"RandomWaitConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a random wait process.</p>"},{"location":"reference/process_manager/examples/simple/v9/#process_manager.examples.simple.v9.create_random_wait_process","title":"create_random_wait_process","text":"<pre><code>create_random_wait_process(config: RandomWaitConfig) -&gt; BaseProcess\n</code></pre> <p>Factory function to create a random wait process.</p> Source code in <code>src/process_manager/examples/simple/v9.py</code> <pre><code>def create_random_wait_process(config: RandomWaitConfig) -&gt; BaseProcess:\n    \"\"\"Factory function to create a random wait process.\"\"\"\n    process = BaseProcess(\n        config=ProcessConfig(\n            process_type=ProcessType.PROCESS,\n            process_id=config.process_id\n        )\n    )\n    # Bind the config to the function and set it as the process method\n    process.process = partial(random_wait_function, config)\n    return process\n</code></pre>"},{"location":"reference/process_manager/examples/simple/v9/#process_manager.examples.simple.v9.random_wait_function","title":"random_wait_function","text":"<pre><code>random_wait_function(config: RandomWaitConfig, input_data: Any) -&gt; ProcessResult\n</code></pre> <p>Function that implements the random wait logic.</p> Source code in <code>src/process_manager/examples/simple/v9.py</code> <pre><code>def random_wait_function(config: RandomWaitConfig, input_data: Any) -&gt; ProcessResult:\n    \"\"\"Function that implements the random wait logic.\"\"\"\n    # Initialize random number generator\n    rng = random.Random(config.seed)\n\n    # Generate random wait time\n    wait_time = rng.uniform(config.min_wait, config.max_wait)\n\n    print(f\"Process {config.process_index} starting with wait time: {wait_time:.2f} seconds\")\n    time.sleep(wait_time)\n    print(f\"Process {config.process_index} completed\")\n\n    # Create a NamedValueHash to store the process data\n    data = dh.NamedValueHash()\n    data.register_value(value=dh.NamedValue(\"wait_time\", wait_time))\n    data.register_value(value=dh.NamedValue(\"process_name\", f\"random_wait_{config.process_index}\"))\n    data.register_value(value=dh.NamedValue(\"random_seed\", config.seed))  # Get first value from random state\n\n    return ProcessResult(\n        process_index=config.process_index,\n        timestamp=time.time(),\n        data=data\n    )\n</code></pre>"},{"location":"reference/process_manager/workflow/","title":"workflow","text":""},{"location":"reference/process_manager/workflow/#process_manager.workflow","title":"workflow","text":"<p>Workflow package initialization.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess","title":"BaseProcess","text":"<pre><code>BaseProcess(config: ProcessConfig)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all process implementations.</p> <p>The BaseProcess class provides a framework for implementing custom processes that can be executed in different contexts (async, threaded, or multiprocess). It handles common functionality like execution tracking, error handling, and workflow integration.</p> Key Features <ul> <li>Flexible execution strategies (async, thread, process)</li> <li>Built-in timeout handling</li> <li>Automatic execution time tracking</li> <li>Process state management</li> <li>Error handling and reporting</li> </ul> <p>Attributes:</p> Name Type Description <code>config</code> <code>ProcessConfig</code> <p>Configuration settings for the process</p> <code>metadata</code> <code>ProcessMetadata</code> <p>Runtime metadata and state tracking</p> <code>_workflow</code> <code>Optional[Workflow]</code> <p>Reference to parent workflow</p> Example <pre><code>class MyProcess(BaseProcess):\n    def __init__(self):\n        super().__init__(ProcessConfig(\n            process_type=ProcessType.THREAD,\n            process_id=\"my_process\"\n        ))\n\n    async def execute(self, input_data: dict) -&gt; dict:\n        # Implement process logic here\n        return processed_data\n</code></pre> <p>Initialize the process with configuration settings.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ProcessConfig</code> <p>Process configuration including: - process_type: Execution strategy (ASYNC, THREAD, PROCESS) - process_id: Unique identifier for the process - timeout: Optional timeout duration in seconds</p> required Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def __init__(self, config: ProcessConfig):\n    \"\"\"Initialize the process with configuration settings.\n\n    Args:\n        config (ProcessConfig): Process configuration including:\n            - process_type: Execution strategy (ASYNC, THREAD, PROCESS)\n            - process_id: Unique identifier for the process\n            - timeout: Optional timeout duration in seconds\n    \"\"\"\n    self.config = config\n    self.metadata = ProcessMetadata(\n        process_id=config.process_id,\n        state=ProcessState.WAITING\n    )\n    self._workflow: Optional[Workflow] = None\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Any) -&gt; ProcessResult\n</code></pre> <p>Execute the process using the appropriate execution strategy.</p> <p>Uses the parent workflow's pool manager if the process is attached to a workflow, otherwise creates a standalone pool manager for independent execution.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the process</p> required <p>Returns:</p> Type Description <code>ProcessResult</code> <p>ProcessResult containing the execution result and metadata</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>async def execute(self, input_data: Any) -&gt; ProcessResult:\n    \"\"\"\n    Execute the process using the appropriate execution strategy.\n\n    Uses the parent workflow's pool manager if the process is attached to a workflow,\n    otherwise creates a standalone pool manager for independent execution.\n\n    Args:\n        input_data: Input data for the process\n\n    Returns:\n        ProcessResult containing the execution result and metadata\n    \"\"\"\n    try:\n        pool_manager = self._workflow.pool_manager\n        process_id = self._workflow.process_id  # Already unique\n    except AttributeError:\n        # Process is not attached to a workflow, create standalone pool manager\n        pool_manager = WorkflowPoolManager.get_instance()\n        process_id = f\"workflow_{id(self)}\"  # Match workflow's ID format\n        print(f\"Warning: Process {self.config.process_id} is not attached to a workflow. Using standalone pool manager.\")\n\n    try:\n        pools = pool_manager.get_or_create_pools(process_id)\n        match self.config.process_type:\n            case ProcessType.ASYNC:\n                return await self._sync_execute(input_data)\n\n            case ProcessType.THREAD | ProcessType.PROCESS:\n                loop = asyncio.get_running_loop()\n                return await loop.run_in_executor(\n                    pools[self.config.process_type],\n                    self._sync_execute,\n                    input_data\n                )\n\n            case _:\n                raise ValueError(f\"Unknown process type: {self.config.process_type}\")\n    finally:\n        pass\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess.get_process_result","title":"get_process_result  <code>classmethod</code>","text":"<pre><code>get_process_result(input_data: Dict[str, Any], process_id: ProcessId) -&gt; Any\n</code></pre> <p>Helper method to consistently extract data from process results.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Dict[str, Any]</code> <p>Dictionary containing process results</p> required <code>process_id</code> <code>ProcessId</code> <p>ProcessId of the process whose result we want</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The data from the specified process result</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the process result is not found or invalid</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>@classmethod\ndef get_process_result(cls, input_data: Dict[str, Any], process_id: ProcessId) -&gt; Any:\n    \"\"\"\n    Helper method to consistently extract data from process results.\n\n    Args:\n        input_data: Dictionary containing process results\n        process_id: ProcessId of the process whose result we want\n\n    Returns:\n        The data from the specified process result\n\n    Raises:\n        ValueError: If the process result is not found or invalid\n    \"\"\"\n    key = str(process_id)\n    if key not in input_data:\n        raise ValueError(f\"Required process {key} not found in input data\")\n\n    result = input_data[key]\n    if isinstance(result, ProcessResult):\n        if not result.success:\n            raise ValueError(f\"Process {key} did not complete successfully\")\n        return result.data\n    else:\n        raise ValueError(f\"Expected ProcessResult for {key}, got {type(result)}\")\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess.process","title":"process","text":"<pre><code>process(input_data: Any) -&gt; Any\n</code></pre> <p>Main processing logic to be implemented by subclasses.</p> <p>This is the primary method that users should override. It contains just the core processing logic without worrying about execution details.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>The input data to process</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The processed result</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def process(self, input_data: Any) -&gt; Any:\n    \"\"\"\n    Main processing logic to be implemented by subclasses.\n\n    This is the primary method that users should override. It contains\n    just the core processing logic without worrying about execution details.\n\n    Args:\n        input_data: The input data to process\n\n    Returns:\n        The processed result\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement process()\")\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess.register_to","title":"register_to","text":"<pre><code>register_to(\n    workflow: Workflow, dependencies: Optional[List[str | ProcessId]] = None, required: bool = True\n) -&gt; BaseProcess\n</code></pre> <p>Register this process as a WorkflowNode to the given workflow.</p> <p>Parameters:</p> Name Type Description Default <code>workflow</code> <code>Workflow</code> <p>The workflow to register this process to</p> required <code>dependencies</code> <code>Optional[List[str | ProcessId]]</code> <p>Optional list of process IDs that this process depends on</p> <code>None</code> <code>required</code> <code>bool</code> <p>Whether this process is required for workflow completion</p> <code>True</code> <p>Returns:</p> Type Description <code>Self</code> <p>Reference for method chaining</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def register_to(\n    self,\n    workflow: Workflow,\n    dependencies: Optional[List[str|ProcessId]] = None,\n    required: bool = True\n) -&gt; BaseProcess:\n    \"\"\"\n    Register this process as a WorkflowNode to the given workflow.\n\n    Args:\n        workflow (Workflow): The workflow to register this process to\n        dependencies (Optional[List[str|ProcessId]]): Optional list of process IDs that this process depends on\n        required (bool): Whether this process is required for workflow completion\n\n    Returns:\n        (Self): Reference for method chaining\n    \"\"\"\n    workflow.add_node(\n        WorkflowNode(\n            process=self,\n            dependencies=dependencies or [],\n            required=required,\n        )\n    )\n    return self\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess.run","title":"run  <code>async</code>","text":"<pre><code>run(input_data: Any) -&gt; ProcessResult\n</code></pre> <p>Run the process with the configured execution strategy.</p> <p>This method handles: 1. Process state management 2. Execution time tracking 3. Error handling 4. Result packaging</p> <p>The execution strategy is determined by the process_type setting in the configuration (ASYNC, THREAD, or PROCESS).</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the process</p> required <p>Returns:</p> Name Type Description <code>ProcessResult</code> <code>ProcessResult</code> <p>Object containing: - success: Whether execution completed successfully - data: Process output data - execution_time: Time taken in seconds - start_time: Execution start timestamp - end_time: Execution end timestamp - error: Error information if execution failed</p> <p>Raises:</p> Type Description <code>ProcessError</code> <p>If execution fails for any reason</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>async def run(self, input_data: Any) -&gt; ProcessResult:\n    \"\"\"Run the process with the configured execution strategy.\n\n    This method handles:\n    1. Process state management\n    2. Execution time tracking\n    3. Error handling\n    4. Result packaging\n\n    The execution strategy is determined by the process_type setting\n    in the configuration (ASYNC, THREAD, or PROCESS).\n\n    Args:\n        input_data (Any): Input data for the process\n\n    Returns:\n        ProcessResult: Object containing:\n            - success: Whether execution completed successfully\n            - data: Process output data\n            - execution_time: Time taken in seconds\n            - start_time: Execution start timestamp\n            - end_time: Execution end timestamp\n            - error: Error information if execution failed\n\n    Raises:\n        ProcessError: If execution fails for any reason\n    \"\"\"\n    self.metadata.state = ProcessState.RUNNING\n    start_time = datetime.now()\n\n    try:\n        # Choose execution strategy based on process type\n        if self.config.process_type == ProcessType.ASYNC:\n            result = await self._run_async(input_data)\n        elif self.config.process_type == ProcessType.THREAD:\n            result = await self._run_threaded(input_data)\n        else:  # ProcessType.PROCESS\n            result = await self._run_multiprocess(input_data)\n\n        end_time = datetime.now()\n        execution_time = (end_time - start_time).total_seconds()\n\n        process_result = ProcessResult(\n            success=True,\n            data=result,\n            execution_time=execution_time,\n            start_time=start_time,\n            end_time=end_time\n        )\n\n        self.metadata.state = ProcessState.COMPLETED\n        return process_result\n\n    except Exception as e:\n        end_time = datetime.now()\n        execution_time = (end_time - start_time).total_seconds()\n\n        process_result = ProcessResult(\n            success=False,\n            data=None,\n            execution_time=execution_time,\n            start_time=start_time,\n            end_time=end_time,\n            error=str(e),\n            error_type=type(e).__name__\n        )\n\n        self.metadata.state = ProcessState.FAILED\n        return process_result\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.BaseProcess.set_workflow","title":"set_workflow","text":"<pre><code>set_workflow(workflow: Workflow) -&gt; None\n</code></pre> <p>Set reference to parent workflow for resource access.</p> <p>This method is called by the workflow when the process is added. The workflow reference provides access to shared resources like thread and process pools.</p> <p>Parameters:</p> Name Type Description Default <code>workflow</code> <code>Workflow</code> <p>Parent workflow instance</p> required Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def set_workflow(self, workflow: Workflow) -&gt; None:\n    \"\"\"Set reference to parent workflow for resource access.\n\n    This method is called by the workflow when the process is added.\n    The workflow reference provides access to shared resources like\n    thread and process pools.\n\n    Args:\n        workflow (Workflow): Parent workflow instance\n    \"\"\"\n    self._workflow = workflow\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessConfig","title":"ProcessConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration settings for a process.</p> <p>Defines how a process should be executed and handled.</p> <p>Attributes:</p> Name Type Description <code>process_type</code> <code>ProcessType</code> <p>Type of execution (async, thread, process)</p> <code>process_id</code> <code>str</code> <p>Unique identifier for the process</p> <code>timeout</code> <code>Optional[float]</code> <p>Maximum execution time in seconds</p> <code>retry_strategy</code> <code>Optional[RetryStrategy]</code> <p>Configuration for retry behavior</p> <code>fail_fast</code> <code>bool</code> <p>Whether to stop workflow on failure</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessMetadata","title":"ProcessMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Runtime metadata for a process.</p> <p>Tracks the current state, progress, and execution history of a process.</p> <p>Attributes:</p> Name Type Description <code>process_id</code> <code>str</code> <p>Unique identifier for the process</p> <code>state</code> <code>ProcessState</code> <p>Current execution state</p> <code>retries</code> <code>int</code> <p>Number of retry attempts made</p> <code>retry_count</code> <code>int</code> <p>Alias for retries</p> <code>progress</code> <code>float</code> <p>Completion percentage (0-100)</p> <code>start_time</code> <code>Optional[datetime]</code> <p>When execution started</p> <code>end_time</code> <code>Optional[datetime]</code> <p>When execution finished</p> <code>last_error</code> <code>Optional[str]</code> <p>Most recent error message</p> <code>result</code> <code>Optional[ProcessResult]</code> <p>Latest execution result</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessMetadata.retry_count","title":"retry_count  <code>property</code>","text":"<pre><code>retry_count: int\n</code></pre> <p>Alias for retries count.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessResult","title":"ProcessResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a process execution.</p> <p>Contains all information about a process execution attempt including timing, success/failure status, and any output data or errors.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>Whether execution completed successfully</p> <code>data</code> <code>Any</code> <p>Output data from the process</p> <code>execution_time</code> <code>float</code> <p>Time taken in seconds</p> <code>start_time</code> <code>datetime</code> <p>When execution started</p> <code>end_time</code> <code>datetime</code> <p>When execution finished</p> <code>error</code> <code>Optional[str]</code> <p>Error message if execution failed</p> <code>error_type</code> <code>Optional[str]</code> <p>Type of error that occurred</p> <code>error_message</code> <code>Optional[str]</code> <p>Formatted error message</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessResult.error_message","title":"error_message  <code>property</code>","text":"<pre><code>error_message: Optional[str]\n</code></pre> <p>Formatted error message combining type and description.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessResult.model_dump","title":"model_dump","text":"<pre><code>model_dump(*args, **kwargs) -&gt; Dict[str, Any]\n</code></pre> <p>Convert result to dictionary format.</p> <p>Overrides pydantic's dict() to handle datetime serialization.</p> Source code in <code>src/process_manager/workflow/workflow_types.py</code> <pre><code>def model_dump(self, *args, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"Convert result to dictionary format.\n\n    Overrides pydantic's dict() to handle datetime serialization.\n    \"\"\"\n    base_dict = super().model_dump(*args, **kwargs)\n    # Convert datetime objects to ISO format strings\n    base_dict['start_time'] = self.start_time.isoformat()\n    base_dict['end_time'] = self.end_time.isoformat()\n    return base_dict\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessState","title":"ProcessState","text":"<p>               Bases: <code>Enum</code></p> <p>States a process can be in during execution.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.ProcessType","title":"ProcessType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of process execution strategies.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.RetryStrategy","title":"RetryStrategy","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for process retry behavior.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow","title":"Workflow","text":"<pre><code>Workflow(\n    max_processes: Optional[int] = None,\n    max_threads: Optional[int] = None,\n    process_id: Optional[str] = None,\n)\n</code></pre> <p>Manages the execution of a workflow graph.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def __init__(self, \n             max_processes: Optional[int] = None,\n             max_threads: Optional[int] = None,\n             process_id: Optional[str] = None):\n    self.nodes: Dict[str, WorkflowNode] = {}\n    self.results: Dict[str, ProcessResult] = {}\n    self.max_processes = max_processes\n    self.max_threads = max_threads\n    self.process_id = process_id or f\"workflow_{id(self)}\"\n    self.pool_manager = WorkflowPoolManager.get_instance()\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow.execution_graph","title":"execution_graph  <code>property</code>","text":"<pre><code>execution_graph: Dict[str, List[str]]\n</code></pre> <p>Build a graph of process dependencies.</p>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow.add_node","title":"add_node","text":"<pre><code>add_node(node: WorkflowNode) -&gt; None\n</code></pre> <p>Add a node to the workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def add_node(self, node: WorkflowNode) -&gt; None:\n    \"\"\"Add a node to the workflow.\"\"\"\n    self.nodes[node.process.config.process_id] = node\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(initial_data: Dict[str, Any] = None) -&gt; Dict[str, ProcessResult]\n</code></pre> <p>Execute the workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>async def execute(self, initial_data: Dict[str, Any] = None) -&gt; Dict[str, ProcessResult]:\n    \"\"\"Execute the workflow.\"\"\"\n    try:\n        with self.get_pools() as (thread_pool, process_pool):\n            # ... (keep existing code until the results processing part)\n            initial_data = initial_data or {}\n            node_results: Dict[str, ProcessResult] = {}\n            completed_nodes = set()\n            failed_nodes = set()\n\n            all_nodes = set(self.nodes.keys())\n\n            while len(completed_nodes) &lt; len(self.nodes):\n                ready_nodes = [\n                    node_id for node_id in all_nodes - completed_nodes\n                    if (\n                        all(dep in completed_nodes for dep in self.nodes[node_id].dependencies) and\n                        all(\n                            dep not in failed_nodes or \n                            not self.nodes[dep].required \n                            for dep in self.nodes[node_id].dependencies\n                        )\n                    )\n                ]\n\n                if not ready_nodes:\n                    remaining_nodes = all_nodes - completed_nodes\n                    if remaining_nodes:\n                        unmet_dependencies = {\n                            node: [\n                                dep for dep in self.nodes[node].dependencies\n                                if dep not in completed_nodes\n                            ]\n                            for node in remaining_nodes\n                        }\n                        raise Exception(\n                            f\"Workflow deadlock detected. Unmet dependencies: {unmet_dependencies}\"\n                        )\n                    break\n\n                async_nodes = []\n                thread_nodes = []\n                process_nodes = []\n\n                for node_id in ready_nodes:\n                    process_type = self.nodes[node_id].process.config.process_type\n                    match process_type:\n                        case ProcessType.ASYNC:\n                            async_nodes.append(node_id)\n                        case ProcessType.THREAD:\n                            thread_nodes.append(node_id)\n                        case ProcessType.PROCESS:\n                            process_nodes.append(node_id)\n                        case _:\n                            raise ValueError(f\"Invalid ProcessType: {process_type}\")\n\n                tasks = []\n\n                for node_id in ready_nodes:\n                    node = self.nodes[node_id]\n                    node_input = {}\n\n                    for dep in node.dependencies:\n                        if dep in node_results and node_results[dep].success:\n                            node_input[dep] = node_results[dep].data\n\n                    if not node.dependencies and node_id in initial_data:\n                        node_input = initial_data[node_id]\n\n                    if node_id in async_nodes:\n                        tasks.append(node.process.run(node_input))\n\n                    elif node_id in thread_nodes:\n                        loop = asyncio.get_running_loop()\n                        tasks.append(\n                            loop.run_in_executor(\n                                thread_pool,\n                                self._run_sync_process,\n                                node.process,\n                                node_input\n                            )\n                        )\n\n                    else:  # process_nodes\n                        loop = asyncio.get_running_loop()\n                        tasks.append(\n                            loop.run_in_executor(\n                                process_pool,\n                                self._run_sync_process,\n                                node.process,\n                                node_input\n                            )\n                        )\n\n                # Execute all ready nodes in parallel\n                results = await asyncio.gather(*tasks, return_exceptions=True)\n\n                # Process results and update workflow state\n                for node_id, result in zip(ready_nodes, results):\n                    node = self.nodes[node_id]\n                    completed_nodes.add(node_id)\n\n                    if isinstance(result, Exception):\n                        node.process.metadata.state = ProcessState.FAILED\n                        node.process.metadata.last_error = str(result)\n                        failed_nodes.add(node_id)\n\n                        if node.required:\n                            if node.process.config.fail_fast:\n                                raise Exception(\n                                    f\"Critical node {node_id} failed: {str(result)}\"\n                                )\n                        continue\n\n                    # Wrap the result in ProcessResult if it isn't already\n                    if not isinstance(result, ProcessResult):\n                        result = ProcessResult(\n                            success=True,\n                            data=result,\n                            execution_time=0,  # We don't have timing info here\n                            start_time=datetime.now(),  # Approximate\n                            end_time=datetime.now()\n                        )\n\n                    node_results[node_id] = result\n                    if not result.success:\n                        failed_nodes.add(node_id)\n                        if node.required and node.process.config.fail_fast:\n                            raise Exception(\n                                f\"Critical node {node_id} failed: {result.error}\"\n                            )\n\n            self.results = node_results\n            return node_results\n# async def execute(self, initial_data: Dict[str, Any] = None) -&gt; Dict[str, ProcessResult]:\n#     \"\"\"Execute the workflow.\"\"\"\n#     try:\n#         with self.get_pools() as (thread_pool, process_pool):\n#             initial_data = initial_data or {}\n#             node_results: Dict[str, ProcessResult] = {}\n#             completed_nodes = set()\n#             failed_nodes = set()\n\n#             all_nodes = set(self.nodes.keys())\n\n#             while len(completed_nodes) &lt; len(self.nodes):\n#                 ready_nodes = [\n#                     node_id for node_id in all_nodes - completed_nodes\n#                     if (\n#                         all(dep in completed_nodes for dep in self.nodes[node_id].dependencies) and\n#                         all(\n#                             dep not in failed_nodes or \n#                             not self.nodes[dep].required \n#                             for dep in self.nodes[node_id].dependencies\n#                         )\n#                     )\n#                 ]\n\n#                 if not ready_nodes:\n#                     remaining_nodes = all_nodes - completed_nodes\n#                     if remaining_nodes:\n#                         unmet_dependencies = {\n#                             node: [\n#                                 dep for dep in self.nodes[node].dependencies\n#                                 if dep not in completed_nodes\n#                             ]\n#                             for node in remaining_nodes\n#                         }\n#                         raise Exception(\n#                             f\"Workflow deadlock detected. Unmet dependencies: {unmet_dependencies}\"\n#                         )\n#                     break\n\n#                 async_nodes = []\n#                 thread_nodes = []\n#                 process_nodes = []\n\n#                 for node_id in ready_nodes:\n#                     process_type = self.nodes[node_id].process.config.process_type\n#                     match process_type:\n#                         case ProcessType.ASYNC:\n#                             async_nodes.append(node_id)\n#                         case ProcessType.THREAD:\n#                             thread_nodes.append(node_id)\n#                         case ProcessType.PROCESS:\n#                             process_nodes.append(node_id)\n#                         case _:\n#                             raise ValueError(f\"Invalid ProcessType: {process_type}\")\n\n#                 tasks = []\n\n#                 for node_id in ready_nodes:\n#                     node = self.nodes[node_id]\n#                     node_input = {}\n\n#                     for dep in node.dependencies:\n#                         if dep in node_results and node_results[dep].success:\n#                             node_input[dep] = node_results[dep].data\n\n#                     if not node.dependencies and node_id in initial_data:\n#                         node_input = initial_data[node_id]\n\n#                     if node_id in async_nodes:\n#                         tasks.append(node.process.run(node_input))\n\n#                     elif node_id in thread_nodes:\n#                         loop = asyncio.get_running_loop()\n#                         tasks.append(\n#                             loop.run_in_executor(\n#                                 thread_pool,\n#                                 self._run_sync_process,\n#                                 node.process,\n#                                 node_input\n#                             )\n#                         )\n\n#                     else:  # process_nodes\n#                         loop = asyncio.get_running_loop()\n#                         tasks.append(\n#                             loop.run_in_executor(\n#                                 process_pool,\n#                                 self._run_sync_process,\n#                                 node.process,\n#                                 node_input\n#                             )\n#                         )\n\n#                 results = await asyncio.gather(*tasks, return_exceptions=True)\n\n#                 for node_id, result in zip(ready_nodes, results):\n#                     node = self.nodes[node_id]\n#                     completed_nodes.add(node_id)\n\n#                     if isinstance(result, Exception):\n#                         node.process.metadata.state = ProcessState.FAILED\n#                         node.process.metadata.last_error = str(result)\n#                         failed_nodes.add(node_id)\n\n#                         if node.required:\n#                             if node.process.config.fail_fast:\n#                                 raise Exception(\n#                                     f\"Critical node {node_id} failed: {str(result)}\"\n#                                 )\n#                         continue\n\n#                     node_results[node_id] = result\n#                     if not result.success:\n#                         failed_nodes.add(node_id)\n#                         if node.required and node.process.config.fail_fast:\n#                             raise Exception(\n#                                 f\"Critical node {node_id} failed: {result.error}\"\n#                             )\n\n#             self.results = node_results\n#             return node_results\n\n    except Exception as e:\n        for node_id in all_nodes - completed_nodes:\n            self.nodes[node_id].process.metadata.state = ProcessState.SKIPPED\n        raise\n\n    finally:\n        for node_id, result in node_results.items():\n            self.nodes[node_id].process.metadata.result = result\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow.get_pools","title":"get_pools","text":"<pre><code>get_pools()\n</code></pre> <p>Get pools for this workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>@contextmanager\ndef get_pools(self):\n    \"\"\"Get pools for this workflow.\"\"\"\n    try:\n        pools = self.pool_manager.get_or_create_pools(\n            self.process_id,\n            self.max_threads,\n            self.max_processes\n        )\n        yield pools['thread_pool'], pools['process_pool']\n    finally:\n        pass  # Don't cleanup here, pools are reused\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow.shutdown","title":"shutdown","text":"<pre><code>shutdown()\n</code></pre> <p>Cleanup resources for this workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def shutdown(self):\n    \"\"\"Cleanup resources for this workflow.\"\"\"\n    self.pool_manager.cleanup_pools(self.process_id)\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.Workflow.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize the workflow state to JSON.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Serialize the workflow state to JSON.\"\"\"\n    workflow_state = {\n        \"nodes\": {\n            node_id: {\n                \"process_id\": node.process.config.process_id,\n                \"dependencies\": node.dependencies,\n                \"required\": node.required,\n                \"state\": node.process.metadata.state.value,\n                \"retry_count\": node.process.metadata.retry_count,\n                \"last_error\": node.process.metadata.last_error\n            }\n            for node_id, node in self.nodes.items()\n        },\n        \"results\": {\n            node_id: result.dict() for node_id, result in self.results.items()\n        }\n    }\n    return json.dumps(workflow_state, default=str)\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.WorkflowNode","title":"WorkflowNode","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a node in the workflow graph.</p> <p>A WorkflowNode encapsulates a process and its dependency information within a workflow. It tracks both the process itself and any other processes that must complete before this node can execute.</p> <p>Attributes:</p> Name Type Description <code>process</code> <code>BaseProcess</code> <p>The process to execute at this node</p> <code>dependencies</code> <code>List[str]</code> <p>Process IDs that must complete before this node</p> <code>required</code> <code>bool</code> <p>Whether this node must complete for workflow success</p> Example <pre><code>node = WorkflowNode(\n    process=MyProcess(),\n    dependencies=[\"process1\", \"process2\"],\n    required=True\n)\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.WorkflowNode.can_execute","title":"can_execute","text":"<pre><code>can_execute(completed_nodes: List[str]) -&gt; bool\n</code></pre> <p>Check if this node is ready to execute.</p> <p>A node can execute when all its dependencies have completed.</p> <p>Parameters:</p> Name Type Description Default <code>completed_nodes</code> <code>List[str]</code> <p>Process IDs that have completed</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if all dependencies are satisfied</p> Example <pre><code>if node.can_execute([\"process1\", \"process2\"]):\n    await node.process.run(input_data)\n</code></pre> Source code in <code>src/process_manager/workflow/workflow_types.py</code> <pre><code>def can_execute(self, completed_nodes: List[str]) -&gt; bool:\n    \"\"\"Check if this node is ready to execute.\n\n    A node can execute when all its dependencies have completed.\n\n    Args:\n        completed_nodes (List[str]): Process IDs that have completed\n\n    Returns:\n        bool: True if all dependencies are satisfied\n\n    Example:\n        ```python\n        if node.can_execute([\"process1\", \"process2\"]):\n            await node.process.run(input_data)\n        ```\n    \"\"\"\n    return all(\n        dep in completed_nodes \n        for dep in self.dependencies\n    )\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.WorkflowNode.validate_dependencies","title":"validate_dependencies","text":"<pre><code>validate_dependencies(available_nodes: List[str]) -&gt; List[str]\n</code></pre> <p>Validate that all dependencies exist in the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>available_nodes</code> <code>List[str]</code> <p>List of all process IDs in the workflow</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of any missing dependencies</p> Example <pre><code>missing = node.validate_dependencies([\"process1\", \"process2\"])\nif missing:\n    print(f\"Missing dependencies: {missing}\")\n</code></pre> Source code in <code>src/process_manager/workflow/workflow_types.py</code> <pre><code>def validate_dependencies(self, available_nodes: List[str]) -&gt; List[str]:\n    \"\"\"Validate that all dependencies exist in the workflow.\n\n    Args:\n        available_nodes (List[str]): List of all process IDs in the workflow\n\n    Returns:\n        List[str]: List of any missing dependencies\n\n    Example:\n        ```python\n        missing = node.validate_dependencies([\"process1\", \"process2\"])\n        if missing:\n            print(f\"Missing dependencies: {missing}\")\n        ```\n    \"\"\"\n    return [\n        dep for dep in self.dependencies \n        if dep not in available_nodes\n    ]\n</code></pre>"},{"location":"reference/process_manager/workflow/#process_manager.workflow.create_workflow","title":"create_workflow","text":"<pre><code>create_workflow(\n    max_processes: Optional[int] = None,\n    max_threads: Optional[int] = None,\n    process_id: Optional[str] = None,\n) -&gt; Workflow\n</code></pre> <p>Create a new workflow instance with specified pool sizes.</p> <p>Parameters:</p> Name Type Description Default <code>max_processes</code> <code>Optional[int]</code> <p>Maximum number of processes in the process pool</p> <code>None</code> <code>max_threads</code> <code>Optional[int]</code> <p>Maximum number of threads in the thread pool</p> <code>None</code> <code>process_id</code> <code>Optional[str]</code> <p>Unique identifier for this workflow instance</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>A new workflow instance</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def create_workflow(\n        max_processes: Optional[int] = None,\n        max_threads: Optional[int] = None,\n        process_id: Optional[str] = None) -&gt; Workflow:\n    \"\"\"Create a new workflow instance with specified pool sizes.\n\n    Args:\n        max_processes: Maximum number of processes in the process pool\n        max_threads: Maximum number of threads in the thread pool\n        process_id: Unique identifier for this workflow instance\n\n    Returns:\n        Workflow: A new workflow instance\n    \"\"\"\n    return Workflow(\n        max_processes=max_processes,\n        max_threads=max_threads,\n        process_id=process_id\n    )\n</code></pre>"},{"location":"reference/process_manager/workflow/core/","title":"core","text":""},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core","title":"core","text":"<p>Core workflow implementation.</p>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow","title":"Workflow","text":"<pre><code>Workflow(\n    max_processes: Optional[int] = None,\n    max_threads: Optional[int] = None,\n    process_id: Optional[str] = None,\n)\n</code></pre> <p>Manages the execution of a workflow graph.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def __init__(self, \n             max_processes: Optional[int] = None,\n             max_threads: Optional[int] = None,\n             process_id: Optional[str] = None):\n    self.nodes: Dict[str, WorkflowNode] = {}\n    self.results: Dict[str, ProcessResult] = {}\n    self.max_processes = max_processes\n    self.max_threads = max_threads\n    self.process_id = process_id or f\"workflow_{id(self)}\"\n    self.pool_manager = WorkflowPoolManager.get_instance()\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow.execution_graph","title":"execution_graph  <code>property</code>","text":"<pre><code>execution_graph: Dict[str, List[str]]\n</code></pre> <p>Build a graph of process dependencies.</p>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow.add_node","title":"add_node","text":"<pre><code>add_node(node: WorkflowNode) -&gt; None\n</code></pre> <p>Add a node to the workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def add_node(self, node: WorkflowNode) -&gt; None:\n    \"\"\"Add a node to the workflow.\"\"\"\n    self.nodes[node.process.config.process_id] = node\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(initial_data: Dict[str, Any] = None) -&gt; Dict[str, ProcessResult]\n</code></pre> <p>Execute the workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>async def execute(self, initial_data: Dict[str, Any] = None) -&gt; Dict[str, ProcessResult]:\n    \"\"\"Execute the workflow.\"\"\"\n    try:\n        with self.get_pools() as (thread_pool, process_pool):\n            # ... (keep existing code until the results processing part)\n            initial_data = initial_data or {}\n            node_results: Dict[str, ProcessResult] = {}\n            completed_nodes = set()\n            failed_nodes = set()\n\n            all_nodes = set(self.nodes.keys())\n\n            while len(completed_nodes) &lt; len(self.nodes):\n                ready_nodes = [\n                    node_id for node_id in all_nodes - completed_nodes\n                    if (\n                        all(dep in completed_nodes for dep in self.nodes[node_id].dependencies) and\n                        all(\n                            dep not in failed_nodes or \n                            not self.nodes[dep].required \n                            for dep in self.nodes[node_id].dependencies\n                        )\n                    )\n                ]\n\n                if not ready_nodes:\n                    remaining_nodes = all_nodes - completed_nodes\n                    if remaining_nodes:\n                        unmet_dependencies = {\n                            node: [\n                                dep for dep in self.nodes[node].dependencies\n                                if dep not in completed_nodes\n                            ]\n                            for node in remaining_nodes\n                        }\n                        raise Exception(\n                            f\"Workflow deadlock detected. Unmet dependencies: {unmet_dependencies}\"\n                        )\n                    break\n\n                async_nodes = []\n                thread_nodes = []\n                process_nodes = []\n\n                for node_id in ready_nodes:\n                    process_type = self.nodes[node_id].process.config.process_type\n                    match process_type:\n                        case ProcessType.ASYNC:\n                            async_nodes.append(node_id)\n                        case ProcessType.THREAD:\n                            thread_nodes.append(node_id)\n                        case ProcessType.PROCESS:\n                            process_nodes.append(node_id)\n                        case _:\n                            raise ValueError(f\"Invalid ProcessType: {process_type}\")\n\n                tasks = []\n\n                for node_id in ready_nodes:\n                    node = self.nodes[node_id]\n                    node_input = {}\n\n                    for dep in node.dependencies:\n                        if dep in node_results and node_results[dep].success:\n                            node_input[dep] = node_results[dep].data\n\n                    if not node.dependencies and node_id in initial_data:\n                        node_input = initial_data[node_id]\n\n                    if node_id in async_nodes:\n                        tasks.append(node.process.run(node_input))\n\n                    elif node_id in thread_nodes:\n                        loop = asyncio.get_running_loop()\n                        tasks.append(\n                            loop.run_in_executor(\n                                thread_pool,\n                                self._run_sync_process,\n                                node.process,\n                                node_input\n                            )\n                        )\n\n                    else:  # process_nodes\n                        loop = asyncio.get_running_loop()\n                        tasks.append(\n                            loop.run_in_executor(\n                                process_pool,\n                                self._run_sync_process,\n                                node.process,\n                                node_input\n                            )\n                        )\n\n                # Execute all ready nodes in parallel\n                results = await asyncio.gather(*tasks, return_exceptions=True)\n\n                # Process results and update workflow state\n                for node_id, result in zip(ready_nodes, results):\n                    node = self.nodes[node_id]\n                    completed_nodes.add(node_id)\n\n                    if isinstance(result, Exception):\n                        node.process.metadata.state = ProcessState.FAILED\n                        node.process.metadata.last_error = str(result)\n                        failed_nodes.add(node_id)\n\n                        if node.required:\n                            if node.process.config.fail_fast:\n                                raise Exception(\n                                    f\"Critical node {node_id} failed: {str(result)}\"\n                                )\n                        continue\n\n                    # Wrap the result in ProcessResult if it isn't already\n                    if not isinstance(result, ProcessResult):\n                        result = ProcessResult(\n                            success=True,\n                            data=result,\n                            execution_time=0,  # We don't have timing info here\n                            start_time=datetime.now(),  # Approximate\n                            end_time=datetime.now()\n                        )\n\n                    node_results[node_id] = result\n                    if not result.success:\n                        failed_nodes.add(node_id)\n                        if node.required and node.process.config.fail_fast:\n                            raise Exception(\n                                f\"Critical node {node_id} failed: {result.error}\"\n                            )\n\n            self.results = node_results\n            return node_results\n# async def execute(self, initial_data: Dict[str, Any] = None) -&gt; Dict[str, ProcessResult]:\n#     \"\"\"Execute the workflow.\"\"\"\n#     try:\n#         with self.get_pools() as (thread_pool, process_pool):\n#             initial_data = initial_data or {}\n#             node_results: Dict[str, ProcessResult] = {}\n#             completed_nodes = set()\n#             failed_nodes = set()\n\n#             all_nodes = set(self.nodes.keys())\n\n#             while len(completed_nodes) &lt; len(self.nodes):\n#                 ready_nodes = [\n#                     node_id for node_id in all_nodes - completed_nodes\n#                     if (\n#                         all(dep in completed_nodes for dep in self.nodes[node_id].dependencies) and\n#                         all(\n#                             dep not in failed_nodes or \n#                             not self.nodes[dep].required \n#                             for dep in self.nodes[node_id].dependencies\n#                         )\n#                     )\n#                 ]\n\n#                 if not ready_nodes:\n#                     remaining_nodes = all_nodes - completed_nodes\n#                     if remaining_nodes:\n#                         unmet_dependencies = {\n#                             node: [\n#                                 dep for dep in self.nodes[node].dependencies\n#                                 if dep not in completed_nodes\n#                             ]\n#                             for node in remaining_nodes\n#                         }\n#                         raise Exception(\n#                             f\"Workflow deadlock detected. Unmet dependencies: {unmet_dependencies}\"\n#                         )\n#                     break\n\n#                 async_nodes = []\n#                 thread_nodes = []\n#                 process_nodes = []\n\n#                 for node_id in ready_nodes:\n#                     process_type = self.nodes[node_id].process.config.process_type\n#                     match process_type:\n#                         case ProcessType.ASYNC:\n#                             async_nodes.append(node_id)\n#                         case ProcessType.THREAD:\n#                             thread_nodes.append(node_id)\n#                         case ProcessType.PROCESS:\n#                             process_nodes.append(node_id)\n#                         case _:\n#                             raise ValueError(f\"Invalid ProcessType: {process_type}\")\n\n#                 tasks = []\n\n#                 for node_id in ready_nodes:\n#                     node = self.nodes[node_id]\n#                     node_input = {}\n\n#                     for dep in node.dependencies:\n#                         if dep in node_results and node_results[dep].success:\n#                             node_input[dep] = node_results[dep].data\n\n#                     if not node.dependencies and node_id in initial_data:\n#                         node_input = initial_data[node_id]\n\n#                     if node_id in async_nodes:\n#                         tasks.append(node.process.run(node_input))\n\n#                     elif node_id in thread_nodes:\n#                         loop = asyncio.get_running_loop()\n#                         tasks.append(\n#                             loop.run_in_executor(\n#                                 thread_pool,\n#                                 self._run_sync_process,\n#                                 node.process,\n#                                 node_input\n#                             )\n#                         )\n\n#                     else:  # process_nodes\n#                         loop = asyncio.get_running_loop()\n#                         tasks.append(\n#                             loop.run_in_executor(\n#                                 process_pool,\n#                                 self._run_sync_process,\n#                                 node.process,\n#                                 node_input\n#                             )\n#                         )\n\n#                 results = await asyncio.gather(*tasks, return_exceptions=True)\n\n#                 for node_id, result in zip(ready_nodes, results):\n#                     node = self.nodes[node_id]\n#                     completed_nodes.add(node_id)\n\n#                     if isinstance(result, Exception):\n#                         node.process.metadata.state = ProcessState.FAILED\n#                         node.process.metadata.last_error = str(result)\n#                         failed_nodes.add(node_id)\n\n#                         if node.required:\n#                             if node.process.config.fail_fast:\n#                                 raise Exception(\n#                                     f\"Critical node {node_id} failed: {str(result)}\"\n#                                 )\n#                         continue\n\n#                     node_results[node_id] = result\n#                     if not result.success:\n#                         failed_nodes.add(node_id)\n#                         if node.required and node.process.config.fail_fast:\n#                             raise Exception(\n#                                 f\"Critical node {node_id} failed: {result.error}\"\n#                             )\n\n#             self.results = node_results\n#             return node_results\n\n    except Exception as e:\n        for node_id in all_nodes - completed_nodes:\n            self.nodes[node_id].process.metadata.state = ProcessState.SKIPPED\n        raise\n\n    finally:\n        for node_id, result in node_results.items():\n            self.nodes[node_id].process.metadata.result = result\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow.get_pools","title":"get_pools","text":"<pre><code>get_pools()\n</code></pre> <p>Get pools for this workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>@contextmanager\ndef get_pools(self):\n    \"\"\"Get pools for this workflow.\"\"\"\n    try:\n        pools = self.pool_manager.get_or_create_pools(\n            self.process_id,\n            self.max_threads,\n            self.max_processes\n        )\n        yield pools['thread_pool'], pools['process_pool']\n    finally:\n        pass  # Don't cleanup here, pools are reused\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow.shutdown","title":"shutdown","text":"<pre><code>shutdown()\n</code></pre> <p>Cleanup resources for this workflow.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def shutdown(self):\n    \"\"\"Cleanup resources for this workflow.\"\"\"\n    self.pool_manager.cleanup_pools(self.process_id)\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.Workflow.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize the workflow state to JSON.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Serialize the workflow state to JSON.\"\"\"\n    workflow_state = {\n        \"nodes\": {\n            node_id: {\n                \"process_id\": node.process.config.process_id,\n                \"dependencies\": node.dependencies,\n                \"required\": node.required,\n                \"state\": node.process.metadata.state.value,\n                \"retry_count\": node.process.metadata.retry_count,\n                \"last_error\": node.process.metadata.last_error\n            }\n            for node_id, node in self.nodes.items()\n        },\n        \"results\": {\n            node_id: result.dict() for node_id, result in self.results.items()\n        }\n    }\n    return json.dumps(workflow_state, default=str)\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.WorkflowPoolManager","title":"WorkflowPoolManager","text":"<p>Manages thread and process pools across workflows.</p>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.WorkflowPoolManager.cleanup_pools","title":"cleanup_pools","text":"<pre><code>cleanup_pools(process_id: str) -&gt; None\n</code></pre> <p>Cleanup pools for a specific process.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def cleanup_pools(self, process_id: str) -&gt; None:\n    \"\"\"Cleanup pools for a specific process.\"\"\"\n    if process_id in self._pools:\n        pools = self._pools[process_id]\n        pools['thread_pool'].shutdown()\n        pools['process_pool'].shutdown()\n        del self._pools[process_id]\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.WorkflowPoolManager.get_or_create_pools","title":"get_or_create_pools","text":"<pre><code>get_or_create_pools(\n    process_id: str, max_threads: Optional[int] = None, max_processes: Optional[int] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>Get or create pools for a specific process.</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def get_or_create_pools(self, process_id: str, max_threads: Optional[int] = None, max_processes: Optional[int] = None) -&gt; Dict[str, Any]:\n    \"\"\"Get or create pools for a specific process.\"\"\"\n    if process_id not in self._pools:\n        self._pools[process_id] = {\n            'thread_pool': ThreadPoolExecutor(max_workers=max_threads),\n            'process_pool': ProcessPoolExecutor(max_workers=max_processes)\n        }\n    return self._pools[process_id]\n</code></pre>"},{"location":"reference/process_manager/workflow/core/#process_manager.workflow.core.create_workflow","title":"create_workflow","text":"<pre><code>create_workflow(\n    max_processes: Optional[int] = None,\n    max_threads: Optional[int] = None,\n    process_id: Optional[str] = None,\n) -&gt; Workflow\n</code></pre> <p>Create a new workflow instance with specified pool sizes.</p> <p>Parameters:</p> Name Type Description Default <code>max_processes</code> <code>Optional[int]</code> <p>Maximum number of processes in the process pool</p> <code>None</code> <code>max_threads</code> <code>Optional[int]</code> <p>Maximum number of threads in the thread pool</p> <code>None</code> <code>process_id</code> <code>Optional[str]</code> <p>Unique identifier for this workflow instance</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>A new workflow instance</p> Source code in <code>src/process_manager/workflow/core.py</code> <pre><code>def create_workflow(\n        max_processes: Optional[int] = None,\n        max_threads: Optional[int] = None,\n        process_id: Optional[str] = None) -&gt; Workflow:\n    \"\"\"Create a new workflow instance with specified pool sizes.\n\n    Args:\n        max_processes: Maximum number of processes in the process pool\n        max_threads: Maximum number of threads in the thread pool\n        process_id: Unique identifier for this workflow instance\n\n    Returns:\n        Workflow: A new workflow instance\n    \"\"\"\n    return Workflow(\n        max_processes=max_processes,\n        max_threads=max_threads,\n        process_id=process_id\n    )\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/","title":"id_generator","text":""},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator","title":"id_generator","text":""},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.ProcessIdGenerator","title":"ProcessIdGenerator","text":"<pre><code>ProcessIdGenerator(prefix: str = 'proc')\n</code></pre> <p>Thread-safe process ID generator.</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def __init__(self, prefix: str = \"proc\"):\n    self._prefix = prefix\n    self._counter = 0\n    self._lock = Lock()\n    self._reserved_ids = set()\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.ProcessIdGenerator.is_reserved","title":"is_reserved","text":"<pre><code>is_reserved(process_id: str) -&gt; bool\n</code></pre> <p>Check if a process ID is already reserved.</p> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <code>str</code> <p>The process ID to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the ID is reserved, False otherwise</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def is_reserved(self, process_id: str) -&gt; bool:\n    \"\"\"\n    Check if a process ID is already reserved.\n\n    Args:\n        process_id: The process ID to check\n\n    Returns:\n        True if the ID is reserved, False otherwise\n    \"\"\"\n    return process_id in self._reserved_ids\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.ProcessIdGenerator.next_id","title":"next_id","text":"<pre><code>next_id(prefix: Optional[str] = None) -&gt; str\n</code></pre> <p>Generate and reserve the next available process ID.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Optional[str]</code> <p>Optional override for the default prefix</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A unique process ID string in format: prefix_number (e.g., proc_1)</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def next_id(self, prefix: Optional[str] = None) -&gt; str:\n    \"\"\"\n    Generate and reserve the next available process ID.\n\n    Args:\n        prefix: Optional override for the default prefix\n\n    Returns:\n        A unique process ID string in format: prefix_number (e.g., proc_1)\n    \"\"\"\n    with self._lock:\n        self._counter += 1\n        while True:\n            process_id = f\"{prefix or self._prefix}_{self._counter}\"\n            if process_id not in self._reserved_ids:\n                self._reserved_ids.add(process_id)\n                return process_id\n            self._counter += 1\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.ProcessIdGenerator.release_id","title":"release_id","text":"<pre><code>release_id(process_id: str) -&gt; None\n</code></pre> <p>Release a reserved process ID back to the pool.</p> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <code>str</code> <p>The process ID to release</p> required Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def release_id(self, process_id: str) -&gt; None:\n    \"\"\"\n    Release a reserved process ID back to the pool.\n\n    Args:\n        process_id: The process ID to release\n    \"\"\"\n    with self._lock:\n        self._reserved_ids.discard(process_id)\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.ProcessIdGenerator.reserve_id","title":"reserve_id","text":"<pre><code>reserve_id(process_id: str) -&gt; bool\n</code></pre> <p>Try to reserve a specific process ID.</p> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <code>str</code> <p>The process ID to reserve</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the ID was reserved, False if already taken</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def reserve_id(self, process_id: str) -&gt; bool:\n    \"\"\"\n    Try to reserve a specific process ID.\n\n    Args:\n        process_id: The process ID to reserve\n\n    Returns:\n        True if the ID was reserved, False if already taken\n    \"\"\"\n    with self._lock:\n        if process_id in self._reserved_ids:\n            return False\n        self._reserved_ids.add(process_id)\n\n        # Update counter if necessary to maintain sequence\n        match = re.match(f\"{self._prefix}_(\\d+)\", process_id)\n        if match:\n            num = int(match.group(1))\n            self._counter = max(self._counter, num)\n\n        return True\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.ProcessIdGenerator.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the generator state.</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset the generator state.\"\"\"\n    with self._lock:\n        self._counter = 0\n        self._reserved_ids.clear()\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.TimestampedProcessIdGenerator","title":"TimestampedProcessIdGenerator","text":"<pre><code>TimestampedProcessIdGenerator(prefix: str = 'proc')\n</code></pre> <p>               Bases: <code>ProcessIdGenerator</code></p> <p>Process ID generator that includes timestamps in IDs.</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def __init__(self, prefix: str = \"proc\"):\n    self._prefix = prefix\n    self._counter = 0\n    self._lock = Lock()\n    self._reserved_ids = set()\n</code></pre>"},{"location":"reference/process_manager/workflow/id_generator/#process_manager.workflow.id_generator.TimestampedProcessIdGenerator.next_id","title":"next_id","text":"<pre><code>next_id(prefix: Optional[str] = None) -&gt; str\n</code></pre> <p>Generate a timestamped process ID.</p> <p>Returns:</p> Type Description <code>str</code> <p>A unique process ID string in format: prefix_timestamp_number </p> <code>str</code> <p>(e.g., proc_20230815_1)</p> Source code in <code>src/process_manager/workflow/id_generator.py</code> <pre><code>def next_id(self, prefix: Optional[str] = None) -&gt; str:\n    \"\"\"\n    Generate a timestamped process ID.\n\n    Returns:\n        A unique process ID string in format: prefix_timestamp_number \n        (e.g., proc_20230815_1)\n    \"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d\")\n    with self._lock:\n        self._counter += 1\n        while True:\n            process_id = f\"{prefix or self._prefix}_{timestamp}_{self._counter}\"\n            if process_id not in self._reserved_ids:\n                self._reserved_ids.add(process_id)\n                return process_id\n            self._counter += 1\n</code></pre>"},{"location":"reference/process_manager/workflow/implementations/","title":"implementations","text":""},{"location":"reference/process_manager/workflow/implementations/#process_manager.workflow.implementations","title":"implementations","text":""},{"location":"reference/process_manager/workflow/implementations/#process_manager.workflow.implementations.AsyncAPIProcess","title":"AsyncAPIProcess","text":"<pre><code>AsyncAPIProcess(config: ProcessConfig, url: str, method: str = 'GET')\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process implementation for async API operations.</p> Source code in <code>src/process_manager/workflow/implementations.py</code> <pre><code>def __init__(self, config: ProcessConfig, url: str, method: str = \"GET\"):\n    config.process_type = ProcessType.ASYNC\n    super().__init__(config)\n    self.url = url\n    self.method = method\n</code></pre>"},{"location":"reference/process_manager/workflow/implementations/#process_manager.workflow.implementations.CommandLineProcess","title":"CommandLineProcess","text":"<pre><code>CommandLineProcess(\n    config: ProcessConfig, command: str, input_mode: str = \"template\", input_format: str = \"json\"\n)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process implementation for running command-line programs.</p> <p>Supports several ways to handle input data: 1. Template strings in command: \"{var_name}\" 2. Environment variables 3. Input files 4. Command line arguments</p> <p>Initialize CommandLineProcess.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ProcessConfig</code> <p>Process configuration</p> required <code>command</code> <code>str</code> <p>Command string to execute</p> required <code>input_mode</code> <code>str</code> <p>How to pass input data to command        (\"template\", \"env\", \"file\", \"args\")</p> <code>'template'</code> <code>input_format</code> <code>str</code> <p>Format for input data (\"json\", \"text\", \"raw\")</p> <code>'json'</code> Source code in <code>src/process_manager/workflow/implementations.py</code> <pre><code>def __init__(self, \n             config: ProcessConfig, \n             command: str,\n             input_mode: str = \"template\",\n             input_format: str = \"json\"):\n    \"\"\"\n    Initialize CommandLineProcess.\n\n    Args:\n        config: Process configuration\n        command: Command string to execute\n        input_mode: How to pass input data to command\n                   (\"template\", \"env\", \"file\", \"args\")\n        input_format: Format for input data (\"json\", \"text\", \"raw\")\n    \"\"\"\n    config.process_type = ProcessType.PROCESS\n    super().__init__(config)\n    self.command = command\n    self.input_mode = input_mode\n    self.input_format = input_format\n</code></pre>"},{"location":"reference/process_manager/workflow/implementations/#process_manager.workflow.implementations.DataTransformProcess","title":"DataTransformProcess","text":"<pre><code>DataTransformProcess(config: ProcessConfig, transform_func: Callable)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process implementation for data transformation.</p> Source code in <code>src/process_manager/workflow/implementations.py</code> <pre><code>def __init__(self, config: ProcessConfig, transform_func: Callable):\n    config.process_type = ProcessType.PROCESS\n    super().__init__(config)\n    self.transform_func = transform_func\n</code></pre>"},{"location":"reference/process_manager/workflow/implementations/#process_manager.workflow.implementations.IOBoundProcess","title":"IOBoundProcess","text":"<pre><code>IOBoundProcess(config: ProcessConfig)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Process for I/O-bound operations.</p> Source code in <code>src/process_manager/workflow/implementations.py</code> <pre><code>def __init__(self, config: ProcessConfig):\n    config.process_type = ProcessType.THREAD  # Force thread pool\n    super().__init__(config)\n</code></pre>"},{"location":"reference/process_manager/workflow/mc/","title":"mc","text":""},{"location":"reference/process_manager/workflow/mc/#process_manager.workflow.mc","title":"mc","text":""},{"location":"reference/process_manager/workflow/mc/#process_manager.workflow.mc.InputGenerator","title":"InputGenerator","text":"<pre><code>InputGenerator(output_dir: Path, num_simulations: int)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Generates input files for the MID solver</p> Source code in <code>src/process_manager/workflow/mc.py</code> <pre><code>def __init__(self, output_dir: Path, num_simulations: int):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.THREAD,\n        process_id=\"input_generator\"\n    ))\n    self.output_dir = output_dir\n    self.num_simulations = num_simulations\n    self.file_handler = FileHandler(output_dir)\n</code></pre>"},{"location":"reference/process_manager/workflow/mc/#process_manager.workflow.mc.MIDSolver","title":"MIDSolver","text":"<pre><code>MIDSolver(mid_executable: Path)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Runs the MID solver on input files</p> Source code in <code>src/process_manager/workflow/mc.py</code> <pre><code>def __init__(self, mid_executable: Path):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.PROCESS,  # Use process pool for parallel execution\n        process_id=\"mid_solver\"\n    ))\n    self.mid_executable = mid_executable\n</code></pre>"},{"location":"reference/process_manager/workflow/mc/#process_manager.workflow.mc.ResultsAnalyzer","title":"ResultsAnalyzer","text":"<pre><code>ResultsAnalyzer(output_dir: Path)\n</code></pre> <p>               Bases: <code>BaseProcess</code></p> <p>Analyzes results from all Monte Carlo simulations</p> Source code in <code>src/process_manager/workflow/mc.py</code> <pre><code>def __init__(self, output_dir: Path):\n    super().__init__(ProcessConfig(\n        process_type=ProcessType.THREAD,\n        process_id=\"results_analyzer\"\n    ))\n    self.output_dir = output_dir\n    self.file_handler = FileHandler(output_dir)\n</code></pre>"},{"location":"reference/process_manager/workflow/mc/#process_manager.workflow.mc.SimulationParams","title":"SimulationParams  <code>dataclass</code>","text":"<pre><code>SimulationParams(temperature: float, pressure: float, flow_rate: float, sim_time: float)\n</code></pre> <p>Parameters for a single Monte Carlo simulation</p>"},{"location":"reference/process_manager/workflow/mc/#process_manager.workflow.mc.run_monte_carlo_study","title":"run_monte_carlo_study  <code>async</code>","text":"<pre><code>run_monte_carlo_study(output_dir: Path, mid_executable: Path, num_simulations: int) -&gt; DataFrame\n</code></pre> <p>Run complete Monte Carlo study workflow</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>Path</code> <p>Directory for all output files</p> required <code>mid_executable</code> <code>Path</code> <p>Path to MID solver executable</p> required <code>num_simulations</code> <code>int</code> <p>Number of Monte Carlo simulations to run</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with analysis results</p> Source code in <code>src/process_manager/workflow/mc.py</code> <pre><code>async def run_monte_carlo_study(\n    output_dir: Path,\n    mid_executable: Path,\n    num_simulations: int\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Run complete Monte Carlo study workflow\n\n    Args:\n        output_dir: Directory for all output files\n        mid_executable: Path to MID solver executable\n        num_simulations: Number of Monte Carlo simulations to run\n\n    Returns:\n        DataFrame with analysis results\n    \"\"\"\n    # Create output directory\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create processes\n    input_gen = InputGenerator(output_dir, num_simulations)\n    solver = MIDSolver(mid_executable)\n    analyzer = ResultsAnalyzer(output_dir)\n\n    # Create workflow nodes\n    input_node = WorkflowNode(\n        process=input_gen,\n        dependencies=[]  # No dependencies\n    )\n\n    solver_node = WorkflowNode(\n        process=solver,\n        dependencies=[input_gen.config.process_id]\n    )\n\n    analyzer_node = WorkflowNode(\n        process=analyzer,\n        dependencies=[solver.config.process_id]\n    )\n\n    # Create and run workflow\n    async with Workflow(\n        max_processes=4,  # Adjust based on your system\n        max_threads=2\n    ) as workflow:\n        # Add nodes\n        workflow.add_node(input_node)\n        workflow.add_node(solver_node)\n        workflow.add_node(analyzer_node)\n\n        # Execute workflow\n        results = await workflow.execute()\n\n        # Return analysis results\n        return results[analyzer.config.process_id].data\n</code></pre>"},{"location":"reference/process_manager/workflow/process/","title":"process","text":""},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process","title":"process","text":"<p>Base process implementation.</p>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess","title":"BaseProcess","text":"<pre><code>BaseProcess(config: ProcessConfig)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all process implementations.</p> <p>The BaseProcess class provides a framework for implementing custom processes that can be executed in different contexts (async, threaded, or multiprocess). It handles common functionality like execution tracking, error handling, and workflow integration.</p> Key Features <ul> <li>Flexible execution strategies (async, thread, process)</li> <li>Built-in timeout handling</li> <li>Automatic execution time tracking</li> <li>Process state management</li> <li>Error handling and reporting</li> </ul> <p>Attributes:</p> Name Type Description <code>config</code> <code>ProcessConfig</code> <p>Configuration settings for the process</p> <code>metadata</code> <code>ProcessMetadata</code> <p>Runtime metadata and state tracking</p> <code>_workflow</code> <code>Optional[Workflow]</code> <p>Reference to parent workflow</p> Example <pre><code>class MyProcess(BaseProcess):\n    def __init__(self):\n        super().__init__(ProcessConfig(\n            process_type=ProcessType.THREAD,\n            process_id=\"my_process\"\n        ))\n\n    async def execute(self, input_data: dict) -&gt; dict:\n        # Implement process logic here\n        return processed_data\n</code></pre> <p>Initialize the process with configuration settings.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ProcessConfig</code> <p>Process configuration including: - process_type: Execution strategy (ASYNC, THREAD, PROCESS) - process_id: Unique identifier for the process - timeout: Optional timeout duration in seconds</p> required Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def __init__(self, config: ProcessConfig):\n    \"\"\"Initialize the process with configuration settings.\n\n    Args:\n        config (ProcessConfig): Process configuration including:\n            - process_type: Execution strategy (ASYNC, THREAD, PROCESS)\n            - process_id: Unique identifier for the process\n            - timeout: Optional timeout duration in seconds\n    \"\"\"\n    self.config = config\n    self.metadata = ProcessMetadata(\n        process_id=config.process_id,\n        state=ProcessState.WAITING\n    )\n    self._workflow: Optional[Workflow] = None\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(input_data: Any) -&gt; ProcessResult\n</code></pre> <p>Execute the process using the appropriate execution strategy.</p> <p>Uses the parent workflow's pool manager if the process is attached to a workflow, otherwise creates a standalone pool manager for independent execution.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the process</p> required <p>Returns:</p> Type Description <code>ProcessResult</code> <p>ProcessResult containing the execution result and metadata</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>async def execute(self, input_data: Any) -&gt; ProcessResult:\n    \"\"\"\n    Execute the process using the appropriate execution strategy.\n\n    Uses the parent workflow's pool manager if the process is attached to a workflow,\n    otherwise creates a standalone pool manager for independent execution.\n\n    Args:\n        input_data: Input data for the process\n\n    Returns:\n        ProcessResult containing the execution result and metadata\n    \"\"\"\n    try:\n        pool_manager = self._workflow.pool_manager\n        process_id = self._workflow.process_id  # Already unique\n    except AttributeError:\n        # Process is not attached to a workflow, create standalone pool manager\n        pool_manager = WorkflowPoolManager.get_instance()\n        process_id = f\"workflow_{id(self)}\"  # Match workflow's ID format\n        print(f\"Warning: Process {self.config.process_id} is not attached to a workflow. Using standalone pool manager.\")\n\n    try:\n        pools = pool_manager.get_or_create_pools(process_id)\n        match self.config.process_type:\n            case ProcessType.ASYNC:\n                return await self._sync_execute(input_data)\n\n            case ProcessType.THREAD | ProcessType.PROCESS:\n                loop = asyncio.get_running_loop()\n                return await loop.run_in_executor(\n                    pools[self.config.process_type],\n                    self._sync_execute,\n                    input_data\n                )\n\n            case _:\n                raise ValueError(f\"Unknown process type: {self.config.process_type}\")\n    finally:\n        pass\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess.get_process_result","title":"get_process_result  <code>classmethod</code>","text":"<pre><code>get_process_result(input_data: Dict[str, Any], process_id: ProcessId) -&gt; Any\n</code></pre> <p>Helper method to consistently extract data from process results.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Dict[str, Any]</code> <p>Dictionary containing process results</p> required <code>process_id</code> <code>ProcessId</code> <p>ProcessId of the process whose result we want</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The data from the specified process result</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the process result is not found or invalid</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>@classmethod\ndef get_process_result(cls, input_data: Dict[str, Any], process_id: ProcessId) -&gt; Any:\n    \"\"\"\n    Helper method to consistently extract data from process results.\n\n    Args:\n        input_data: Dictionary containing process results\n        process_id: ProcessId of the process whose result we want\n\n    Returns:\n        The data from the specified process result\n\n    Raises:\n        ValueError: If the process result is not found or invalid\n    \"\"\"\n    key = str(process_id)\n    if key not in input_data:\n        raise ValueError(f\"Required process {key} not found in input data\")\n\n    result = input_data[key]\n    if isinstance(result, ProcessResult):\n        if not result.success:\n            raise ValueError(f\"Process {key} did not complete successfully\")\n        return result.data\n    else:\n        raise ValueError(f\"Expected ProcessResult for {key}, got {type(result)}\")\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess.process","title":"process","text":"<pre><code>process(input_data: Any) -&gt; Any\n</code></pre> <p>Main processing logic to be implemented by subclasses.</p> <p>This is the primary method that users should override. It contains just the core processing logic without worrying about execution details.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>The input data to process</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The processed result</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def process(self, input_data: Any) -&gt; Any:\n    \"\"\"\n    Main processing logic to be implemented by subclasses.\n\n    This is the primary method that users should override. It contains\n    just the core processing logic without worrying about execution details.\n\n    Args:\n        input_data: The input data to process\n\n    Returns:\n        The processed result\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement process()\")\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess.register_to","title":"register_to","text":"<pre><code>register_to(\n    workflow: Workflow, dependencies: Optional[List[str | ProcessId]] = None, required: bool = True\n) -&gt; BaseProcess\n</code></pre> <p>Register this process as a WorkflowNode to the given workflow.</p> <p>Parameters:</p> Name Type Description Default <code>workflow</code> <code>Workflow</code> <p>The workflow to register this process to</p> required <code>dependencies</code> <code>Optional[List[str | ProcessId]]</code> <p>Optional list of process IDs that this process depends on</p> <code>None</code> <code>required</code> <code>bool</code> <p>Whether this process is required for workflow completion</p> <code>True</code> <p>Returns:</p> Type Description <code>Self</code> <p>Reference for method chaining</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def register_to(\n    self,\n    workflow: Workflow,\n    dependencies: Optional[List[str|ProcessId]] = None,\n    required: bool = True\n) -&gt; BaseProcess:\n    \"\"\"\n    Register this process as a WorkflowNode to the given workflow.\n\n    Args:\n        workflow (Workflow): The workflow to register this process to\n        dependencies (Optional[List[str|ProcessId]]): Optional list of process IDs that this process depends on\n        required (bool): Whether this process is required for workflow completion\n\n    Returns:\n        (Self): Reference for method chaining\n    \"\"\"\n    workflow.add_node(\n        WorkflowNode(\n            process=self,\n            dependencies=dependencies or [],\n            required=required,\n        )\n    )\n    return self\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess.run","title":"run  <code>async</code>","text":"<pre><code>run(input_data: Any) -&gt; ProcessResult\n</code></pre> <p>Run the process with the configured execution strategy.</p> <p>This method handles: 1. Process state management 2. Execution time tracking 3. Error handling 4. Result packaging</p> <p>The execution strategy is determined by the process_type setting in the configuration (ASYNC, THREAD, or PROCESS).</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the process</p> required <p>Returns:</p> Name Type Description <code>ProcessResult</code> <code>ProcessResult</code> <p>Object containing: - success: Whether execution completed successfully - data: Process output data - execution_time: Time taken in seconds - start_time: Execution start timestamp - end_time: Execution end timestamp - error: Error information if execution failed</p> <p>Raises:</p> Type Description <code>ProcessError</code> <p>If execution fails for any reason</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>async def run(self, input_data: Any) -&gt; ProcessResult:\n    \"\"\"Run the process with the configured execution strategy.\n\n    This method handles:\n    1. Process state management\n    2. Execution time tracking\n    3. Error handling\n    4. Result packaging\n\n    The execution strategy is determined by the process_type setting\n    in the configuration (ASYNC, THREAD, or PROCESS).\n\n    Args:\n        input_data (Any): Input data for the process\n\n    Returns:\n        ProcessResult: Object containing:\n            - success: Whether execution completed successfully\n            - data: Process output data\n            - execution_time: Time taken in seconds\n            - start_time: Execution start timestamp\n            - end_time: Execution end timestamp\n            - error: Error information if execution failed\n\n    Raises:\n        ProcessError: If execution fails for any reason\n    \"\"\"\n    self.metadata.state = ProcessState.RUNNING\n    start_time = datetime.now()\n\n    try:\n        # Choose execution strategy based on process type\n        if self.config.process_type == ProcessType.ASYNC:\n            result = await self._run_async(input_data)\n        elif self.config.process_type == ProcessType.THREAD:\n            result = await self._run_threaded(input_data)\n        else:  # ProcessType.PROCESS\n            result = await self._run_multiprocess(input_data)\n\n        end_time = datetime.now()\n        execution_time = (end_time - start_time).total_seconds()\n\n        process_result = ProcessResult(\n            success=True,\n            data=result,\n            execution_time=execution_time,\n            start_time=start_time,\n            end_time=end_time\n        )\n\n        self.metadata.state = ProcessState.COMPLETED\n        return process_result\n\n    except Exception as e:\n        end_time = datetime.now()\n        execution_time = (end_time - start_time).total_seconds()\n\n        process_result = ProcessResult(\n            success=False,\n            data=None,\n            execution_time=execution_time,\n            start_time=start_time,\n            end_time=end_time,\n            error=str(e),\n            error_type=type(e).__name__\n        )\n\n        self.metadata.state = ProcessState.FAILED\n        return process_result\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.BaseProcess.set_workflow","title":"set_workflow","text":"<pre><code>set_workflow(workflow: Workflow) -&gt; None\n</code></pre> <p>Set reference to parent workflow for resource access.</p> <p>This method is called by the workflow when the process is added. The workflow reference provides access to shared resources like thread and process pools.</p> <p>Parameters:</p> Name Type Description Default <code>workflow</code> <code>Workflow</code> <p>Parent workflow instance</p> required Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def set_workflow(self, workflow: Workflow) -&gt; None:\n    \"\"\"Set reference to parent workflow for resource access.\n\n    This method is called by the workflow when the process is added.\n    The workflow reference provides access to shared resources like\n    thread and process pools.\n\n    Args:\n        workflow (Workflow): Parent workflow instance\n    \"\"\"\n    self._workflow = workflow\n</code></pre>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.ProcessId","title":"ProcessId","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Structured process identifier.</p>"},{"location":"reference/process_manager/workflow/process/#process_manager.workflow.process.ProcessId.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Convert to string format used in workflow.</p> Source code in <code>src/process_manager/workflow/process.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Convert to string format used in workflow.\"\"\"\n    if self.index is not None:\n        return f\"{self.base_name}_{self.index}\"\n    return self.base_name\n</code></pre>"},{"location":"reference/process_manager/workflow/workflow_types/","title":"workflow_types","text":""},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types","title":"workflow_types","text":"<p>Common type definitions for workflow system.</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessConfig","title":"ProcessConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration settings for a process.</p> <p>Defines how a process should be executed and handled.</p> <p>Attributes:</p> Name Type Description <code>process_type</code> <code>ProcessType</code> <p>Type of execution (async, thread, process)</p> <code>process_id</code> <code>str</code> <p>Unique identifier for the process</p> <code>timeout</code> <code>Optional[float]</code> <p>Maximum execution time in seconds</p> <code>retry_strategy</code> <code>Optional[RetryStrategy]</code> <p>Configuration for retry behavior</p> <code>fail_fast</code> <code>bool</code> <p>Whether to stop workflow on failure</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessMetadata","title":"ProcessMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Runtime metadata for a process.</p> <p>Tracks the current state, progress, and execution history of a process.</p> <p>Attributes:</p> Name Type Description <code>process_id</code> <code>str</code> <p>Unique identifier for the process</p> <code>state</code> <code>ProcessState</code> <p>Current execution state</p> <code>retries</code> <code>int</code> <p>Number of retry attempts made</p> <code>retry_count</code> <code>int</code> <p>Alias for retries</p> <code>progress</code> <code>float</code> <p>Completion percentage (0-100)</p> <code>start_time</code> <code>Optional[datetime]</code> <p>When execution started</p> <code>end_time</code> <code>Optional[datetime]</code> <p>When execution finished</p> <code>last_error</code> <code>Optional[str]</code> <p>Most recent error message</p> <code>result</code> <code>Optional[ProcessResult]</code> <p>Latest execution result</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessMetadata.retry_count","title":"retry_count  <code>property</code>","text":"<pre><code>retry_count: int\n</code></pre> <p>Alias for retries count.</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessResult","title":"ProcessResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a process execution.</p> <p>Contains all information about a process execution attempt including timing, success/failure status, and any output data or errors.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>Whether execution completed successfully</p> <code>data</code> <code>Any</code> <p>Output data from the process</p> <code>execution_time</code> <code>float</code> <p>Time taken in seconds</p> <code>start_time</code> <code>datetime</code> <p>When execution started</p> <code>end_time</code> <code>datetime</code> <p>When execution finished</p> <code>error</code> <code>Optional[str]</code> <p>Error message if execution failed</p> <code>error_type</code> <code>Optional[str]</code> <p>Type of error that occurred</p> <code>error_message</code> <code>Optional[str]</code> <p>Formatted error message</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessResult.error_message","title":"error_message  <code>property</code>","text":"<pre><code>error_message: Optional[str]\n</code></pre> <p>Formatted error message combining type and description.</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessResult.model_dump","title":"model_dump","text":"<pre><code>model_dump(*args, **kwargs) -&gt; Dict[str, Any]\n</code></pre> <p>Convert result to dictionary format.</p> <p>Overrides pydantic's dict() to handle datetime serialization.</p> Source code in <code>src/process_manager/workflow/workflow_types.py</code> <pre><code>def model_dump(self, *args, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"Convert result to dictionary format.\n\n    Overrides pydantic's dict() to handle datetime serialization.\n    \"\"\"\n    base_dict = super().model_dump(*args, **kwargs)\n    # Convert datetime objects to ISO format strings\n    base_dict['start_time'] = self.start_time.isoformat()\n    base_dict['end_time'] = self.end_time.isoformat()\n    return base_dict\n</code></pre>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessState","title":"ProcessState","text":"<p>               Bases: <code>Enum</code></p> <p>States a process can be in during execution.</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.ProcessType","title":"ProcessType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of process execution strategies.</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.RetryStrategy","title":"RetryStrategy","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for process retry behavior.</p>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.WorkflowNode","title":"WorkflowNode","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a node in the workflow graph.</p> <p>A WorkflowNode encapsulates a process and its dependency information within a workflow. It tracks both the process itself and any other processes that must complete before this node can execute.</p> <p>Attributes:</p> Name Type Description <code>process</code> <code>BaseProcess</code> <p>The process to execute at this node</p> <code>dependencies</code> <code>List[str]</code> <p>Process IDs that must complete before this node</p> <code>required</code> <code>bool</code> <p>Whether this node must complete for workflow success</p> Example <pre><code>node = WorkflowNode(\n    process=MyProcess(),\n    dependencies=[\"process1\", \"process2\"],\n    required=True\n)\n</code></pre>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.WorkflowNode.can_execute","title":"can_execute","text":"<pre><code>can_execute(completed_nodes: List[str]) -&gt; bool\n</code></pre> <p>Check if this node is ready to execute.</p> <p>A node can execute when all its dependencies have completed.</p> <p>Parameters:</p> Name Type Description Default <code>completed_nodes</code> <code>List[str]</code> <p>Process IDs that have completed</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if all dependencies are satisfied</p> Example <pre><code>if node.can_execute([\"process1\", \"process2\"]):\n    await node.process.run(input_data)\n</code></pre> Source code in <code>src/process_manager/workflow/workflow_types.py</code> <pre><code>def can_execute(self, completed_nodes: List[str]) -&gt; bool:\n    \"\"\"Check if this node is ready to execute.\n\n    A node can execute when all its dependencies have completed.\n\n    Args:\n        completed_nodes (List[str]): Process IDs that have completed\n\n    Returns:\n        bool: True if all dependencies are satisfied\n\n    Example:\n        ```python\n        if node.can_execute([\"process1\", \"process2\"]):\n            await node.process.run(input_data)\n        ```\n    \"\"\"\n    return all(\n        dep in completed_nodes \n        for dep in self.dependencies\n    )\n</code></pre>"},{"location":"reference/process_manager/workflow/workflow_types/#process_manager.workflow.workflow_types.WorkflowNode.validate_dependencies","title":"validate_dependencies","text":"<pre><code>validate_dependencies(available_nodes: List[str]) -&gt; List[str]\n</code></pre> <p>Validate that all dependencies exist in the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>available_nodes</code> <code>List[str]</code> <p>List of all process IDs in the workflow</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of any missing dependencies</p> Example <pre><code>missing = node.validate_dependencies([\"process1\", \"process2\"])\nif missing:\n    print(f\"Missing dependencies: {missing}\")\n</code></pre> Source code in <code>src/process_manager/workflow/workflow_types.py</code> <pre><code>def validate_dependencies(self, available_nodes: List[str]) -&gt; List[str]:\n    \"\"\"Validate that all dependencies exist in the workflow.\n\n    Args:\n        available_nodes (List[str]): List of all process IDs in the workflow\n\n    Returns:\n        List[str]: List of any missing dependencies\n\n    Example:\n        ```python\n        missing = node.validate_dependencies([\"process1\", \"process2\"])\n        if missing:\n            print(f\"Missing dependencies: {missing}\")\n        ```\n    \"\"\"\n    return [\n        dep for dep in self.dependencies \n        if dep not in available_nodes\n    ]\n</code></pre>"},{"location":"reference/results_manager/","title":"results_manager","text":""},{"location":"reference/results_manager/#results_manager","title":"results_manager","text":""},{"location":"reference/results_manager/#results_manager.AsyncFileBackend","title":"AsyncFileBackend","text":"<pre><code>AsyncFileBackend(\n    base_dir: Union[str, Path],\n    create_if_missing: bool = True,\n    locks_dir: Optional[Union[str, Path]] = None,\n)\n</code></pre> <p>               Bases: <code>AsyncResultsBackend[T]</code></p> <p>Async wrapper for FileBackend.</p> <p>Runs the synchronous FileBackend methods in a threadpool to avoid blocking the event loop.</p> <p>Initialize the AsyncFileBackend.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory to store results</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>locks_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory to store lock files. If None, uses a system temp directory.</p> <code>None</code> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>def __init__(self, base_dir: Union[str, Path], create_if_missing: bool = True, locks_dir: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize the AsyncFileBackend.\n\n    Args:\n        base_dir: Base directory to store results\n        create_if_missing: Whether to create the directory if it doesn't exist\n        locks_dir: Directory to store lock files. If None, uses a system temp directory.\n    \"\"\"\n    # Create the synchronous backend\n    self._backend = FileBackend(base_dir, create_if_missing, locks_dir)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncFileBackend.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    await asyncio.to_thread(\n        self._backend.clear\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncFileBackend.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.delete,\n        result_id=result_id\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncFileBackend.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.exists,\n        result_id=result_id\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncFileBackend.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.get,\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncFileBackend.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.list_ids,\n        prefix=prefix\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncFileBackend.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.set,\n        result_id=result_id,\n        data=data,\n        behavior=behavior,\n        namespace=namespace,\n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend","title":"AsyncResultsBackend","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Abstract base class for async results storage backends.</p> <p>Implementations should provide asynchronous storage and retrieval of Pydantic models.</p>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend.clear","title":"clear  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend.exists","title":"exists  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend.get","title":"get  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend.list_ids","title":"list_ids  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsBackend.set","title":"set  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager","title":"AsyncResultsManager","text":"<pre><code>AsyncResultsManager(\n    base_dir: Union[str, Path] = None,\n    create_if_missing: bool = True,\n    backend: Optional[AsyncResultsBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Async version of ResultsManager for managing results from parallel processes.</p> <p>Provides an asynchronous interface for storing and retrieving pydantic models.</p> <p>Initialize the AsyncResultsManager.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory for file storage (used only if backend is None)</p> <code>None</code> <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>backend</code> <code>Optional[AsyncResultsBackend]</code> <p>Optional custom async backend to use. If None, uses AsyncFileBackend.</p> <code>None</code> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>def __init__(self, \n             base_dir: Union[str, Path] = None, \n             create_if_missing: bool = True, \n             backend: Optional[AsyncResultsBackend] = None):\n    \"\"\"\n    Initialize the AsyncResultsManager.\n\n    Args:\n        base_dir: Base directory for file storage (used only if backend is None)\n        create_if_missing: Whether to create the directory if it doesn't exist\n        backend: Optional custom async backend to use. If None, uses AsyncFileBackend.\n    \"\"\"\n    if backend is None:\n        if base_dir is None:\n            raise ValueError(\"Must provide either base_dir or backend\")\n        self.backend = AsyncFileBackend(base_dir, create_if_missing)\n    else:\n        self.backend = backend\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    await self.backend.clear()\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return await self.backend.delete(result_id)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return await self.backend.exists(result_id)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    return await self.backend.get(\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return await self.backend.list_ids(prefix)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.AsyncResultsManager.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    return await self.backend.set(\n        result_id=result_id, \n        data=data, \n        behavior=behavior, \n        namespace=namespace, \n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend","title":"FileBackend","text":"<pre><code>FileBackend(\n    base_dir: Union[str, Path],\n    create_if_missing: bool = True,\n    locks_dir: Optional[Union[str, Path]] = None,\n)\n</code></pre> <p>               Bases: <code>ResultsBackend[T]</code></p> <p>File-based implementation of ResultsBackend.</p> <p>Stores results as JSON files in a hierarchical directory structure.</p> <p>Initialize the FileBackend.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory to store results</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>locks_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory to store lock files. If None, uses a system temp directory.</p> <code>None</code> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def __init__(self, base_dir: Union[str, Path], create_if_missing: bool = True, locks_dir: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize the FileBackend.\n\n    Args:\n        base_dir: Base directory to store results\n        create_if_missing: Whether to create the directory if it doesn't exist\n        locks_dir: Directory to store lock files. If None, uses a system temp directory.\n    \"\"\"\n    self.base_dir = Path(base_dir)\n\n    if create_if_missing and not self.base_dir.exists():\n        self.base_dir.mkdir(parents=True)\n    elif not self.base_dir.exists():\n        raise FileNotFoundError(f\"Base directory {self.base_dir} does not exist\")\n\n    # Set up locks directory\n    if locks_dir is None:\n        self.locks_dir = Path(tempfile.gettempdir()) / \"results_manager_locks\"\n    else:\n        self.locks_dir = Path(locks_dir)\n\n    # Create locks directory if it doesn't exist\n    if not self.locks_dir.exists():\n        self.locks_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    # For clear(), we'll use a more aggressive approach of deleting then recreating\n    # the directory, which avoids having to lock individual files\n    if self.base_dir.exists():\n        # Create a temporary lock file for the entire directory\n        lock_path = self.locks_dir / \"clear_all.lock\"\n        with FileLock(lock_path):\n            # Save the path\n            path = self.base_dir\n            # Delete everything\n            shutil.rmtree(str(self.base_dir))\n            # Recreate the directory\n            self.base_dir.mkdir(parents=True)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend.delete","title":"delete","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure thread/process safety\n    with FileLock(lock_path):\n        if not file_path.exists():\n            return False\n\n        file_path.unlink()\n\n        # Try to clean up empty directories\n        current_dir = file_path.parent\n        while current_dir != self.base_dir:\n            if not any(current_dir.iterdir()):\n                current_dir.rmdir()\n                current_dir = current_dir.parent\n            else:\n                break\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend.exists","title":"exists","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure consistent state\n    with FileLock(lock_path):\n        return file_path.exists()\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend.get","title":"get","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against. If not provided,          the stored model type will be used.</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace override to look for the model in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> <code>ValidationError</code> <p>If the data doesn't match the model schema</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against. If not provided,\n                     the stored model type will be used.\n        namespace: Optional namespace override to look for the model in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n        ValidationError: If the data doesn't match the model schema\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure thread/process safety\n    with FileLock(lock_path):\n        if not file_path.exists():\n            raise FileNotFoundError(f\"No result found for ID: {result_id}\")\n\n        with open(file_path, 'r') as f:\n            stored_data = json.load(f)\n\n        # Check for missing model_type even when model_class is provided\n        model_type_name = stored_data.get(\"model_type\")\n        if not model_type_name:\n            raise ValueError(f\"Stored data missing model type information\")\n\n        # If no model class is provided, try to find it from the registry\n        if not model_class:\n            # Use the stored namespace if none provided\n            stored_namespace = stored_data.get(\"namespace\", DEFAULT_NAMESPACE)\n            lookup_namespace = namespace if namespace is not None else stored_namespace\n\n            model_class = get_model_class(model_type_name, namespace=lookup_namespace)\n\n            # If not found in the specified namespace, try alternatives\n            # Continue from where we left off:\n\n        # If not found in the specified namespace, try alternatives\n        if not model_class:\n            # Try finding in all namespaces\n            model_matches = find_model_in_all_namespaces(model_type_name)\n            if model_matches:\n                # Use the first match\n                first_namespace, model_class = model_matches[0]\n            else:\n                namespaces_tried = [lookup_namespace]\n                if lookup_namespace != DEFAULT_NAMESPACE:\n                    namespaces_tried.append(DEFAULT_NAMESPACE)\n\n                raise ValueError(\n                    f\"Model type '{model_type_name}' is not registered in \"\n                    f\"namespace '{lookup_namespace}' or any other namespace. \"\n                    f\"Tried namespaces: {', '.join(namespaces_tried)}\"\n                )\n\n        # Get the data to validate outside the lock\n        data = stored_data[\"data\"]\n\n    # Validate outside the lock to minimize lock time\n    return model_class.model_validate(data)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend.list_ids","title":"list_ids","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    if prefix is None:\n        base_path = self.base_dir\n    else:\n        if isinstance(prefix, str):\n            prefix = prefix.split('/')\n        base_path = self.base_dir.joinpath(*prefix)\n\n    if not base_path.exists():\n        return []\n\n    result_ids = []\n    # No need for locking as we're just reading directory structure\n    for path in base_path.rglob(\"*.json\"):\n        # Convert path to relative path from base_dir\n        rel_path = path.relative_to(self.base_dir)\n        # Remove .json extension and convert to string\n        result_id = str(rel_path.with_suffix(''))\n        result_ids.append(result_id)\n\n    return result_ids\n</code></pre>"},{"location":"reference/results_manager/#results_manager.FileBackend.set","title":"set","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock with a timeout to avoid deadlocks\n    with FileLock(lock_path, timeout=10):  # 10 second timeout\n        # Handle existing data according to behavior\n        if file_path.exists():\n            if behavior == SetBehavior.RAISE_IF_EXISTS:\n                raise FileExistsError(f\"Data already exists for ID: {result_id}\")\n\n            elif behavior == SetBehavior.SKIP_IF_EXISTS:\n                try:\n                    # Simplified logic for SKIP_IF_EXISTS\n                    with open(file_path, 'r') as f:\n                        stored_data = json.load(f)\n\n                    # Compare model types\n                    if stored_data.get(\"model_type\") == data.__class__.__name__:\n                        # Direct comparison of dumped data\n                        if stored_data.get(\"data\") == data.model_dump():\n                            return False  # Skip if exactly the same\n                except (json.JSONDecodeError, KeyError, FileNotFoundError):\n                    # If any error occurs during comparison, default to overwriting\n                    pass\n\n            elif behavior == SetBehavior.RAISE_IF_DIFFERENT:\n                try:\n                    # Load existing data for comparison\n                    with open(file_path, 'r') as f:\n                        stored_data = json.load(f)\n\n                    # Compare model types\n                    if stored_data.get(\"model_type\") == data.__class__.__name__:\n                        # Direct comparison of dumped data\n                        if stored_data.get(\"data\") != data.model_dump():\n                            raise FileExistsError(f\"Different data already exists for ID: {result_id}\")\n                except (json.JSONDecodeError, KeyError, FileNotFoundError):\n                    # If we can't load the file properly, treat as different\n                    raise FileExistsError(f\"Invalid data exists for ID: {result_id}\")\n\n        # Determine the namespace to use\n        if namespace is None:\n            # Try to find the namespace from the model class\n            try:\n                model_namespace = find_model_namespace(data.__class__, strict=strict_namespace)\n                if model_namespace is not None:\n                    namespace = model_namespace\n                else:\n                    namespace = DEFAULT_NAMESPACE\n            except ValueError as e:\n                # Re-raise the error about multiple namespaces\n                raise ValueError(\n                    f\"Cannot automatically determine namespace for {data.__class__.__name__} \"\n                    f\"when saving to '{result_id}': {str(e)}\"\n                ) from e\n\n        # Ensure the directory exists\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Store the model type and namespace along with the data\n        serialized_data = {\n            \"model_type\": data.__class__.__name__,\n            \"namespace\": namespace,\n            \"data\": data.model_dump()\n        }\n\n        # Use atomic write pattern for extra safety\n        temp_file = file_path.with_suffix('.tmp')\n        with open(temp_file, 'w') as f:\n            json.dump(serialized_data, f, indent=2)\n\n        # Rename is atomic on most filesystems\n        temp_file.replace(file_path)\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsBackend","title":"ResultsBackend","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Abstract base class for results storage backends.</p> <p>Implementations should provide storage and retrieval of Pydantic models based on unique IDs.</p>"},{"location":"reference/results_manager/#results_manager.ResultsBackend.clear","title":"clear  <code>abstractmethod</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsBackend.delete","title":"delete  <code>abstractmethod</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsBackend.exists","title":"exists  <code>abstractmethod</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsBackend.get","title":"get  <code>abstractmethod</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsBackend.list_ids","title":"list_ids  <code>abstractmethod</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsBackend.set","title":"set  <code>abstractmethod</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager","title":"ResultsManager","text":"<pre><code>ResultsManager(\n    base_dir: Union[str, Path] = None,\n    create_if_missing: bool = True,\n    backend: Optional[ResultsBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Manages results from parallel processes, storing and retrieving pydantic models.</p> <p>This class provides a unified interface to different storage backends.</p> <p>Initialize the ResultsManager.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory for file storage (used only if backend is None)</p> <code>None</code> <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>backend</code> <code>Optional[ResultsBackend]</code> <p>Optional custom backend to use. If None, uses FileBackend.</p> <code>None</code> Source code in <code>src/results_manager/manager.py</code> <pre><code>def __init__(self, \n             base_dir: Union[str, Path] = None, \n             create_if_missing: bool = True, \n             backend: Optional[ResultsBackend] = None):\n    \"\"\"\n    Initialize the ResultsManager.\n\n    Args:\n        base_dir: Base directory for file storage (used only if backend is None)\n        create_if_missing: Whether to create the directory if it doesn't exist\n        backend: Optional custom backend to use. If None, uses FileBackend.\n    \"\"\"\n    if backend is None:\n        if base_dir is None:\n            raise ValueError(\"Must provide either base_dir or backend\")\n        self.backend = FileBackend(base_dir, create_if_missing)\n    else:\n        self.backend = backend\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    self.backend.clear()\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager.delete","title":"delete","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return self.backend.delete(result_id)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager.exists","title":"exists","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return self.backend.exists(result_id)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager.get","title":"get","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against. If not provided,          the stored model type will be used.</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace override to look for the model in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> <code>ValidationError</code> <p>If the data doesn't match the model schema</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against. If not provided,\n                     the stored model type will be used.\n        namespace: Optional namespace override to look for the model in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n        ValidationError: If the data doesn't match the model schema\n    \"\"\"\n    return self.backend.get(\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager.list_ids","title":"list_ids","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return self.backend.list_ids(prefix)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.ResultsManager.set","title":"set","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in. If None, will try to       determine the namespace from the model class automatically.</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if the model is registered               in multiple non-default namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped (only for SKIP_IF_EXISTS)</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in. If None, will try to\n                  determine the namespace from the model class automatically.\n        strict_namespace: If True, raises an error if the model is registered \n                         in multiple non-default namespaces\n\n    Returns:\n        True if data was written, False if skipped (only for SKIP_IF_EXISTS)\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    return self.backend.set(\n        result_id=result_id, \n        data=data, \n        behavior=behavior, \n        namespace=namespace, \n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/#results_manager.SetBehavior","title":"SetBehavior","text":"<p>               Bases: <code>Enum</code></p> <p>Defines behavior when setting data for an ID that already exists.</p>"},{"location":"reference/results_manager/#results_manager.clear_registry","title":"clear_registry","text":"<pre><code>clear_registry(namespace: Optional[str] = None)\n</code></pre> <p>Clear the model registry, optionally only for a specific namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Optional[str]</code> <p>If provided, only clear this namespace. Otherwise, clear all.</p> <code>None</code> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def clear_registry(namespace: Optional[str] = None):\n    \"\"\"\n    Clear the model registry, optionally only for a specific namespace.\n\n    Args:\n        namespace: If provided, only clear this namespace. Otherwise, clear all.\n    \"\"\"\n    if namespace is None:\n        _MODEL_REGISTRY.clear()\n    elif namespace in _MODEL_REGISTRY:\n        _MODEL_REGISTRY[namespace].clear()\n</code></pre>"},{"location":"reference/results_manager/#results_manager.find_model_in_all_namespaces","title":"find_model_in_all_namespaces","text":"<pre><code>find_model_in_all_namespaces(model_name: str) -&gt; List[Tuple[str, Type[BaseModel]]]\n</code></pre> <p>Find a model by name in all namespaces.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model class</p> required <p>Returns:</p> Type Description <code>List[Tuple[str, Type[BaseModel]]]</code> <p>List of (namespace, model_class) tuples for all matches</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def find_model_in_all_namespaces(model_name: str) -&gt; List[Tuple[str, Type[BaseModel]]]:\n    \"\"\"\n    Find a model by name in all namespaces.\n\n    Args:\n        model_name: The name of the model class\n\n    Returns:\n        List of (namespace, model_class) tuples for all matches\n    \"\"\"\n    results = []\n    for namespace, models in _MODEL_REGISTRY.items():\n        if model_name in models:\n            results.append((namespace, models[model_name]))\n    return results\n</code></pre>"},{"location":"reference/results_manager/#results_manager.find_model_namespace","title":"find_model_namespace","text":"<pre><code>find_model_namespace(model_class: Type[BaseModel], strict: bool = False) -&gt; Optional[str]\n</code></pre> <p>Find the namespace for a model class.</p> <p>If the model is registered in multiple namespaces, behavior depends on the 'strict' parameter: - If strict=False (default): Prioritizes non-default namespaces, returns the first one found - If strict=True: Raises ValueError if found in multiple non-default namespaces</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>Type[BaseModel]</code> <p>The model class to find the namespace for</p> required <code>strict</code> <code>bool</code> <p>Whether to raise an error if the model is in multiple non-default namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The namespace name if found, None otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If strict=True and the model is registered in multiple non-default namespaces</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def find_model_namespace(model_class: Type[BaseModel], strict: bool = False) -&gt; Optional[str]:\n    \"\"\"\n    Find the namespace for a model class.\n\n    If the model is registered in multiple namespaces, behavior depends on the 'strict' parameter:\n    - If strict=False (default): Prioritizes non-default namespaces, returns the first one found\n    - If strict=True: Raises ValueError if found in multiple non-default namespaces\n\n    Args:\n        model_class: The model class to find the namespace for\n        strict: Whether to raise an error if the model is in multiple non-default namespaces\n\n    Returns:\n        The namespace name if found, None otherwise\n\n    Raises:\n        ValueError: If strict=True and the model is registered in multiple non-default namespaces\n    \"\"\"\n    model_name = model_class.__name__\n    found_namespaces = []\n\n    # Find all namespaces containing this model class\n    for namespace, models in _MODEL_REGISTRY.items():\n        if model_name in models and models[model_name] is model_class:\n            found_namespaces.append(namespace)\n\n    if not found_namespaces:\n        return None\n\n    # Filter to just non-default namespaces\n    non_default_namespaces = [ns for ns in found_namespaces if ns != DEFAULT_NAMESPACE]\n\n    # If strict mode and multiple non-default namespaces, raise error\n    if strict and len(non_default_namespaces) &gt; 1:\n        raise ValueError(\n            f\"Model '{model_name}' is registered in multiple non-default namespaces: \"\n            f\"{', '.join(non_default_namespaces)}. Specify a namespace explicitly.\"\n        )\n\n    # Prioritize: first non-default namespace, or default namespace\n    if non_default_namespaces:\n        return non_default_namespaces[0]\n    elif DEFAULT_NAMESPACE in found_namespaces:\n        return DEFAULT_NAMESPACE\n    else:\n        return None  # Should not reach here, but just in case\n</code></pre>"},{"location":"reference/results_manager/#results_manager.get_model_class","title":"get_model_class","text":"<pre><code>get_model_class(model_name: str, namespace: str = DEFAULT_NAMESPACE) -&gt; Optional[Type[BaseModel]]\n</code></pre> <p>Retrieve a model class from the registry by name and namespace.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model class</p> required <code>namespace</code> <code>str</code> <p>The namespace to look in</p> <code>DEFAULT_NAMESPACE</code> <p>Returns:</p> Type Description <code>Optional[Type[BaseModel]]</code> <p>The model class if found, None otherwise</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def get_model_class(model_name: str, namespace: str = DEFAULT_NAMESPACE) -&gt; Optional[Type[BaseModel]]:\n    \"\"\"\n    Retrieve a model class from the registry by name and namespace.\n\n    Args:\n        model_name: The name of the model class\n        namespace: The namespace to look in\n\n    Returns:\n        The model class if found, None otherwise\n    \"\"\"\n    namespace_registry = _MODEL_REGISTRY.get(namespace, {})\n    return namespace_registry.get(model_name)\n</code></pre>"},{"location":"reference/results_manager/#results_manager.get_models_in_namespace","title":"get_models_in_namespace","text":"<pre><code>get_models_in_namespace(namespace: str = DEFAULT_NAMESPACE) -&gt; List[str]\n</code></pre> <p>Get a list of all model names in a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>The namespace to get models from</p> <code>DEFAULT_NAMESPACE</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of model names</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def get_models_in_namespace(namespace: str = DEFAULT_NAMESPACE) -&gt; List[str]:\n    \"\"\"\n    Get a list of all model names in a namespace.\n\n    Args:\n        namespace: The namespace to get models from\n\n    Returns:\n        List of model names\n    \"\"\"\n    return list(_MODEL_REGISTRY.get(namespace, {}).keys())\n</code></pre>"},{"location":"reference/results_manager/#results_manager.get_namespaces","title":"get_namespaces","text":"<pre><code>get_namespaces() -&gt; List[str]\n</code></pre> <p>Get a list of all registered namespaces.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of namespace names</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def get_namespaces() -&gt; List[str]:\n    \"\"\"\n    Get a list of all registered namespaces.\n\n    Returns:\n        List of namespace names\n    \"\"\"\n    return list(_MODEL_REGISTRY.keys())\n</code></pre>"},{"location":"reference/results_manager/#results_manager.register_model","title":"register_model","text":"<pre><code>register_model(model_class_or_namespace: Any = None, *, namespace: str = DEFAULT_NAMESPACE)\n</code></pre> <p>Register a pydantic model class in the registry.</p> <p>Can be used as a decorator with or without arguments:</p> <p>@register_model class MyModel(BaseModel):     ...</p> <p>@register_model(namespace=\"custom\") class MyModel(BaseModel):     ...</p> <p>Or programmatically: register_model(MyModel, namespace=\"custom\")</p> <p>Parameters:</p> Name Type Description Default <code>model_class_or_namespace</code> <code>Any</code> <p>The model class to register or a namespace string</p> <code>None</code> <code>namespace</code> <code>str</code> <p>The namespace to register the model in (when used programmatically)</p> <code>DEFAULT_NAMESPACE</code> <p>Returns:</p> Type Description <p>The decorator function or the registered model class</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def register_model(model_class_or_namespace: Any = None, *, namespace: str = DEFAULT_NAMESPACE):\n    \"\"\"\n    Register a pydantic model class in the registry.\n\n    Can be used as a decorator with or without arguments:\n\n    @register_model\n    class MyModel(BaseModel):\n        ...\n\n    @register_model(namespace=\"custom\")\n    class MyModel(BaseModel):\n        ...\n\n    Or programmatically:\n    register_model(MyModel, namespace=\"custom\")\n\n    Args:\n        model_class_or_namespace: The model class to register or a namespace string\n        namespace: The namespace to register the model in (when used programmatically)\n\n    Returns:\n        The decorator function or the registered model class\n    \"\"\"\n    # Handle case where register_model is called directly with a model class\n    if isinstance(model_class_or_namespace, type) and issubclass(model_class_or_namespace, BaseModel):\n        return _register_model(model_class_or_namespace, namespace)\n\n    # Handle case where register_model is used as a decorator with or without arguments\n    def decorator(model_class):\n        if not isinstance(model_class, type) or not issubclass(model_class, BaseModel):\n            raise TypeError(\"Registered model must be a subclass of BaseModel\")\n\n        # If model_class_or_namespace is a string, use it as namespace\n        ns = model_class_or_namespace if isinstance(model_class_or_namespace, str) else namespace\n        return _register_model(model_class, ns)\n\n    return decorator\n</code></pre>"},{"location":"reference/results_manager/async_manager/","title":"async_manager","text":""},{"location":"reference/results_manager/async_manager/#results_manager.async_manager","title":"async_manager","text":""},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager","title":"AsyncResultsManager","text":"<pre><code>AsyncResultsManager(\n    base_dir: Union[str, Path] = None,\n    create_if_missing: bool = True,\n    backend: Optional[AsyncResultsBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Async version of ResultsManager for managing results from parallel processes.</p> <p>Provides an asynchronous interface for storing and retrieving pydantic models.</p> <p>Initialize the AsyncResultsManager.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory for file storage (used only if backend is None)</p> <code>None</code> <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>backend</code> <code>Optional[AsyncResultsBackend]</code> <p>Optional custom async backend to use. If None, uses AsyncFileBackend.</p> <code>None</code> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>def __init__(self, \n             base_dir: Union[str, Path] = None, \n             create_if_missing: bool = True, \n             backend: Optional[AsyncResultsBackend] = None):\n    \"\"\"\n    Initialize the AsyncResultsManager.\n\n    Args:\n        base_dir: Base directory for file storage (used only if backend is None)\n        create_if_missing: Whether to create the directory if it doesn't exist\n        backend: Optional custom async backend to use. If None, uses AsyncFileBackend.\n    \"\"\"\n    if backend is None:\n        if base_dir is None:\n            raise ValueError(\"Must provide either base_dir or backend\")\n        self.backend = AsyncFileBackend(base_dir, create_if_missing)\n    else:\n        self.backend = backend\n</code></pre>"},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    await self.backend.clear()\n</code></pre>"},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return await self.backend.delete(result_id)\n</code></pre>"},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return await self.backend.exists(result_id)\n</code></pre>"},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    return await self.backend.get(\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return await self.backend.list_ids(prefix)\n</code></pre>"},{"location":"reference/results_manager/async_manager/#results_manager.async_manager.AsyncResultsManager.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_manager.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    return await self.backend.set(\n        result_id=result_id, \n        data=data, \n        behavior=behavior, \n        namespace=namespace, \n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/manager/","title":"manager","text":""},{"location":"reference/results_manager/manager/#results_manager.manager","title":"manager","text":""},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager","title":"ResultsManager","text":"<pre><code>ResultsManager(\n    base_dir: Union[str, Path] = None,\n    create_if_missing: bool = True,\n    backend: Optional[ResultsBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Manages results from parallel processes, storing and retrieving pydantic models.</p> <p>This class provides a unified interface to different storage backends.</p> <p>Initialize the ResultsManager.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory for file storage (used only if backend is None)</p> <code>None</code> <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>backend</code> <code>Optional[ResultsBackend]</code> <p>Optional custom backend to use. If None, uses FileBackend.</p> <code>None</code> Source code in <code>src/results_manager/manager.py</code> <pre><code>def __init__(self, \n             base_dir: Union[str, Path] = None, \n             create_if_missing: bool = True, \n             backend: Optional[ResultsBackend] = None):\n    \"\"\"\n    Initialize the ResultsManager.\n\n    Args:\n        base_dir: Base directory for file storage (used only if backend is None)\n        create_if_missing: Whether to create the directory if it doesn't exist\n        backend: Optional custom backend to use. If None, uses FileBackend.\n    \"\"\"\n    if backend is None:\n        if base_dir is None:\n            raise ValueError(\"Must provide either base_dir or backend\")\n        self.backend = FileBackend(base_dir, create_if_missing)\n    else:\n        self.backend = backend\n</code></pre>"},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    self.backend.clear()\n</code></pre>"},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager.delete","title":"delete","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return self.backend.delete(result_id)\n</code></pre>"},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager.exists","title":"exists","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return self.backend.exists(result_id)\n</code></pre>"},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager.get","title":"get","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against. If not provided,          the stored model type will be used.</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace override to look for the model in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> <code>ValidationError</code> <p>If the data doesn't match the model schema</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against. If not provided,\n                     the stored model type will be used.\n        namespace: Optional namespace override to look for the model in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n        ValidationError: If the data doesn't match the model schema\n    \"\"\"\n    return self.backend.get(\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager.list_ids","title":"list_ids","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return self.backend.list_ids(prefix)\n</code></pre>"},{"location":"reference/results_manager/manager/#results_manager.manager.ResultsManager.set","title":"set","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in. If None, will try to       determine the namespace from the model class automatically.</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if the model is registered               in multiple non-default namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped (only for SKIP_IF_EXISTS)</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/manager.py</code> <pre><code>def set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in. If None, will try to\n                  determine the namespace from the model class automatically.\n        strict_namespace: If True, raises an error if the model is registered \n                         in multiple non-default namespaces\n\n    Returns:\n        True if data was written, False if skipped (only for SKIP_IF_EXISTS)\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    return self.backend.set(\n        result_id=result_id, \n        data=data, \n        behavior=behavior, \n        namespace=namespace, \n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/model_registry/","title":"model_registry","text":""},{"location":"reference/results_manager/model_registry/#results_manager.model_registry","title":"model_registry","text":""},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.clear_registry","title":"clear_registry","text":"<pre><code>clear_registry(namespace: Optional[str] = None)\n</code></pre> <p>Clear the model registry, optionally only for a specific namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Optional[str]</code> <p>If provided, only clear this namespace. Otherwise, clear all.</p> <code>None</code> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def clear_registry(namespace: Optional[str] = None):\n    \"\"\"\n    Clear the model registry, optionally only for a specific namespace.\n\n    Args:\n        namespace: If provided, only clear this namespace. Otherwise, clear all.\n    \"\"\"\n    if namespace is None:\n        _MODEL_REGISTRY.clear()\n    elif namespace in _MODEL_REGISTRY:\n        _MODEL_REGISTRY[namespace].clear()\n</code></pre>"},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.find_model_in_all_namespaces","title":"find_model_in_all_namespaces","text":"<pre><code>find_model_in_all_namespaces(model_name: str) -&gt; List[Tuple[str, Type[BaseModel]]]\n</code></pre> <p>Find a model by name in all namespaces.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model class</p> required <p>Returns:</p> Type Description <code>List[Tuple[str, Type[BaseModel]]]</code> <p>List of (namespace, model_class) tuples for all matches</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def find_model_in_all_namespaces(model_name: str) -&gt; List[Tuple[str, Type[BaseModel]]]:\n    \"\"\"\n    Find a model by name in all namespaces.\n\n    Args:\n        model_name: The name of the model class\n\n    Returns:\n        List of (namespace, model_class) tuples for all matches\n    \"\"\"\n    results = []\n    for namespace, models in _MODEL_REGISTRY.items():\n        if model_name in models:\n            results.append((namespace, models[model_name]))\n    return results\n</code></pre>"},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.find_model_namespace","title":"find_model_namespace","text":"<pre><code>find_model_namespace(model_class: Type[BaseModel], strict: bool = False) -&gt; Optional[str]\n</code></pre> <p>Find the namespace for a model class.</p> <p>If the model is registered in multiple namespaces, behavior depends on the 'strict' parameter: - If strict=False (default): Prioritizes non-default namespaces, returns the first one found - If strict=True: Raises ValueError if found in multiple non-default namespaces</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>Type[BaseModel]</code> <p>The model class to find the namespace for</p> required <code>strict</code> <code>bool</code> <p>Whether to raise an error if the model is in multiple non-default namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The namespace name if found, None otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If strict=True and the model is registered in multiple non-default namespaces</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def find_model_namespace(model_class: Type[BaseModel], strict: bool = False) -&gt; Optional[str]:\n    \"\"\"\n    Find the namespace for a model class.\n\n    If the model is registered in multiple namespaces, behavior depends on the 'strict' parameter:\n    - If strict=False (default): Prioritizes non-default namespaces, returns the first one found\n    - If strict=True: Raises ValueError if found in multiple non-default namespaces\n\n    Args:\n        model_class: The model class to find the namespace for\n        strict: Whether to raise an error if the model is in multiple non-default namespaces\n\n    Returns:\n        The namespace name if found, None otherwise\n\n    Raises:\n        ValueError: If strict=True and the model is registered in multiple non-default namespaces\n    \"\"\"\n    model_name = model_class.__name__\n    found_namespaces = []\n\n    # Find all namespaces containing this model class\n    for namespace, models in _MODEL_REGISTRY.items():\n        if model_name in models and models[model_name] is model_class:\n            found_namespaces.append(namespace)\n\n    if not found_namespaces:\n        return None\n\n    # Filter to just non-default namespaces\n    non_default_namespaces = [ns for ns in found_namespaces if ns != DEFAULT_NAMESPACE]\n\n    # If strict mode and multiple non-default namespaces, raise error\n    if strict and len(non_default_namespaces) &gt; 1:\n        raise ValueError(\n            f\"Model '{model_name}' is registered in multiple non-default namespaces: \"\n            f\"{', '.join(non_default_namespaces)}. Specify a namespace explicitly.\"\n        )\n\n    # Prioritize: first non-default namespace, or default namespace\n    if non_default_namespaces:\n        return non_default_namespaces[0]\n    elif DEFAULT_NAMESPACE in found_namespaces:\n        return DEFAULT_NAMESPACE\n    else:\n        return None  # Should not reach here, but just in case\n</code></pre>"},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.get_model_class","title":"get_model_class","text":"<pre><code>get_model_class(model_name: str, namespace: str = DEFAULT_NAMESPACE) -&gt; Optional[Type[BaseModel]]\n</code></pre> <p>Retrieve a model class from the registry by name and namespace.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model class</p> required <code>namespace</code> <code>str</code> <p>The namespace to look in</p> <code>DEFAULT_NAMESPACE</code> <p>Returns:</p> Type Description <code>Optional[Type[BaseModel]]</code> <p>The model class if found, None otherwise</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def get_model_class(model_name: str, namespace: str = DEFAULT_NAMESPACE) -&gt; Optional[Type[BaseModel]]:\n    \"\"\"\n    Retrieve a model class from the registry by name and namespace.\n\n    Args:\n        model_name: The name of the model class\n        namespace: The namespace to look in\n\n    Returns:\n        The model class if found, None otherwise\n    \"\"\"\n    namespace_registry = _MODEL_REGISTRY.get(namespace, {})\n    return namespace_registry.get(model_name)\n</code></pre>"},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.get_models_in_namespace","title":"get_models_in_namespace","text":"<pre><code>get_models_in_namespace(namespace: str = DEFAULT_NAMESPACE) -&gt; List[str]\n</code></pre> <p>Get a list of all model names in a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>The namespace to get models from</p> <code>DEFAULT_NAMESPACE</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of model names</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def get_models_in_namespace(namespace: str = DEFAULT_NAMESPACE) -&gt; List[str]:\n    \"\"\"\n    Get a list of all model names in a namespace.\n\n    Args:\n        namespace: The namespace to get models from\n\n    Returns:\n        List of model names\n    \"\"\"\n    return list(_MODEL_REGISTRY.get(namespace, {}).keys())\n</code></pre>"},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.get_namespaces","title":"get_namespaces","text":"<pre><code>get_namespaces() -&gt; List[str]\n</code></pre> <p>Get a list of all registered namespaces.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of namespace names</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def get_namespaces() -&gt; List[str]:\n    \"\"\"\n    Get a list of all registered namespaces.\n\n    Returns:\n        List of namespace names\n    \"\"\"\n    return list(_MODEL_REGISTRY.keys())\n</code></pre>"},{"location":"reference/results_manager/model_registry/#results_manager.model_registry.register_model","title":"register_model","text":"<pre><code>register_model(model_class_or_namespace: Any = None, *, namespace: str = DEFAULT_NAMESPACE)\n</code></pre> <p>Register a pydantic model class in the registry.</p> <p>Can be used as a decorator with or without arguments:</p> <p>@register_model class MyModel(BaseModel):     ...</p> <p>@register_model(namespace=\"custom\") class MyModel(BaseModel):     ...</p> <p>Or programmatically: register_model(MyModel, namespace=\"custom\")</p> <p>Parameters:</p> Name Type Description Default <code>model_class_or_namespace</code> <code>Any</code> <p>The model class to register or a namespace string</p> <code>None</code> <code>namespace</code> <code>str</code> <p>The namespace to register the model in (when used programmatically)</p> <code>DEFAULT_NAMESPACE</code> <p>Returns:</p> Type Description <p>The decorator function or the registered model class</p> Source code in <code>src/results_manager/model_registry.py</code> <pre><code>def register_model(model_class_or_namespace: Any = None, *, namespace: str = DEFAULT_NAMESPACE):\n    \"\"\"\n    Register a pydantic model class in the registry.\n\n    Can be used as a decorator with or without arguments:\n\n    @register_model\n    class MyModel(BaseModel):\n        ...\n\n    @register_model(namespace=\"custom\")\n    class MyModel(BaseModel):\n        ...\n\n    Or programmatically:\n    register_model(MyModel, namespace=\"custom\")\n\n    Args:\n        model_class_or_namespace: The model class to register or a namespace string\n        namespace: The namespace to register the model in (when used programmatically)\n\n    Returns:\n        The decorator function or the registered model class\n    \"\"\"\n    # Handle case where register_model is called directly with a model class\n    if isinstance(model_class_or_namespace, type) and issubclass(model_class_or_namespace, BaseModel):\n        return _register_model(model_class_or_namespace, namespace)\n\n    # Handle case where register_model is used as a decorator with or without arguments\n    def decorator(model_class):\n        if not isinstance(model_class, type) or not issubclass(model_class, BaseModel):\n            raise TypeError(\"Registered model must be a subclass of BaseModel\")\n\n        # If model_class_or_namespace is a string, use it as namespace\n        ns = model_class_or_namespace if isinstance(model_class_or_namespace, str) else namespace\n        return _register_model(model_class, ns)\n\n    return decorator\n</code></pre>"},{"location":"reference/results_manager/async_backends/","title":"async_backends","text":""},{"location":"reference/results_manager/async_backends/#results_manager.async_backends","title":"async_backends","text":""},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend","title":"AsyncFileBackend","text":"<pre><code>AsyncFileBackend(\n    base_dir: Union[str, Path],\n    create_if_missing: bool = True,\n    locks_dir: Optional[Union[str, Path]] = None,\n)\n</code></pre> <p>               Bases: <code>AsyncResultsBackend[T]</code></p> <p>Async wrapper for FileBackend.</p> <p>Runs the synchronous FileBackend methods in a threadpool to avoid blocking the event loop.</p> <p>Initialize the AsyncFileBackend.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory to store results</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>locks_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory to store lock files. If None, uses a system temp directory.</p> <code>None</code> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>def __init__(self, base_dir: Union[str, Path], create_if_missing: bool = True, locks_dir: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize the AsyncFileBackend.\n\n    Args:\n        base_dir: Base directory to store results\n        create_if_missing: Whether to create the directory if it doesn't exist\n        locks_dir: Directory to store lock files. If None, uses a system temp directory.\n    \"\"\"\n    # Create the synchronous backend\n    self._backend = FileBackend(base_dir, create_if_missing, locks_dir)\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    await asyncio.to_thread(\n        self._backend.clear\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.delete,\n        result_id=result_id\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.exists,\n        result_id=result_id\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.get,\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.list_ids,\n        prefix=prefix\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncFileBackend.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.set,\n        result_id=result_id,\n        data=data,\n        behavior=behavior,\n        namespace=namespace,\n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend","title":"AsyncResultsBackend","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Abstract base class for async results storage backends.</p> <p>Implementations should provide asynchronous storage and retrieval of Pydantic models.</p>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend.clear","title":"clear  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend.exists","title":"exists  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend.get","title":"get  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend.list_ids","title":"list_ids  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncResultsBackend.set","title":"set  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend","title":"AsyncSqliteBackend","text":"<pre><code>AsyncSqliteBackend(db_path: Union[str, Path], create_if_missing: bool = True)\n</code></pre> <p>               Bases: <code>AsyncResultsBackend[T]</code></p> <p>Async SQLite-based implementation of AsyncResultsBackend.</p> <p>Uses aiosqlite for asynchronous database operations.</p> <p>Initialize the AsyncSqliteBackend.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>Union[str, Path]</code> <p>Path to the SQLite database file</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the database if it doesn't exist</p> <code>True</code> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>def __init__(self, db_path: Union[str, Path], create_if_missing: bool = True):\n    \"\"\"\n    Initialize the AsyncSqliteBackend.\n\n    Args:\n        db_path: Path to the SQLite database file\n        create_if_missing: Whether to create the database if it doesn't exist\n    \"\"\"\n    self.db_path = Path(db_path)\n\n    # Check if the directory exists\n    if not self.db_path.parent.exists():\n        if create_if_missing:\n            self.db_path.parent.mkdir(parents=True, exist_ok=True)\n        else:\n            raise FileNotFoundError(f\"Directory for database {self.db_path.parent} does not exist\")\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    # Make sure the database directory exists\n    if not self.db_path.parent.exists():\n        self.db_path.parent.mkdir(parents=True, exist_ok=True)\n        return  # No database yet, so nothing to clear\n\n    try:\n        # Initialize the database if needed\n        await self._init_db()\n\n        async with aiosqlite.connect(str(self.db_path)) as conn:\n            # Delete all records\n            await conn.execute(\"DELETE FROM results\")\n            await conn.commit()\n\n    except Exception as e:\n        # Log the error or handle it as appropriate\n        print(f\"Error clearing SQLite database: {e}\")\n        raise\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    # Check if it exists first\n    if not await self.exists(normalized_id):\n        return False\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Delete the record\n        await conn.execute(\"DELETE FROM results WHERE id = ?\", (normalized_id,))\n        await conn.commit()\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Check if the ID exists\n        async with conn.execute(\n            \"SELECT 1 FROM results WHERE id = ? LIMIT 1\", \n            (normalized_id,)\n        ) as cursor:\n            result = await cursor.fetchone()\n\n        return result is not None\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Query the database\n        async with conn.execute(\n            \"SELECT model_type, namespace, data FROM results WHERE id = ?\", \n            (normalized_id,)\n        ) as cursor:\n            result = await cursor.fetchone()\n\n        if not result:\n            raise FileNotFoundError(f\"No result found for ID: {normalized_id}\")\n\n        model_type_name, stored_namespace, data_json = result\n\n        # Check for missing model_type\n        if not model_type_name:\n            raise ValueError(f\"Stored data missing model type information\")\n\n        # Parse the JSON data\n        stored_data = json.loads(data_json)\n\n        # If no model class is provided, try to find it from the registry\n        if not model_class:\n            # Use the stored namespace if none provided\n            lookup_namespace = namespace if namespace is not None else stored_namespace\n\n            model_class = get_model_class(model_type_name, namespace=lookup_namespace)\n\n            # If not found in the specified namespace, try alternatives\n            if not model_class:\n                # Try finding in all namespaces\n                model_matches = find_model_in_all_namespaces(model_type_name)\n                if model_matches:\n                    # Use the first match\n                    first_namespace, model_class = model_matches[0]\n                else:\n                    namespaces_tried = [lookup_namespace]\n                    if lookup_namespace != DEFAULT_NAMESPACE:\n                        namespaces_tried.append(DEFAULT_NAMESPACE)\n\n                    raise ValueError(\n                        f\"Model type '{model_type_name}' is not registered in \"\n                        f\"namespace '{lookup_namespace}' or any other namespace. \"\n                        f\"Tried namespaces: {', '.join(namespaces_tried)}\"\n                    )\n\n        # Validate and return the model instance\n        return model_class.model_validate(stored_data)\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        if prefix is None:\n            # Get all IDs\n            async with conn.execute(\"SELECT id FROM results ORDER BY id\") as cursor:\n                rows = await cursor.fetchall()\n        else:\n            # Get IDs matching the prefix\n            normalized_prefix = self._normalize_id(prefix)\n            query_prefix = f\"{normalized_prefix}%\" if normalized_prefix else \"%\"\n            async with conn.execute(\n                \"SELECT id FROM results WHERE id LIKE ? ORDER BY id\", \n                (query_prefix,)\n            ) as cursor:\n                rows = await cursor.fetchall()\n\n        # Extract and return the IDs\n        return [row[0] for row in rows]\n</code></pre>"},{"location":"reference/results_manager/async_backends/#results_manager.async_backends.AsyncSqliteBackend.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    # Determine the namespace to use\n    if namespace is None:\n        # Try to find the namespace from the model class\n        try:\n            model_namespace = find_model_namespace(data.__class__, strict=strict_namespace)\n            if model_namespace is not None:\n                namespace = model_namespace\n            else:\n                namespace = DEFAULT_NAMESPACE\n        except ValueError as e:\n            # Re-raise the error about multiple namespaces\n            raise ValueError(\n                f\"Cannot automatically determine namespace for {data.__class__.__name__} \"\n                f\"when saving to '{normalized_id}': {str(e)}\"\n            ) from e\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Check if entry already exists\n        async with conn.execute(\n            \"SELECT model_type, namespace, data FROM results WHERE id = ?\", \n            (normalized_id,)\n        ) as cursor:\n            existing = await cursor.fetchone()\n\n        if existing:\n            if behavior == SetBehavior.RAISE_IF_EXISTS:\n                raise FileExistsError(f\"Data already exists for ID: {normalized_id}\")\n\n            elif behavior == SetBehavior.RAISE_IF_DIFFERENT or behavior == SetBehavior.SKIP_IF_EXISTS:\n                # Compare data directly\n                stored_model_type, stored_namespace, stored_data_json = existing\n                stored_data = json.loads(stored_data_json)\n\n                if stored_model_type == data.__class__.__name__:\n                    # Direct comparison if same model type\n                    if behavior == SetBehavior.SKIP_IF_EXISTS:\n                        # If the data is the same, skip\n                        if stored_data == data.model_dump():\n                            return False\n                    elif behavior == SetBehavior.RAISE_IF_DIFFERENT:\n                        # If the data is different, raise\n                        if stored_data != data.model_dump():\n                            raise FileExistsError(f\"Different data already exists for ID: {normalized_id}\")\n\n        # Prepare data for storage\n        model_type = data.__class__.__name__\n        serialized_data = json.dumps(data.model_dump())\n\n        # Insert or update the record\n        await conn.execute('''\n        INSERT OR REPLACE INTO results (id, model_type, namespace, data, updated_at)\n        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n        ''', (normalized_id, model_type, namespace, serialized_data))\n\n        await conn.commit()\n        return True\n</code></pre>"},{"location":"reference/results_manager/async_backends/base/","title":"base","text":""},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base","title":"base","text":""},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend","title":"AsyncResultsBackend","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Abstract base class for async results storage backends.</p> <p>Implementations should provide asynchronous storage and retrieval of Pydantic models.</p>"},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend.clear","title":"clear  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend.exists","title":"exists  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend.get","title":"get  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend.list_ids","title":"list_ids  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/base/#results_manager.async_backends.base.AsyncResultsBackend.set","title":"set  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/async_backends/base.py</code> <pre><code>@abstractmethod\nasync def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/","title":"file_backend","text":""},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend","title":"file_backend","text":""},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend","title":"AsyncFileBackend","text":"<pre><code>AsyncFileBackend(\n    base_dir: Union[str, Path],\n    create_if_missing: bool = True,\n    locks_dir: Optional[Union[str, Path]] = None,\n)\n</code></pre> <p>               Bases: <code>AsyncResultsBackend[T]</code></p> <p>Async wrapper for FileBackend.</p> <p>Runs the synchronous FileBackend methods in a threadpool to avoid blocking the event loop.</p> <p>Initialize the AsyncFileBackend.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory to store results</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>locks_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory to store lock files. If None, uses a system temp directory.</p> <code>None</code> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>def __init__(self, base_dir: Union[str, Path], create_if_missing: bool = True, locks_dir: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize the AsyncFileBackend.\n\n    Args:\n        base_dir: Base directory to store results\n        create_if_missing: Whether to create the directory if it doesn't exist\n        locks_dir: Directory to store lock files. If None, uses a system temp directory.\n    \"\"\"\n    # Create the synchronous backend\n    self._backend = FileBackend(base_dir, create_if_missing, locks_dir)\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    await asyncio.to_thread(\n        self._backend.clear\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.delete,\n        result_id=result_id\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.exists,\n        result_id=result_id\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.get,\n        result_id=result_id,\n        model_class=model_class,\n        namespace=namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.list_ids,\n        prefix=prefix\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/file_backend/#results_manager.async_backends.file_backend.AsyncFileBackend.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_backends/file_backend.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    return await asyncio.to_thread(\n        self._backend.set,\n        result_id=result_id,\n        data=data,\n        behavior=behavior,\n        namespace=namespace,\n        strict_namespace=strict_namespace\n    )\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/","title":"sqlite_backend","text":""},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend","title":"sqlite_backend","text":""},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend","title":"AsyncSqliteBackend","text":"<pre><code>AsyncSqliteBackend(db_path: Union[str, Path], create_if_missing: bool = True)\n</code></pre> <p>               Bases: <code>AsyncResultsBackend[T]</code></p> <p>Async SQLite-based implementation of AsyncResultsBackend.</p> <p>Uses aiosqlite for asynchronous database operations.</p> <p>Initialize the AsyncSqliteBackend.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>Union[str, Path]</code> <p>Path to the SQLite database file</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the database if it doesn't exist</p> <code>True</code> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>def __init__(self, db_path: Union[str, Path], create_if_missing: bool = True):\n    \"\"\"\n    Initialize the AsyncSqliteBackend.\n\n    Args:\n        db_path: Path to the SQLite database file\n        create_if_missing: Whether to create the database if it doesn't exist\n    \"\"\"\n    self.db_path = Path(db_path)\n\n    # Check if the directory exists\n    if not self.db_path.parent.exists():\n        if create_if_missing:\n            self.db_path.parent.mkdir(parents=True, exist_ok=True)\n        else:\n            raise FileNotFoundError(f\"Directory for database {self.db_path.parent} does not exist\")\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend.clear","title":"clear  <code>async</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Asynchronously clear all stored results.</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"\n    Asynchronously clear all stored results.\n    \"\"\"\n    # Make sure the database directory exists\n    if not self.db_path.parent.exists():\n        self.db_path.parent.mkdir(parents=True, exist_ok=True)\n        return  # No database yet, so nothing to clear\n\n    try:\n        # Initialize the database if needed\n        await self._init_db()\n\n        async with aiosqlite.connect(str(self.db_path)) as conn:\n            # Delete all records\n            await conn.execute(\"DELETE FROM results\")\n            await conn.commit()\n\n    except Exception as e:\n        # Log the error or handle it as appropriate\n        print(f\"Error clearing SQLite database: {e}\")\n        raise\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    # Check if it exists first\n    if not await self.exists(normalized_id):\n        return False\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Delete the record\n        await conn.execute(\"DELETE FROM results WHERE id = ?\", (normalized_id,))\n        await conn.commit()\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend.exists","title":"exists  <code>async</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Asynchronously check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Asynchronously check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Check if the ID exists\n        async with conn.execute(\n            \"SELECT 1 FROM results WHERE id = ? LIMIT 1\", \n            (normalized_id,)\n        ) as cursor:\n            result = await cursor.fetchone()\n\n        return result is not None\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend.get","title":"get  <code>async</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Asynchronously retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def get(self, \n             result_id: Union[str, List[str]], \n             model_class: Optional[Type[T]] = None,\n             namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Asynchronously retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Query the database\n        async with conn.execute(\n            \"SELECT model_type, namespace, data FROM results WHERE id = ?\", \n            (normalized_id,)\n        ) as cursor:\n            result = await cursor.fetchone()\n\n        if not result:\n            raise FileNotFoundError(f\"No result found for ID: {normalized_id}\")\n\n        model_type_name, stored_namespace, data_json = result\n\n        # Check for missing model_type\n        if not model_type_name:\n            raise ValueError(f\"Stored data missing model type information\")\n\n        # Parse the JSON data\n        stored_data = json.loads(data_json)\n\n        # If no model class is provided, try to find it from the registry\n        if not model_class:\n            # Use the stored namespace if none provided\n            lookup_namespace = namespace if namespace is not None else stored_namespace\n\n            model_class = get_model_class(model_type_name, namespace=lookup_namespace)\n\n            # If not found in the specified namespace, try alternatives\n            if not model_class:\n                # Try finding in all namespaces\n                model_matches = find_model_in_all_namespaces(model_type_name)\n                if model_matches:\n                    # Use the first match\n                    first_namespace, model_class = model_matches[0]\n                else:\n                    namespaces_tried = [lookup_namespace]\n                    if lookup_namespace != DEFAULT_NAMESPACE:\n                        namespaces_tried.append(DEFAULT_NAMESPACE)\n\n                    raise ValueError(\n                        f\"Model type '{model_type_name}' is not registered in \"\n                        f\"namespace '{lookup_namespace}' or any other namespace. \"\n                        f\"Tried namespaces: {', '.join(namespaces_tried)}\"\n                    )\n\n        # Validate and return the model instance\n        return model_class.model_validate(stored_data)\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend.list_ids","title":"list_ids  <code>async</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>Asynchronously list all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Asynchronously list all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        if prefix is None:\n            # Get all IDs\n            async with conn.execute(\"SELECT id FROM results ORDER BY id\") as cursor:\n                rows = await cursor.fetchall()\n        else:\n            # Get IDs matching the prefix\n            normalized_prefix = self._normalize_id(prefix)\n            query_prefix = f\"{normalized_prefix}%\" if normalized_prefix else \"%\"\n            async with conn.execute(\n                \"SELECT id FROM results WHERE id LIKE ? ORDER BY id\", \n                (query_prefix,)\n            ) as cursor:\n                rows = await cursor.fetchall()\n\n        # Extract and return the IDs\n        return [row[0] for row in rows]\n</code></pre>"},{"location":"reference/results_manager/async_backends/sqlite_backend/#results_manager.async_backends.sqlite_backend.AsyncSqliteBackend.set","title":"set  <code>async</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Asynchronously store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/async_backends/sqlite_backend.py</code> <pre><code>async def set(self, \n             result_id: Union[str, List[str]], \n             data: BaseModel, \n             behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n             namespace: Optional[str] = None,\n             strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Asynchronously store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    # Ensure database is initialized\n    await self._init_db()\n\n    normalized_id = self._normalize_id(result_id)\n\n    # Determine the namespace to use\n    if namespace is None:\n        # Try to find the namespace from the model class\n        try:\n            model_namespace = find_model_namespace(data.__class__, strict=strict_namespace)\n            if model_namespace is not None:\n                namespace = model_namespace\n            else:\n                namespace = DEFAULT_NAMESPACE\n        except ValueError as e:\n            # Re-raise the error about multiple namespaces\n            raise ValueError(\n                f\"Cannot automatically determine namespace for {data.__class__.__name__} \"\n                f\"when saving to '{normalized_id}': {str(e)}\"\n            ) from e\n\n    async with aiosqlite.connect(str(self.db_path)) as conn:\n        # Check if entry already exists\n        async with conn.execute(\n            \"SELECT model_type, namespace, data FROM results WHERE id = ?\", \n            (normalized_id,)\n        ) as cursor:\n            existing = await cursor.fetchone()\n\n        if existing:\n            if behavior == SetBehavior.RAISE_IF_EXISTS:\n                raise FileExistsError(f\"Data already exists for ID: {normalized_id}\")\n\n            elif behavior == SetBehavior.RAISE_IF_DIFFERENT or behavior == SetBehavior.SKIP_IF_EXISTS:\n                # Compare data directly\n                stored_model_type, stored_namespace, stored_data_json = existing\n                stored_data = json.loads(stored_data_json)\n\n                if stored_model_type == data.__class__.__name__:\n                    # Direct comparison if same model type\n                    if behavior == SetBehavior.SKIP_IF_EXISTS:\n                        # If the data is the same, skip\n                        if stored_data == data.model_dump():\n                            return False\n                    elif behavior == SetBehavior.RAISE_IF_DIFFERENT:\n                        # If the data is different, raise\n                        if stored_data != data.model_dump():\n                            raise FileExistsError(f\"Different data already exists for ID: {normalized_id}\")\n\n        # Prepare data for storage\n        model_type = data.__class__.__name__\n        serialized_data = json.dumps(data.model_dump())\n\n        # Insert or update the record\n        await conn.execute('''\n        INSERT OR REPLACE INTO results (id, model_type, namespace, data, updated_at)\n        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n        ''', (normalized_id, model_type, namespace, serialized_data))\n\n        await conn.commit()\n        return True\n</code></pre>"},{"location":"reference/results_manager/backends/","title":"backends","text":""},{"location":"reference/results_manager/backends/#results_manager.backends","title":"backends","text":""},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend","title":"FileBackend","text":"<pre><code>FileBackend(\n    base_dir: Union[str, Path],\n    create_if_missing: bool = True,\n    locks_dir: Optional[Union[str, Path]] = None,\n)\n</code></pre> <p>               Bases: <code>ResultsBackend[T]</code></p> <p>File-based implementation of ResultsBackend.</p> <p>Stores results as JSON files in a hierarchical directory structure.</p> <p>Initialize the FileBackend.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory to store results</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>locks_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory to store lock files. If None, uses a system temp directory.</p> <code>None</code> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def __init__(self, base_dir: Union[str, Path], create_if_missing: bool = True, locks_dir: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize the FileBackend.\n\n    Args:\n        base_dir: Base directory to store results\n        create_if_missing: Whether to create the directory if it doesn't exist\n        locks_dir: Directory to store lock files. If None, uses a system temp directory.\n    \"\"\"\n    self.base_dir = Path(base_dir)\n\n    if create_if_missing and not self.base_dir.exists():\n        self.base_dir.mkdir(parents=True)\n    elif not self.base_dir.exists():\n        raise FileNotFoundError(f\"Base directory {self.base_dir} does not exist\")\n\n    # Set up locks directory\n    if locks_dir is None:\n        self.locks_dir = Path(tempfile.gettempdir()) / \"results_manager_locks\"\n    else:\n        self.locks_dir = Path(locks_dir)\n\n    # Create locks directory if it doesn't exist\n    if not self.locks_dir.exists():\n        self.locks_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    # For clear(), we'll use a more aggressive approach of deleting then recreating\n    # the directory, which avoids having to lock individual files\n    if self.base_dir.exists():\n        # Create a temporary lock file for the entire directory\n        lock_path = self.locks_dir / \"clear_all.lock\"\n        with FileLock(lock_path):\n            # Save the path\n            path = self.base_dir\n            # Delete everything\n            shutil.rmtree(str(self.base_dir))\n            # Recreate the directory\n            self.base_dir.mkdir(parents=True)\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend.delete","title":"delete","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure thread/process safety\n    with FileLock(lock_path):\n        if not file_path.exists():\n            return False\n\n        file_path.unlink()\n\n        # Try to clean up empty directories\n        current_dir = file_path.parent\n        while current_dir != self.base_dir:\n            if not any(current_dir.iterdir()):\n                current_dir.rmdir()\n                current_dir = current_dir.parent\n            else:\n                break\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend.exists","title":"exists","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure consistent state\n    with FileLock(lock_path):\n        return file_path.exists()\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend.get","title":"get","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against. If not provided,          the stored model type will be used.</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace override to look for the model in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> <code>ValidationError</code> <p>If the data doesn't match the model schema</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against. If not provided,\n                     the stored model type will be used.\n        namespace: Optional namespace override to look for the model in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n        ValidationError: If the data doesn't match the model schema\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure thread/process safety\n    with FileLock(lock_path):\n        if not file_path.exists():\n            raise FileNotFoundError(f\"No result found for ID: {result_id}\")\n\n        with open(file_path, 'r') as f:\n            stored_data = json.load(f)\n\n        # Check for missing model_type even when model_class is provided\n        model_type_name = stored_data.get(\"model_type\")\n        if not model_type_name:\n            raise ValueError(f\"Stored data missing model type information\")\n\n        # If no model class is provided, try to find it from the registry\n        if not model_class:\n            # Use the stored namespace if none provided\n            stored_namespace = stored_data.get(\"namespace\", DEFAULT_NAMESPACE)\n            lookup_namespace = namespace if namespace is not None else stored_namespace\n\n            model_class = get_model_class(model_type_name, namespace=lookup_namespace)\n\n            # If not found in the specified namespace, try alternatives\n            # Continue from where we left off:\n\n        # If not found in the specified namespace, try alternatives\n        if not model_class:\n            # Try finding in all namespaces\n            model_matches = find_model_in_all_namespaces(model_type_name)\n            if model_matches:\n                # Use the first match\n                first_namespace, model_class = model_matches[0]\n            else:\n                namespaces_tried = [lookup_namespace]\n                if lookup_namespace != DEFAULT_NAMESPACE:\n                    namespaces_tried.append(DEFAULT_NAMESPACE)\n\n                raise ValueError(\n                    f\"Model type '{model_type_name}' is not registered in \"\n                    f\"namespace '{lookup_namespace}' or any other namespace. \"\n                    f\"Tried namespaces: {', '.join(namespaces_tried)}\"\n                )\n\n        # Get the data to validate outside the lock\n        data = stored_data[\"data\"]\n\n    # Validate outside the lock to minimize lock time\n    return model_class.model_validate(data)\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend.list_ids","title":"list_ids","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    if prefix is None:\n        base_path = self.base_dir\n    else:\n        if isinstance(prefix, str):\n            prefix = prefix.split('/')\n        base_path = self.base_dir.joinpath(*prefix)\n\n    if not base_path.exists():\n        return []\n\n    result_ids = []\n    # No need for locking as we're just reading directory structure\n    for path in base_path.rglob(\"*.json\"):\n        # Convert path to relative path from base_dir\n        rel_path = path.relative_to(self.base_dir)\n        # Remove .json extension and convert to string\n        result_id = str(rel_path.with_suffix(''))\n        result_ids.append(result_id)\n\n    return result_ids\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.FileBackend.set","title":"set","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock with a timeout to avoid deadlocks\n    with FileLock(lock_path, timeout=10):  # 10 second timeout\n        # Handle existing data according to behavior\n        if file_path.exists():\n            if behavior == SetBehavior.RAISE_IF_EXISTS:\n                raise FileExistsError(f\"Data already exists for ID: {result_id}\")\n\n            elif behavior == SetBehavior.SKIP_IF_EXISTS:\n                try:\n                    # Simplified logic for SKIP_IF_EXISTS\n                    with open(file_path, 'r') as f:\n                        stored_data = json.load(f)\n\n                    # Compare model types\n                    if stored_data.get(\"model_type\") == data.__class__.__name__:\n                        # Direct comparison of dumped data\n                        if stored_data.get(\"data\") == data.model_dump():\n                            return False  # Skip if exactly the same\n                except (json.JSONDecodeError, KeyError, FileNotFoundError):\n                    # If any error occurs during comparison, default to overwriting\n                    pass\n\n            elif behavior == SetBehavior.RAISE_IF_DIFFERENT:\n                try:\n                    # Load existing data for comparison\n                    with open(file_path, 'r') as f:\n                        stored_data = json.load(f)\n\n                    # Compare model types\n                    if stored_data.get(\"model_type\") == data.__class__.__name__:\n                        # Direct comparison of dumped data\n                        if stored_data.get(\"data\") != data.model_dump():\n                            raise FileExistsError(f\"Different data already exists for ID: {result_id}\")\n                except (json.JSONDecodeError, KeyError, FileNotFoundError):\n                    # If we can't load the file properly, treat as different\n                    raise FileExistsError(f\"Invalid data exists for ID: {result_id}\")\n\n        # Determine the namespace to use\n        if namespace is None:\n            # Try to find the namespace from the model class\n            try:\n                model_namespace = find_model_namespace(data.__class__, strict=strict_namespace)\n                if model_namespace is not None:\n                    namespace = model_namespace\n                else:\n                    namespace = DEFAULT_NAMESPACE\n            except ValueError as e:\n                # Re-raise the error about multiple namespaces\n                raise ValueError(\n                    f\"Cannot automatically determine namespace for {data.__class__.__name__} \"\n                    f\"when saving to '{result_id}': {str(e)}\"\n                ) from e\n\n        # Ensure the directory exists\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Store the model type and namespace along with the data\n        serialized_data = {\n            \"model_type\": data.__class__.__name__,\n            \"namespace\": namespace,\n            \"data\": data.model_dump()\n        }\n\n        # Use atomic write pattern for extra safety\n        temp_file = file_path.with_suffix('.tmp')\n        with open(temp_file, 'w') as f:\n            json.dump(serialized_data, f, indent=2)\n\n        # Rename is atomic on most filesystems\n        temp_file.replace(file_path)\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend","title":"ResultsBackend","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Abstract base class for results storage backends.</p> <p>Implementations should provide storage and retrieval of Pydantic models based on unique IDs.</p>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend.clear","title":"clear  <code>abstractmethod</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend.delete","title":"delete  <code>abstractmethod</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend.exists","title":"exists  <code>abstractmethod</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend.get","title":"get  <code>abstractmethod</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend.list_ids","title":"list_ids  <code>abstractmethod</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/#results_manager.backends.ResultsBackend.set","title":"set  <code>abstractmethod</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/","title":"base","text":""},{"location":"reference/results_manager/backends/base/#results_manager.backends.base","title":"base","text":""},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend","title":"ResultsBackend","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Abstract base class for results storage backends.</p> <p>Implementations should provide storage and retrieval of Pydantic models based on unique IDs.</p>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend.clear","title":"clear  <code>abstractmethod</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend.delete","title":"delete  <code>abstractmethod</code>","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend.exists","title":"exists  <code>abstractmethod</code>","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend.get","title":"get  <code>abstractmethod</code>","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to look in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against\n        namespace: Optional namespace to look in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend.list_ids","title":"list_ids  <code>abstractmethod</code>","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.ResultsBackend.set","title":"set  <code>abstractmethod</code>","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/backends/base.py</code> <pre><code>@abstractmethod\ndef set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/results_manager/backends/base/#results_manager.backends.base.SetBehavior","title":"SetBehavior","text":"<p>               Bases: <code>Enum</code></p> <p>Defines behavior when setting data for an ID that already exists.</p>"},{"location":"reference/results_manager/backends/file_backend/","title":"file_backend","text":""},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend","title":"file_backend","text":""},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend","title":"FileBackend","text":"<pre><code>FileBackend(\n    base_dir: Union[str, Path],\n    create_if_missing: bool = True,\n    locks_dir: Optional[Union[str, Path]] = None,\n)\n</code></pre> <p>               Bases: <code>ResultsBackend[T]</code></p> <p>File-based implementation of ResultsBackend.</p> <p>Stores results as JSON files in a hierarchical directory structure.</p> <p>Initialize the FileBackend.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Union[str, Path]</code> <p>Base directory to store results</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the directory if it doesn't exist</p> <code>True</code> <code>locks_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory to store lock files. If None, uses a system temp directory.</p> <code>None</code> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def __init__(self, base_dir: Union[str, Path], create_if_missing: bool = True, locks_dir: Optional[Union[str, Path]] = None):\n    \"\"\"\n    Initialize the FileBackend.\n\n    Args:\n        base_dir: Base directory to store results\n        create_if_missing: Whether to create the directory if it doesn't exist\n        locks_dir: Directory to store lock files. If None, uses a system temp directory.\n    \"\"\"\n    self.base_dir = Path(base_dir)\n\n    if create_if_missing and not self.base_dir.exists():\n        self.base_dir.mkdir(parents=True)\n    elif not self.base_dir.exists():\n        raise FileNotFoundError(f\"Base directory {self.base_dir} does not exist\")\n\n    # Set up locks directory\n    if locks_dir is None:\n        self.locks_dir = Path(tempfile.gettempdir()) / \"results_manager_locks\"\n    else:\n        self.locks_dir = Path(locks_dir)\n\n    # Create locks directory if it doesn't exist\n    if not self.locks_dir.exists():\n        self.locks_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    # For clear(), we'll use a more aggressive approach of deleting then recreating\n    # the directory, which avoids having to lock individual files\n    if self.base_dir.exists():\n        # Create a temporary lock file for the entire directory\n        lock_path = self.locks_dir / \"clear_all.lock\"\n        with FileLock(lock_path):\n            # Save the path\n            path = self.base_dir\n            # Delete everything\n            shutil.rmtree(str(self.base_dir))\n            # Recreate the directory\n            self.base_dir.mkdir(parents=True)\n</code></pre>"},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend.delete","title":"delete","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure thread/process safety\n    with FileLock(lock_path):\n        if not file_path.exists():\n            return False\n\n        file_path.unlink()\n\n        # Try to clean up empty directories\n        current_dir = file_path.parent\n        while current_dir != self.base_dir:\n            if not any(current_dir.iterdir()):\n                current_dir.rmdir()\n                current_dir = current_dir.parent\n            else:\n                break\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend.exists","title":"exists","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure consistent state\n    with FileLock(lock_path):\n        return file_path.exists()\n</code></pre>"},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend.get","title":"get","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against. If not provided,          the stored model type will be used.</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace override to look for the model in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> <code>ValidationError</code> <p>If the data doesn't match the model schema</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against. If not provided,\n                     the stored model type will be used.\n        namespace: Optional namespace override to look for the model in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n        ValidationError: If the data doesn't match the model schema\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock to ensure thread/process safety\n    with FileLock(lock_path):\n        if not file_path.exists():\n            raise FileNotFoundError(f\"No result found for ID: {result_id}\")\n\n        with open(file_path, 'r') as f:\n            stored_data = json.load(f)\n\n        # Check for missing model_type even when model_class is provided\n        model_type_name = stored_data.get(\"model_type\")\n        if not model_type_name:\n            raise ValueError(f\"Stored data missing model type information\")\n\n        # If no model class is provided, try to find it from the registry\n        if not model_class:\n            # Use the stored namespace if none provided\n            stored_namespace = stored_data.get(\"namespace\", DEFAULT_NAMESPACE)\n            lookup_namespace = namespace if namespace is not None else stored_namespace\n\n            model_class = get_model_class(model_type_name, namespace=lookup_namespace)\n\n            # If not found in the specified namespace, try alternatives\n            # Continue from where we left off:\n\n        # If not found in the specified namespace, try alternatives\n        if not model_class:\n            # Try finding in all namespaces\n            model_matches = find_model_in_all_namespaces(model_type_name)\n            if model_matches:\n                # Use the first match\n                first_namespace, model_class = model_matches[0]\n            else:\n                namespaces_tried = [lookup_namespace]\n                if lookup_namespace != DEFAULT_NAMESPACE:\n                    namespaces_tried.append(DEFAULT_NAMESPACE)\n\n                raise ValueError(\n                    f\"Model type '{model_type_name}' is not registered in \"\n                    f\"namespace '{lookup_namespace}' or any other namespace. \"\n                    f\"Tried namespaces: {', '.join(namespaces_tried)}\"\n                )\n\n        # Get the data to validate outside the lock\n        data = stored_data[\"data\"]\n\n    # Validate outside the lock to minimize lock time\n    return model_class.model_validate(data)\n</code></pre>"},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend.list_ids","title":"list_ids","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    if prefix is None:\n        base_path = self.base_dir\n    else:\n        if isinstance(prefix, str):\n            prefix = prefix.split('/')\n        base_path = self.base_dir.joinpath(*prefix)\n\n    if not base_path.exists():\n        return []\n\n    result_ids = []\n    # No need for locking as we're just reading directory structure\n    for path in base_path.rglob(\"*.json\"):\n        # Convert path to relative path from base_dir\n        rel_path = path.relative_to(self.base_dir)\n        # Remove .json extension and convert to string\n        result_id = str(rel_path.with_suffix(''))\n        result_ids.append(result_id)\n\n    return result_ids\n</code></pre>"},{"location":"reference/results_manager/backends/file_backend/#results_manager.backends.file_backend.FileBackend.set","title":"set","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if model is in multiple namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped</p> Source code in <code>src/results_manager/backends/file_backend.py</code> <pre><code>def set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in\n        strict_namespace: If True, raises an error if model is in multiple namespaces\n\n    Returns:\n        True if data was written, False if skipped\n    \"\"\"\n    file_path = self._get_path_from_id(result_id)\n    lock_path = self._get_lock_path(file_path)\n\n    # Use file lock with a timeout to avoid deadlocks\n    with FileLock(lock_path, timeout=10):  # 10 second timeout\n        # Handle existing data according to behavior\n        if file_path.exists():\n            if behavior == SetBehavior.RAISE_IF_EXISTS:\n                raise FileExistsError(f\"Data already exists for ID: {result_id}\")\n\n            elif behavior == SetBehavior.SKIP_IF_EXISTS:\n                try:\n                    # Simplified logic for SKIP_IF_EXISTS\n                    with open(file_path, 'r') as f:\n                        stored_data = json.load(f)\n\n                    # Compare model types\n                    if stored_data.get(\"model_type\") == data.__class__.__name__:\n                        # Direct comparison of dumped data\n                        if stored_data.get(\"data\") == data.model_dump():\n                            return False  # Skip if exactly the same\n                except (json.JSONDecodeError, KeyError, FileNotFoundError):\n                    # If any error occurs during comparison, default to overwriting\n                    pass\n\n            elif behavior == SetBehavior.RAISE_IF_DIFFERENT:\n                try:\n                    # Load existing data for comparison\n                    with open(file_path, 'r') as f:\n                        stored_data = json.load(f)\n\n                    # Compare model types\n                    if stored_data.get(\"model_type\") == data.__class__.__name__:\n                        # Direct comparison of dumped data\n                        if stored_data.get(\"data\") != data.model_dump():\n                            raise FileExistsError(f\"Different data already exists for ID: {result_id}\")\n                except (json.JSONDecodeError, KeyError, FileNotFoundError):\n                    # If we can't load the file properly, treat as different\n                    raise FileExistsError(f\"Invalid data exists for ID: {result_id}\")\n\n        # Determine the namespace to use\n        if namespace is None:\n            # Try to find the namespace from the model class\n            try:\n                model_namespace = find_model_namespace(data.__class__, strict=strict_namespace)\n                if model_namespace is not None:\n                    namespace = model_namespace\n                else:\n                    namespace = DEFAULT_NAMESPACE\n            except ValueError as e:\n                # Re-raise the error about multiple namespaces\n                raise ValueError(\n                    f\"Cannot automatically determine namespace for {data.__class__.__name__} \"\n                    f\"when saving to '{result_id}': {str(e)}\"\n                ) from e\n\n        # Ensure the directory exists\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Store the model type and namespace along with the data\n        serialized_data = {\n            \"model_type\": data.__class__.__name__,\n            \"namespace\": namespace,\n            \"data\": data.model_dump()\n        }\n\n        # Use atomic write pattern for extra safety\n        temp_file = file_path.with_suffix('.tmp')\n        with open(temp_file, 'w') as f:\n            json.dump(serialized_data, f, indent=2)\n\n        # Rename is atomic on most filesystems\n        temp_file.replace(file_path)\n\n        return True\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/","title":"sqlite_backend","text":""},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend","title":"sqlite_backend","text":""},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend","title":"SqliteBackend","text":"<pre><code>SqliteBackend(db_path: Union[str, Path], create_if_missing: bool = True)\n</code></pre> <p>               Bases: <code>ResultsBackend[T]</code></p> <p>SQLite-based implementation of ResultsBackend.</p> <p>Stores results in a SQLite database with efficient indexing and querying.</p> <p>Initialize the SqliteBackend.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>Union[str, Path]</code> <p>Path to the SQLite database file</p> required <code>create_if_missing</code> <code>bool</code> <p>Whether to create the database if it doesn't exist</p> <code>True</code> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def __init__(self, db_path: Union[str, Path], create_if_missing: bool = True):\n    \"\"\"\n    Initialize the SqliteBackend.\n\n    Args:\n        db_path: Path to the SQLite database file\n        create_if_missing: Whether to create the database if it doesn't exist\n    \"\"\"\n    self.db_path = Path(db_path)\n\n    # Check if the directory exists\n    if not self.db_path.parent.exists():\n        if create_if_missing:\n            self.db_path.parent.mkdir(parents=True, exist_ok=True)\n        else:\n            raise FileNotFoundError(f\"Directory for database {self.db_path.parent} does not exist\")\n\n    # Initialize database and create tables if needed\n    self._init_db()\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all stored results.</p> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all stored results.\n    \"\"\"\n    # Make sure the database directory exists\n    if not self.db_path.parent.exists():\n        self.db_path.parent.mkdir(parents=True, exist_ok=True)\n        return  # No database yet, so nothing to clear\n\n    conn = sqlite3.connect(str(self.db_path))\n    try:\n        cursor = conn.cursor()\n\n        # Check if the table exists\n        cursor.execute('''\n        SELECT name FROM sqlite_master WHERE type='table' AND name='results'\n        ''')\n\n        if cursor.fetchone():\n            # Table exists, so delete all records\n            cursor.execute(\"DELETE FROM results\")\n            conn.commit()\n        else:\n            # Initialize the database\n            self._init_db()\n\n    finally:\n        conn.close()\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend.delete","title":"delete","text":"<pre><code>delete(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Delete a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deleted, False if not found</p> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def delete(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Delete a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if deleted, False if not found\n    \"\"\"\n    normalized_id = self._normalize_id(result_id)\n\n    conn = sqlite3.connect(str(self.db_path))\n    try:\n        cursor = conn.cursor()\n\n        # Check if it exists first\n        if not self.exists(normalized_id):\n            return False\n\n        # Delete the record\n        cursor.execute(\"DELETE FROM results WHERE id = ?\", (normalized_id,))\n        conn.commit()\n\n        return True\n\n    finally:\n        conn.close()\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend.exists","title":"exists","text":"<pre><code>exists(result_id: Union[str, List[str]]) -&gt; bool\n</code></pre> <p>Check if a result exists for the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the result exists, False otherwise</p> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def exists(self, result_id: Union[str, List[str]]) -&gt; bool:\n    \"\"\"\n    Check if a result exists for the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n\n    Returns:\n        True if the result exists, False otherwise\n    \"\"\"\n    normalized_id = self._normalize_id(result_id)\n\n    conn = sqlite3.connect(str(self.db_path))\n    try:\n        cursor = conn.cursor()\n\n        # Check if the ID exists\n        cursor.execute(\"SELECT 1 FROM results WHERE id = ? LIMIT 1\", (normalized_id,))\n        return cursor.fetchone() is not None\n\n    finally:\n        conn.close()\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend.get","title":"get","text":"<pre><code>get(\n    result_id: Union[str, List[str]],\n    model_class: Optional[Type[T]] = None,\n    namespace: Optional[str] = None,\n) -&gt; T\n</code></pre> <p>Retrieve a result by ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>model_class</code> <code>Optional[Type[T]]</code> <p>Optional model class to validate against. If not provided,          the stored model type will be used.</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace override to look for the model in</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>Pydantic model instance</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the result doesn't exist</p> <code>ValueError</code> <p>If the model type is not registered</p> <code>ValidationError</code> <p>If the data doesn't match the model schema</p> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def get(self, \n        result_id: Union[str, List[str]], \n        model_class: Optional[Type[T]] = None,\n        namespace: Optional[str] = None) -&gt; T:\n    \"\"\"\n    Retrieve a result by ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        model_class: Optional model class to validate against. If not provided,\n                     the stored model type will be used.\n        namespace: Optional namespace override to look for the model in\n\n    Returns:\n        Pydantic model instance\n\n    Raises:\n        FileNotFoundError: If the result doesn't exist\n        ValueError: If the model type is not registered\n        ValidationError: If the data doesn't match the model schema\n    \"\"\"\n    normalized_id = self._normalize_id(result_id)\n\n    conn = sqlite3.connect(str(self.db_path))\n    try:\n        cursor = conn.cursor()\n\n        # Query the database\n        cursor.execute(\"SELECT model_type, namespace, data FROM results WHERE id = ?\", (normalized_id,))\n        result = cursor.fetchone()\n\n        if not result:\n            raise FileNotFoundError(f\"No result found for ID: {normalized_id}\")\n\n        model_type_name, stored_namespace, data_json = result\n\n        # Check for missing model_type\n        if not model_type_name:\n            raise ValueError(f\"Stored data missing model type information\")\n\n        # Parse the JSON data\n        stored_data = json.loads(data_json)\n\n        # If no model class is provided, try to find it from the registry\n        if not model_class:\n            # Use the stored namespace if none provided\n            lookup_namespace = namespace if namespace is not None else stored_namespace\n\n            model_class = get_model_class(model_type_name, namespace=lookup_namespace)\n\n            # If not found in the specified namespace, try alternatives\n            if not model_class:\n                # Try finding in all namespaces\n                model_matches = find_model_in_all_namespaces(model_type_name)\n                if model_matches:\n                    # Use the first match\n                    first_namespace, model_class = model_matches[0]\n                else:\n                    namespaces_tried = [lookup_namespace]\n                    if lookup_namespace != DEFAULT_NAMESPACE:\n                        namespaces_tried.append(DEFAULT_NAMESPACE)\n\n                    raise ValueError(\n                        f\"Model type '{model_type_name}' is not registered in \"\n                        f\"namespace '{lookup_namespace}' or any other namespace. \"\n                        f\"Tried namespaces: {', '.join(namespaces_tried)}\"\n                    )\n\n        # Validate and return the model instance\n        return model_class.model_validate(stored_data)\n\n    finally:\n        conn.close()\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend.list_ids","title":"list_ids","text":"<pre><code>list_ids(prefix: Union[str, List[str]] = None) -&gt; List[str]\n</code></pre> <p>List all result IDs, optionally filtered by a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Union[str, List[str]]</code> <p>Optional prefix path to filter results</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of result IDs</p> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def list_ids(self, prefix: Union[str, List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    List all result IDs, optionally filtered by a prefix.\n\n    Args:\n        prefix: Optional prefix path to filter results\n\n    Returns:\n        List of result IDs\n    \"\"\"\n    conn = sqlite3.connect(str(self.db_path))\n    try:\n        cursor = conn.cursor()\n\n        if prefix is None:\n            # Get all IDs\n            cursor.execute(\"SELECT id FROM results ORDER BY id\")\n        else:\n            # Get IDs matching the prefix\n            normalized_prefix = self._normalize_id(prefix)\n            query_prefix = f\"{normalized_prefix}%\" if normalized_prefix else \"%\"\n            cursor.execute(\"SELECT id FROM results WHERE id LIKE ? ORDER BY id\", (query_prefix,))\n\n        # Extract and return the IDs\n        return [row[0] for row in cursor.fetchall()]\n\n    finally:\n        conn.close()\n</code></pre>"},{"location":"reference/results_manager/backends/sqlite_backend/#results_manager.backends.sqlite_backend.SqliteBackend.set","title":"set","text":"<pre><code>set(\n    result_id: Union[str, List[str]],\n    data: BaseModel,\n    behavior: SetBehavior = RAISE_IF_EXISTS,\n    namespace: Optional[str] = None,\n    strict_namespace: bool = False,\n) -&gt; bool\n</code></pre> <p>Store a result with the given ID.</p> <p>Parameters:</p> Name Type Description Default <code>result_id</code> <code>Union[str, List[str]]</code> <p>Unique identifier or hierarchical path for the result</p> required <code>data</code> <code>BaseModel</code> <p>Pydantic model instance to store</p> required <code>behavior</code> <code>SetBehavior</code> <p>How to handle existing data with the same ID</p> <code>RAISE_IF_EXISTS</code> <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace to store the model in. If None, will try to       determine the namespace from the model class automatically.</p> <code>None</code> <code>strict_namespace</code> <code>bool</code> <p>If True, raises an error if the model is registered               in multiple non-default namespaces</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if data was written, False if skipped (only for SKIP_IF_EXISTS)</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If data already exists (for RAISE_IF_EXISTS) or              if different data exists (for RAISE_IF_DIFFERENT)</p> Source code in <code>src/results_manager/backends/sqlite_backend.py</code> <pre><code>def set(self, \n        result_id: Union[str, List[str]], \n        data: BaseModel, \n        behavior: SetBehavior = SetBehavior.RAISE_IF_EXISTS,\n        namespace: Optional[str] = None,\n        strict_namespace: bool = False) -&gt; bool:\n    \"\"\"\n    Store a result with the given ID.\n\n    Args:\n        result_id: Unique identifier or hierarchical path for the result\n        data: Pydantic model instance to store\n        behavior: How to handle existing data with the same ID\n        namespace: Optional namespace to store the model in. If None, will try to\n                  determine the namespace from the model class automatically.\n        strict_namespace: If True, raises an error if the model is registered \n                         in multiple non-default namespaces\n\n    Returns:\n        True if data was written, False if skipped (only for SKIP_IF_EXISTS)\n\n    Raises:\n        FileExistsError: If data already exists (for RAISE_IF_EXISTS) or\n                         if different data exists (for RAISE_IF_DIFFERENT)\n    \"\"\"\n    normalized_id = self._normalize_id(result_id)\n\n    # Determine the namespace to use\n    if namespace is None:\n        # Try to find the namespace from the model class\n        try:\n            model_namespace = find_model_namespace(data.__class__, strict=strict_namespace)\n            if model_namespace is not None:\n                namespace = model_namespace\n            else:\n                namespace = DEFAULT_NAMESPACE\n        except ValueError as e:\n            # Re-raise the error about multiple namespaces\n            raise ValueError(\n                f\"Cannot automatically determine namespace for {data.__class__.__name__} \"\n                f\"when saving to '{normalized_id}': {str(e)}\"\n            ) from e\n\n    conn = sqlite3.connect(str(self.db_path))\n    try:\n        cursor = conn.cursor()\n\n        # Check if entry already exists\n        cursor.execute(\"SELECT model_type, namespace, data FROM results WHERE id = ?\", (normalized_id,))\n        existing = cursor.fetchone()\n\n        if existing:\n            if behavior == SetBehavior.RAISE_IF_EXISTS:\n                raise FileExistsError(f\"Data already exists for ID: {normalized_id}\")\n\n            elif behavior == SetBehavior.RAISE_IF_DIFFERENT or behavior == SetBehavior.SKIP_IF_EXISTS:\n                # Compare data directly\n                stored_model_type, stored_namespace, stored_data_json = existing\n                stored_data = json.loads(stored_data_json)\n\n                if stored_model_type == data.__class__.__name__:\n                    # Direct comparison if same model type\n                    if behavior == SetBehavior.SKIP_IF_EXISTS:\n                        # If the data is the same, skip\n                        if stored_data == data.model_dump():\n                            return False\n                    elif behavior == SetBehavior.RAISE_IF_DIFFERENT:\n                        # If the data is different, raise\n                        if stored_data != data.model_dump():\n                            raise FileExistsError(f\"Different data already exists for ID: {normalized_id}\")\n\n                # For more complex comparisons, we'd need to load the model class\n                # but for simplicity in this example, we'll just compare the raw data\n\n        # Prepare data for storage\n        model_type = data.__class__.__name__\n        serialized_data = json.dumps(data.model_dump())\n\n        # Insert or update the record\n        cursor.execute('''\n        INSERT OR REPLACE INTO results (id, model_type, namespace, data, updated_at)\n        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n        ''', (normalized_id, model_type, namespace, serialized_data))\n\n        conn.commit()\n        return True\n\n    finally:\n        conn.close()\n</code></pre>"}]}